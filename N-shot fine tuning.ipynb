{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41acd604-1100-4d78-a5f2-e8fea87d2c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('labeled_comments_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b35a84-15c3-4020-92a8-c9a83b0eb818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>anonymized_nickname</th>\n",
       "      <th>document_paragraph_text</th>\n",
       "      <th>document_selected_text</th>\n",
       "      <th>document_selected_sentences</th>\n",
       "      <th>comment_full_text</th>\n",
       "      <th>comment_sentence_text</th>\n",
       "      <th>is_sentence</th>\n",
       "      <th>...</th>\n",
       "      <th>spelling_errors</th>\n",
       "      <th>tracked_changes</th>\n",
       "      <th>next_action</th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>level_3</th>\n",
       "      <th>level_4</th>\n",
       "      <th>date_column</th>\n",
       "      <th>time_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ed88fa24-1a89-44fb-9a66-c7f554d87f5d</td>\n",
       "      <td>ffc97358-69e6-48fb-aaf0-6a844e26f653</td>\n",
       "      <td>2013-04-09 09:30:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Editor</td>\n",
       "      <td>The experiments were carried out in a fluidize...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ok?</td>\n",
       "      <td>Ok?</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KEEP</td>\n",
       "      <td>INFORMATION EXCHANGE</td>\n",
       "      <td>REQUESTED</td>\n",
       "      <td>REQUESTING_CONFIRMATION</td>\n",
       "      <td>POTENTIAL_CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-04-09</td>\n",
       "      <td>09:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e</td>\n",
       "      <td>ffa706dc-4877-492d-ac74-598d5f4d07c5</td>\n",
       "      <td>2011-12-08 15:51:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Alicia R. Dalton-Tingler</td>\n",
       "      <td>In addition to the work mentioned above, the E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KEEP</td>\n",
       "      <td>MODIFICATION</td>\n",
       "      <td>EXECUTION</td>\n",
       "      <td>PROMISE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>15:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e</td>\n",
       "      <td>ffa706dc-4877-492d-ac74-598d5f4d07c5</td>\n",
       "      <td>2011-12-08 15:51:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Alicia R. Dalton-Tingler</td>\n",
       "      <td>In addition to the work mentioned above, the E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>It is, however, very out of place sitting here.</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KEEP</td>\n",
       "      <td>SOCIAL COMMUNICATION</td>\n",
       "      <td>DISCUSSION</td>\n",
       "      <td>CONTENT</td>\n",
       "      <td>NOT_POTENTIAL_CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>15:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e</td>\n",
       "      <td>ffa706dc-4877-492d-ac74-598d5f4d07c5</td>\n",
       "      <td>2011-12-08 15:51:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Alicia R. Dalton-Tingler</td>\n",
       "      <td>In addition to the work mentioned above, the E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KEEP</td>\n",
       "      <td>MODIFICATION</td>\n",
       "      <td>REQUESTED</td>\n",
       "      <td>CONTENT</td>\n",
       "      <td>EXPLICIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>15:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f5208894-9572-4cb8-b023-00b3c03cee89</td>\n",
       "      <td>ff533813-4050-424d-8e01-3c8dbb392f4d</td>\n",
       "      <td>2016-03-09 15:05:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Alannah Kittle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CODING\\n\\nCode qualitative data for WAVGUAGE03A</td>\n",
       "      <td>CODING\\n\\nCode qualitative data for WAVGUAGE03A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KEEP</td>\n",
       "      <td>INFORMATION EXCHANGE</td>\n",
       "      <td>PROVIDED</td>\n",
       "      <td>REFERENCE</td>\n",
       "      <td>POTENTIAL_CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-09</td>\n",
       "      <td>15:05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file_id                            comment_id  \\\n",
       "0  ed88fa24-1a89-44fb-9a66-c7f554d87f5d  ffc97358-69e6-48fb-aaf0-6a844e26f653   \n",
       "1  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
       "2  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
       "3  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
       "4  f5208894-9572-4cb8-b023-00b3c03cee89  ff533813-4050-424d-8e01-3c8dbb392f4d   \n",
       "\n",
       "                               comment_date       anonymized_nickname  \\\n",
       "0  2013-04-09 09:30:00+00:00 00:00:00+00:00                    Editor   \n",
       "1  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
       "2  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
       "3  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
       "4  2016-03-09 15:05:00+00:00 00:00:00+00:00            Alannah Kittle   \n",
       "\n",
       "                             document_paragraph_text document_selected_text  \\\n",
       "0  The experiments were carried out in a fluidize...                    NaN   \n",
       "1  In addition to the work mentioned above, the E...                    NaN   \n",
       "2  In addition to the work mentioned above, the E...                    NaN   \n",
       "3  In addition to the work mentioned above, the E...                    NaN   \n",
       "4                                                NaN                    NaN   \n",
       "\n",
       "   document_selected_sentences  \\\n",
       "0                          1.0   \n",
       "1                          1.0   \n",
       "2                          1.0   \n",
       "3                          1.0   \n",
       "4                          1.0   \n",
       "\n",
       "                                   comment_full_text  \\\n",
       "0                                                Ok?   \n",
       "1  This has been discussed in the Executive Summa...   \n",
       "2  This has been discussed in the Executive Summa...   \n",
       "3  This has been discussed in the Executive Summa...   \n",
       "4    CODING\\n\\nCode qualitative data for WAVGUAGE03A   \n",
       "\n",
       "                               comment_sentence_text  is_sentence  ...  \\\n",
       "0                                                Ok?            0  ...   \n",
       "1  This has been discussed in the Executive Summa...            1  ...   \n",
       "2    It is, however, very out of place sitting here.            1  ...   \n",
       "3  This has been discussed in the Executive Summa...            0  ...   \n",
       "4    CODING\\n\\nCode qualitative data for WAVGUAGE03A            0  ...   \n",
       "\n",
       "   spelling_errors  tracked_changes  next_action               level_0  \\\n",
       "0              0.0              2.0         KEEP  INFORMATION EXCHANGE   \n",
       "1              0.0              1.0         KEEP          MODIFICATION   \n",
       "2              0.0              1.0         KEEP  SOCIAL COMMUNICATION   \n",
       "3              0.0              1.0         KEEP          MODIFICATION   \n",
       "4              0.0              0.0         KEEP  INFORMATION EXCHANGE   \n",
       "\n",
       "      level_1                  level_2               level_3  level_4  \\\n",
       "0   REQUESTED  REQUESTING_CONFIRMATION      POTENTIAL_CHANGE      NaN   \n",
       "1   EXECUTION                  PROMISE                   NaN      NaN   \n",
       "2  DISCUSSION                  CONTENT  NOT_POTENTIAL_CHANGE      NaN   \n",
       "3   REQUESTED                  CONTENT              EXPLICIT      NaN   \n",
       "4    PROVIDED                REFERENCE      POTENTIAL_CHANGE      NaN   \n",
       "\n",
       "   date_column time_column  \n",
       "0   2013-04-09    09:30:00  \n",
       "1   2011-12-08    15:51:00  \n",
       "2   2011-12-08    15:51:00  \n",
       "3   2011-12-08    15:51:00  \n",
       "4   2016-03-09    15:05:00  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d8a79f-6c1c-43d2-ab59-4e599041f149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('triaged_comments_with_levels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54f4726-5199-448f-a13d-e7c5a19dd2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>anonymized_nickname</th>\n",
       "      <th>document_paragraph_text</th>\n",
       "      <th>document_selected_text</th>\n",
       "      <th>document_selected_sentences</th>\n",
       "      <th>comment_full_text</th>\n",
       "      <th>comment_sentence_text</th>\n",
       "      <th>is_sentence</th>\n",
       "      <th>...</th>\n",
       "      <th>level_3</th>\n",
       "      <th>level_4</th>\n",
       "      <th>date_column</th>\n",
       "      <th>time_column</th>\n",
       "      <th>zero_shot_labels</th>\n",
       "      <th>n_shot_labels</th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>priority</th>\n",
       "      <th>category</th>\n",
       "      <th>triage_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ed88fa24-1a89-44fb-9a66-c7f554d87f5d</td>\n",
       "      <td>ffc97358-69e6-48fb-aaf0-6a844e26f653</td>\n",
       "      <td>2013-04-09 09:30:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Editor</td>\n",
       "      <td>The experiments were carried out in a fluidize...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ok?</td>\n",
       "      <td>Ok?</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>POTENTIAL_CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-04-09</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>important</td>\n",
       "      <td>Ok?\\n\\nIs anyone else watching?\\n\\nI didn't me...</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Legal/Contractual Issues</td>\n",
       "      <td>Medium - Legal/Contractual Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e</td>\n",
       "      <td>ffa706dc-4877-492d-ac74-598d5f4d07c5</td>\n",
       "      <td>2011-12-08 15:51:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Alicia R. Dalton-Tingler</td>\n",
       "      <td>In addition to the work mentioned above, the E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>15:51:00</td>\n",
       "      <td>general</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>Operational Details</td>\n",
       "      <td>High - Operational Details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e</td>\n",
       "      <td>ffa706dc-4877-492d-ac74-598d5f4d07c5</td>\n",
       "      <td>2011-12-08 15:51:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Alicia R. Dalton-Tingler</td>\n",
       "      <td>In addition to the work mentioned above, the E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>15:51:00</td>\n",
       "      <td>general</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>Operational Details</td>\n",
       "      <td>High - Operational Details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e</td>\n",
       "      <td>ffa706dc-4877-492d-ac74-598d5f4d07c5</td>\n",
       "      <td>2011-12-08 15:51:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Alicia R. Dalton-Tingler</td>\n",
       "      <td>In addition to the work mentioned above, the E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>15:51:00</td>\n",
       "      <td>general</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>Operational Details</td>\n",
       "      <td>High - Operational Details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e</td>\n",
       "      <td>ffa706dc-4877-492d-ac74-598d5f4d07c5</td>\n",
       "      <td>2011-12-08 15:51:00+00:00 00:00:00+00:00</td>\n",
       "      <td>Alicia R. Dalton-Tingler</td>\n",
       "      <td>In addition to the work mentioned above, the E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>15:51:00</td>\n",
       "      <td>general</td>\n",
       "      <td>This has been discussed in the Executive Summa...</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>Operational Details</td>\n",
       "      <td>High - Operational Details</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file_id                            comment_id  \\\n",
       "0  ed88fa24-1a89-44fb-9a66-c7f554d87f5d  ffc97358-69e6-48fb-aaf0-6a844e26f653   \n",
       "1  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
       "2  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
       "3  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
       "4  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
       "\n",
       "                               comment_date       anonymized_nickname  \\\n",
       "0  2013-04-09 09:30:00+00:00 00:00:00+00:00                    Editor   \n",
       "1  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
       "2  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
       "3  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
       "4  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
       "\n",
       "                             document_paragraph_text document_selected_text  \\\n",
       "0  The experiments were carried out in a fluidize...                    NaN   \n",
       "1  In addition to the work mentioned above, the E...                    NaN   \n",
       "2  In addition to the work mentioned above, the E...                    NaN   \n",
       "3  In addition to the work mentioned above, the E...                    NaN   \n",
       "4  In addition to the work mentioned above, the E...                    NaN   \n",
       "\n",
       "   document_selected_sentences  \\\n",
       "0                          1.0   \n",
       "1                          1.0   \n",
       "2                          1.0   \n",
       "3                          1.0   \n",
       "4                          1.0   \n",
       "\n",
       "                                   comment_full_text  \\\n",
       "0                                                Ok?   \n",
       "1  This has been discussed in the Executive Summa...   \n",
       "2  This has been discussed in the Executive Summa...   \n",
       "3  This has been discussed in the Executive Summa...   \n",
       "4  This has been discussed in the Executive Summa...   \n",
       "\n",
       "                               comment_sentence_text  is_sentence  ...  \\\n",
       "0                                                Ok?            0  ...   \n",
       "1  This has been discussed in the Executive Summa...            1  ...   \n",
       "2  This has been discussed in the Executive Summa...            1  ...   \n",
       "3  This has been discussed in the Executive Summa...            1  ...   \n",
       "4  This has been discussed in the Executive Summa...            1  ...   \n",
       "\n",
       "            level_3  level_4  date_column  time_column  zero_shot_labels  \\\n",
       "0  POTENTIAL_CHANGE      NaN   2013-04-09     09:30:00         important   \n",
       "1               NaN      NaN   2011-12-08     15:51:00           general   \n",
       "2               NaN      NaN   2011-12-08     15:51:00           general   \n",
       "3               NaN      NaN   2011-12-08     15:51:00           general   \n",
       "4               NaN      NaN   2011-12-08     15:51:00           general   \n",
       "\n",
       "                                       n_shot_labels  dominant_topic  \\\n",
       "0  Ok?\\n\\nIs anyone else watching?\\n\\nI didn't me...               1   \n",
       "1  This has been discussed in the Executive Summa...               0   \n",
       "2  This has been discussed in the Executive Summa...               0   \n",
       "3  This has been discussed in the Executive Summa...               0   \n",
       "4  This has been discussed in the Executive Summa...               0   \n",
       "\n",
       "   priority                  category                       triage_label  \n",
       "0    Medium  Legal/Contractual Issues  Medium - Legal/Contractual Issues  \n",
       "1      High       Operational Details         High - Operational Details  \n",
       "2      High       Operational Details         High - Operational Details  \n",
       "3      High       Operational Details         High - Operational Details  \n",
       "4      High       Operational Details         High - Operational Details  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c769ceb-fb1e-47fb-9644-8ca5386bd7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [315/315 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.259658</td>\n",
       "      <td>0.534535</td>\n",
       "      <td>0.499373</td>\n",
       "      <td>0.580185</td>\n",
       "      <td>0.534535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.274500</td>\n",
       "      <td>0.912623</td>\n",
       "      <td>0.671672</td>\n",
       "      <td>0.615096</td>\n",
       "      <td>0.571641</td>\n",
       "      <td>0.671672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.274500</td>\n",
       "      <td>0.737642</td>\n",
       "      <td>0.690691</td>\n",
       "      <td>0.640823</td>\n",
       "      <td>0.657484</td>\n",
       "      <td>0.690691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.812400</td>\n",
       "      <td>0.666546</td>\n",
       "      <td>0.734735</td>\n",
       "      <td>0.721264</td>\n",
       "      <td>0.759923</td>\n",
       "      <td>0.734735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.587800</td>\n",
       "      <td>0.622103</td>\n",
       "      <td>0.772773</td>\n",
       "      <td>0.768849</td>\n",
       "      <td>0.785110</td>\n",
       "      <td>0.772773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7727727727727728\n",
      "Validation F1 Score: 0.7688485007541725\n",
      "Validation Precision: 0.7851102402742246\n",
      "Validation Recall: 0.7727727727727728\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_fscore_support\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')  # Use your actual file path\n",
    "\n",
    "# Ensure there are no missing values in the relevant columns\n",
    "data = data[['comment_full_text', 'level_0']].dropna()\n",
    "\n",
    "# Map labels to integers\n",
    "label_list = data['level_0'].unique().tolist()\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "data['labels'] = data['level_0'].map(label_to_id)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['comment_full_text'], padding=True, truncation=True)\n",
    "\n",
    "# Convert datasets to the Hugging Face `Dataset` format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "\n",
    "# Convert datasets to the Torch format\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Load the model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=len(label_list)\n",
    ")\n",
    "\n",
    "# Define training arguments with optimizations\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,  # Increase the number of epochs\n",
    "    per_device_train_batch_size=8,  # Adjust the batch size\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,  # Increase weight decay for better regularization\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='epoch',  # Evaluate at the end of each epoch\n",
    "    save_strategy='epoch',  # Save model after each epoch\n",
    "    learning_rate=2e-5,  # Tune the learning rate\n",
    "    load_best_model_at_end=True,  # Early stopping\n",
    "    logging_steps=100,  # Log metrics every 100 steps\n",
    ")\n",
    "\n",
    "# Define a function to compute metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Initialize the Trainer with the new arguments\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print out evaluation metrics\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d754ce6f-bbd4-43b9-b1c6-6e6e6da2e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 04:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.162675</td>\n",
       "      <td>0.347347</td>\n",
       "      <td>0.185427</td>\n",
       "      <td>0.541782</td>\n",
       "      <td>0.347347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.161100</td>\n",
       "      <td>0.865831</td>\n",
       "      <td>0.691692</td>\n",
       "      <td>0.661982</td>\n",
       "      <td>0.725334</td>\n",
       "      <td>0.691692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.161100</td>\n",
       "      <td>0.675484</td>\n",
       "      <td>0.742743</td>\n",
       "      <td>0.723319</td>\n",
       "      <td>0.766747</td>\n",
       "      <td>0.742743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>0.617051</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.767294</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.537800</td>\n",
       "      <td>0.577047</td>\n",
       "      <td>0.797798</td>\n",
       "      <td>0.795129</td>\n",
       "      <td>0.801772</td>\n",
       "      <td>0.797798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.537800</td>\n",
       "      <td>0.572286</td>\n",
       "      <td>0.793794</td>\n",
       "      <td>0.793189</td>\n",
       "      <td>0.794846</td>\n",
       "      <td>0.793794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.542965</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.801511</td>\n",
       "      <td>0.802839</td>\n",
       "      <td>0.801802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.359500</td>\n",
       "      <td>0.538988</td>\n",
       "      <td>0.804805</td>\n",
       "      <td>0.805229</td>\n",
       "      <td>0.806455</td>\n",
       "      <td>0.804805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.359500</td>\n",
       "      <td>0.580742</td>\n",
       "      <td>0.785786</td>\n",
       "      <td>0.787056</td>\n",
       "      <td>0.790293</td>\n",
       "      <td>0.785786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.599532</td>\n",
       "      <td>0.791792</td>\n",
       "      <td>0.792890</td>\n",
       "      <td>0.796314</td>\n",
       "      <td>0.791792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8048048048048048\n",
      "Validation F1 Score: 0.8052287768839695\n",
      "Validation Precision: 0.8064548107920221\n",
      "Validation Recall: 0.8048048048048048\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "\n",
    "# Ensure no missing values\n",
    "data = data[['comment_full_text', 'level_0']].dropna()\n",
    "\n",
    "# Label mapping\n",
    "label_list = data['level_0'].unique().tolist()\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "data['labels'] = data['level_0'].map(label_to_id)\n",
    "\n",
    "# Train/test split\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_list))\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['comment_full_text'], padding=True, truncation=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data).map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "val_dataset = Dataset.from_pandas(val_data).map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "\n",
    "# Format datasets\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Training arguments with early stopping and learning rate scheduling\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type='linear',\n",
    "    logging_dir='./logs'\n",
    ")\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with early stopping\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0665925f-fb4f-4780-9952-bb7bf4869c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 04:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.294981</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>0.510855</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>0.549550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.872877</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.591641</td>\n",
       "      <td>0.557353</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.683653</td>\n",
       "      <td>0.711712</td>\n",
       "      <td>0.681875</td>\n",
       "      <td>0.670483</td>\n",
       "      <td>0.711712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.653151</td>\n",
       "      <td>0.757758</td>\n",
       "      <td>0.745630</td>\n",
       "      <td>0.788709</td>\n",
       "      <td>0.757758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.560789</td>\n",
       "      <td>0.778779</td>\n",
       "      <td>0.778651</td>\n",
       "      <td>0.780540</td>\n",
       "      <td>0.778779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.596330</td>\n",
       "      <td>0.782783</td>\n",
       "      <td>0.781969</td>\n",
       "      <td>0.782336</td>\n",
       "      <td>0.782783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.546750</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.785287</td>\n",
       "      <td>0.789561</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>0.559102</td>\n",
       "      <td>0.788789</td>\n",
       "      <td>0.788911</td>\n",
       "      <td>0.792557</td>\n",
       "      <td>0.788789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>0.616594</td>\n",
       "      <td>0.781782</td>\n",
       "      <td>0.783466</td>\n",
       "      <td>0.790473</td>\n",
       "      <td>0.781782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>0.623546</td>\n",
       "      <td>0.798799</td>\n",
       "      <td>0.799024</td>\n",
       "      <td>0.799918</td>\n",
       "      <td>0.798799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7837837837837838\n",
      "Validation F1 Score: 0.7852866528954086\n",
      "Validation Precision: 0.7895608812465167\n",
      "Validation Recall: 0.7837837837837838\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "\n",
    "# Ensure there are no missing values in the relevant columns\n",
    "data = data[['comment_full_text', 'level_0']].dropna()\n",
    "\n",
    "# Map labels to integers\n",
    "label_list = data['level_0'].unique().tolist()\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "data['labels'] = data['level_0'].map(label_to_id)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the tokenizer for RoBERTa\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['comment_full_text'], padding=True, truncation=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data).map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "val_dataset = Dataset.from_pandas(val_data).map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "\n",
    "# Convert datasets to the Torch format\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Load the RoBERTa model\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    'roberta-base',\n",
    "    num_labels=len(label_list)\n",
    ")\n",
    "\n",
    "# Update dropout rate to avoid overfitting\n",
    "model.config.hidden_dropout_prob = 0.3  # Increase the dropout\n",
    "\n",
    "# Define training arguments with improved strategies\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=10,  # Increase the number of epochs\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,  # Keep weight decay for regularization\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type='cosine_with_restarts',  # Switch to cosine annealing with restarts\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
    ")\n",
    "\n",
    "# Define a function to compute metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print out evaluation results\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6573903-043a-4b5b-9017-9643c8818ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for N-shot Predictions:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "INFORMATION EXCHANGE       0.00      0.00      0.00    2483.0\n",
      "        MODIFICATION       0.00      0.00      0.00    1886.0\n",
      "               OTHER       0.00      0.00      0.00     273.0\n",
      "SOCIAL COMMUNICATION       0.00      0.00      0.00     349.0\n",
      "       contradiction       0.00      0.00      0.00       0.0\n",
      "          entailment       0.00      0.00      0.00       0.0\n",
      "             neutral       0.00      0.00      0.00       0.0\n",
      "\n",
      "            accuracy                           0.00    4991.0\n",
      "           macro avg       0.00      0.00      0.00    4991.0\n",
      "        weighted avg       0.00      0.00      0.00    4991.0\n",
      "\n",
      "Accuracy: 0.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "\n",
      "Classification Report for Combined LDA + N-shot Predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "       0_contradiction       0.00      0.00      0.00       0.0\n",
      "          0_entailment       0.00      0.00      0.00       0.0\n",
      "             0_neutral       0.00      0.00      0.00       0.0\n",
      "       1_contradiction       0.00      0.00      0.00       0.0\n",
      "          1_entailment       0.00      0.00      0.00       0.0\n",
      "             1_neutral       0.00      0.00      0.00       0.0\n",
      "       2_contradiction       0.00      0.00      0.00       0.0\n",
      "          2_entailment       0.00      0.00      0.00       0.0\n",
      "             2_neutral       0.00      0.00      0.00       0.0\n",
      "       3_contradiction       0.00      0.00      0.00       0.0\n",
      "          3_entailment       0.00      0.00      0.00       0.0\n",
      "             3_neutral       0.00      0.00      0.00       0.0\n",
      "       4_contradiction       0.00      0.00      0.00       0.0\n",
      "          4_entailment       0.00      0.00      0.00       0.0\n",
      "             4_neutral       0.00      0.00      0.00       0.0\n",
      "INFORMATION EXCHANGE_0       0.00      0.00      0.00     570.0\n",
      "INFORMATION EXCHANGE_1       0.00      0.00      0.00     490.0\n",
      "INFORMATION EXCHANGE_2       0.00      0.00      0.00     289.0\n",
      "INFORMATION EXCHANGE_3       0.00      0.00      0.00     393.0\n",
      "INFORMATION EXCHANGE_4       0.00      0.00      0.00     741.0\n",
      "        MODIFICATION_0       0.00      0.00      0.00     455.0\n",
      "        MODIFICATION_1       0.00      0.00      0.00     157.0\n",
      "        MODIFICATION_2       0.00      0.00      0.00     298.0\n",
      "        MODIFICATION_3       0.00      0.00      0.00     682.0\n",
      "        MODIFICATION_4       0.00      0.00      0.00     294.0\n",
      "               OTHER_0       0.00      0.00      0.00      67.0\n",
      "               OTHER_1       0.00      0.00      0.00      49.0\n",
      "               OTHER_2       0.00      0.00      0.00      49.0\n",
      "               OTHER_3       0.00      0.00      0.00      41.0\n",
      "               OTHER_4       0.00      0.00      0.00      67.0\n",
      "SOCIAL COMMUNICATION_0       0.00      0.00      0.00      62.0\n",
      "SOCIAL COMMUNICATION_1       0.00      0.00      0.00      59.0\n",
      "SOCIAL COMMUNICATION_2       0.00      0.00      0.00      37.0\n",
      "SOCIAL COMMUNICATION_3       0.00      0.00      0.00      57.0\n",
      "SOCIAL COMMUNICATION_4       0.00      0.00      0.00     134.0\n",
      "\n",
      "              accuracy                           0.00    4991.0\n",
      "             macro avg       0.00      0.00      0.00    4991.0\n",
      "          weighted avg       0.00      0.00      0.00    4991.0\n",
      "\n",
      "Combined Accuracy: 0.0\n",
      "Combined Precision: 0.0\n",
      "Combined Recall: 0.0\n",
      "Combined F1 Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(comment):\n",
    "    return [word for word in simple_preprocess(comment) if word not in stop_words]\n",
    "\n",
    "# Preprocess the text and create LDA input\n",
    "data['processed_text'] = data['comment_full_text'].apply(preprocess)\n",
    "texts = data['processed_text'].tolist()\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "from gensim.models import LdaModel\n",
    "lda_model = LdaModel(corpus=corpus, num_topics=5, id2word=dictionary, passes=10)\n",
    "\n",
    "# Assign dominant topic for each comment\n",
    "def get_dominant_topic(lda_model, corpus):\n",
    "    dominant_topics = []\n",
    "    for doc in corpus:\n",
    "        topics = lda_model.get_document_topics(doc)\n",
    "        dominant_topic = max(topics, key=lambda x: x[1])[0]  # Topic with highest score\n",
    "        dominant_topics.append(dominant_topic)\n",
    "    return dominant_topics\n",
    "\n",
    "data['dominant_topic'] = get_dominant_topic(lda_model, corpus)\n",
    "\n",
    "# Initialize N-shot learning (using a pre-trained N-shot model)\n",
    "n_shot_classifier = pipeline(\"text-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Apply N-shot classifier to predict labels\n",
    "data['n_shot_labels'] = data['comment_full_text'].apply(lambda x: n_shot_classifier(x)[0]['label'])\n",
    "\n",
    "# Now, compare true labels (e.g., from `level_0`) with predicted labels (`n_shot_labels`)\n",
    "true_labels = data['level_0']\n",
    "predicted_labels = data['n_shot_labels']\n",
    "\n",
    "# Generate classification report for the N-shot learning performance\n",
    "print(\"\\nClassification Report for N-shot Predictions:\")\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    "# Evaluate performance metrics for N-shot predictions\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Evaluate performance of N-shot combined with LDA topics (e.g., dominant topic)\n",
    "# You can create a combined label like 'level_0_dominant_topic' for advanced analysis\n",
    "data['combined_labels'] = data['dominant_topic'].astype(str) + \"_\" + data['n_shot_labels']\n",
    "true_combined_labels = data['level_0'] + \"_\" + data['dominant_topic'].astype(str)\n",
    "predicted_combined_labels = data['combined_labels']\n",
    "\n",
    "# Generate classification report for combined LDA + N-shot results\n",
    "print(\"\\nClassification Report for Combined LDA + N-shot Predictions:\")\n",
    "print(classification_report(true_combined_labels, predicted_combined_labels))\n",
    "\n",
    "# Additional performance metrics for the combined approach\n",
    "combined_accuracy = accuracy_score(true_combined_labels, predicted_combined_labels)\n",
    "combined_precision = precision_score(true_combined_labels, predicted_combined_labels, average='weighted')\n",
    "combined_recall = recall_score(true_combined_labels, predicted_combined_labels, average='weighted')\n",
    "combined_f1 = f1_score(true_combined_labels, predicted_combined_labels, average='weighted')\n",
    "\n",
    "print(f\"Combined Accuracy: {combined_accuracy}\")\n",
    "print(f\"Combined Precision: {combined_precision}\")\n",
    "print(f\"Combined Recall: {combined_recall}\")\n",
    "print(f\"Combined F1 Score: {combined_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6396f02f-3e4b-4593-9480-d3d24c24602b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3993 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.640664</td>\n",
       "      <td>0.739479</td>\n",
       "      <td>0.714676</td>\n",
       "      <td>0.719050</td>\n",
       "      <td>0.739479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.555452</td>\n",
       "      <td>0.778557</td>\n",
       "      <td>0.776350</td>\n",
       "      <td>0.779418</td>\n",
       "      <td>0.778557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.545304</td>\n",
       "      <td>0.784569</td>\n",
       "      <td>0.784482</td>\n",
       "      <td>0.787168</td>\n",
       "      <td>0.784569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7845691382765531\n",
      "Validation Precision: 0.7871681981462326\n",
      "Validation Recall: 0.7845691382765531\n",
      "Validation F1 Score: 0.7844818437761822\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "\n",
    "# Map labels to integers\n",
    "label_list = data['level_0'].unique().tolist()\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "data['labels'] = data['level_0'].map(label_to_id)\n",
    "\n",
    "# Split into train/test\n",
    "train_data = data.sample(frac=0.8, random_state=42)\n",
    "val_data = data.drop(train_data.index)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['comment_full_text'], padding=True, truncation=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Initialize model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_list))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Define compute metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "989ef9e2-6df8-4abc-bd0d-3ba3a440e490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 01:08, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.271377</td>\n",
       "      <td>0.504505</td>\n",
       "      <td>0.383683</td>\n",
       "      <td>0.562606</td>\n",
       "      <td>0.504505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.023958</td>\n",
       "      <td>0.641642</td>\n",
       "      <td>0.574389</td>\n",
       "      <td>0.739478</td>\n",
       "      <td>0.641642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.679680</td>\n",
       "      <td>0.623760</td>\n",
       "      <td>0.739080</td>\n",
       "      <td>0.679680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.727050</td>\n",
       "      <td>0.668669</td>\n",
       "      <td>0.614924</td>\n",
       "      <td>0.718683</td>\n",
       "      <td>0.668669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.645171</td>\n",
       "      <td>0.737738</td>\n",
       "      <td>0.717678</td>\n",
       "      <td>0.771245</td>\n",
       "      <td>0.737738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7377377377377378\n",
      "Validation Precision: 0.7712446926244793\n",
      "Validation Recall: 0.7377377377377378\n",
      "Validation F1 Score: 0.7176779122314849\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')  # Use your actual file path\n",
    "\n",
    "# Ensure there are no missing values in the relevant columns\n",
    "data = data[['comment_full_text', 'level_0']].dropna()\n",
    "\n",
    "# Map labels to integers (N-shot categories)\n",
    "label_list = data['level_0'].unique().tolist()\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "data['labels'] = data['level_0'].map(label_to_id)\n",
    "\n",
    "# Split the data into training and validation sets (Few examples for N-shot)\n",
    "n_shot_train_size = 5  # Set small N-shot size\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['comment_full_text'], padding=True, truncation=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Load the DistilBERT model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_list))\n",
    "\n",
    "# Define training arguments for few-shot training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,  # Few more epochs for N-shot learning\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e70c5f1-2c89-4799-a6ae-9a79ba847210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.422624</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.422685</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.422824</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.423033</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.423291</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.25\n",
      "Validation F1 Score: 0.25\n",
      "Validation Precision: 0.25\n",
      "Validation Recall: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')  # Use your actual file path\n",
    "\n",
    "# Ensure no missing values in relevant columns\n",
    "data = data[['comment_full_text', 'level_0']].dropna()\n",
    "\n",
    "# Map labels to integers\n",
    "label_list = data['level_0'].unique().tolist()\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "data['labels'] = data['level_0'].map(label_to_id)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenization function with padding and truncation\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['comment_full_text'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "# Define a function to select N-shot samples for each class\n",
    "def select_n_shot_samples(data, n=5):\n",
    "    n_shot_data = []\n",
    "    for label in data['level_0'].unique():\n",
    "        label_data = data[data['level_0'] == label]\n",
    "        # Randomly select n samples from each class\n",
    "        n_shot_data.append(label_data.sample(n=n, random_state=42))\n",
    "    return pd.concat(n_shot_data)\n",
    "\n",
    "# Apply N-shot selection (for example, 5-shot learning)\n",
    "n_shot_data = select_n_shot_samples(data, n=5)\n",
    "\n",
    "# Split the N-shot data into training and validation sets\n",
    "train_data, val_data = train_test_split(n_shot_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert datasets to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "\n",
    "# Set format to PyTorch tensors\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Load pre-trained RoBERTa model\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(label_list))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Define the compute_metrics function for evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a3fa151-4dc1-4376-b9e3-ad6bd599954f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [315/315 01:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.352982</td>\n",
       "      <td>0.462462</td>\n",
       "      <td>0.426605</td>\n",
       "      <td>0.619204</td>\n",
       "      <td>0.462462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.354200</td>\n",
       "      <td>1.194710</td>\n",
       "      <td>0.677678</td>\n",
       "      <td>0.680170</td>\n",
       "      <td>0.704205</td>\n",
       "      <td>0.677678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.354200</td>\n",
       "      <td>0.852175</td>\n",
       "      <td>0.685686</td>\n",
       "      <td>0.697806</td>\n",
       "      <td>0.736637</td>\n",
       "      <td>0.685686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.056900</td>\n",
       "      <td>0.683072</td>\n",
       "      <td>0.717718</td>\n",
       "      <td>0.722431</td>\n",
       "      <td>0.754611</td>\n",
       "      <td>0.717718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.653700</td>\n",
       "      <td>0.621867</td>\n",
       "      <td>0.734735</td>\n",
       "      <td>0.738543</td>\n",
       "      <td>0.779241</td>\n",
       "      <td>0.734735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7347347347347347\n",
      "Validation F1 Score: 0.7385429833851495\n",
      "Validation Precision: 0.7792412671399538\n",
      "Validation Recall: 0.7347347347347347\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "\n",
    "# Ensure there are no missing values in relevant columns\n",
    "data = data[['comment_full_text', 'level_0']].dropna()\n",
    "\n",
    "# Label mapping\n",
    "label_list = data['level_0'].unique().tolist()\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "data['labels'] = data['level_0'].map(label_to_id)\n",
    "\n",
    "# Train/test split\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['comment_full_text'], padding=True, truncation=True)\n",
    "\n",
    "# Convert datasets to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_data).map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "val_dataset = Dataset.from_pandas(val_data).map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "\n",
    "# Format datasets for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(data['labels']), y=data['labels'])\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Load model with DistilBERT\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_list))\n",
    "\n",
    "# Custom Trainer class to override loss function\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        \n",
    "        # Check if model is wrapped in DataParallel\n",
    "        actual_model = model.module if hasattr(model, \"module\") else model\n",
    "        \n",
    "        # Use the custom loss function with class weights\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor.to(logits.device))\n",
    "        loss = loss_fct(logits.view(-1, actual_model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Compute metrics for evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Training arguments with early stopping and learning rate tuning\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,  # Adjust based on performance\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,  # Adjust learning rate if needed\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    lr_scheduler_type='linear'\n",
    ")\n",
    "\n",
    "# Initialize Custom Trainer with early stopping\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e45f05a6-fd18-4c17-8aaa-d159479839f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.469031</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.143254</td>\n",
       "      <td>0.126469</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.468261</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.143254</td>\n",
       "      <td>0.126469</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.466909</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.143254</td>\n",
       "      <td>0.126469</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.464962</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.167401</td>\n",
       "      <td>0.150585</td>\n",
       "      <td>0.270833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.462401</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.167401</td>\n",
       "      <td>0.150585</td>\n",
       "      <td>0.270833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.2708333333333333\n",
      "Validation F1 Score: 0.16740105132962277\n",
      "Validation Precision: 0.1505847953216374\n",
      "Validation Recall: 0.2708333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "\n",
    "# Ensure no missing values\n",
    "data = data[['comment_full_text', 'level_0']].dropna()\n",
    "\n",
    "# Map labels to integers\n",
    "label_list = data['level_0'].unique().tolist()\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "data['labels'] = data['level_0'].map(label_to_id)\n",
    "\n",
    "# Function for N-shot sampling (e.g., 10-shot learning)\n",
    "def n_shot_sampling(data, N):\n",
    "    grouped = data.groupby('labels')\n",
    "    sampled_data = grouped.apply(lambda x: x.sample(n=N, random_state=42)).reset_index(drop=True)\n",
    "    return sampled_data\n",
    "\n",
    "# Sample 10 examples from each class (increase from 5)\n",
    "n_shot_train_data = n_shot_sampling(data, N=60)\n",
    "\n",
    "# Split the sampled data into training and validation sets\n",
    "train_data, val_data = train_test_split(n_shot_train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['comment_full_text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Convert datasets to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n",
    "\n",
    "# Set format to PyTorch tensors\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(data['labels']), y=data['labels'])\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Load model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_list))\n",
    "\n",
    "# Custom Trainer to add class weights to the loss function\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        actual_model = model.module if hasattr(model, \"module\") else model\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor.to(logits.device))\n",
    "        loss = loss_fct(logits.view(-1, actual_model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Metrics calculation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Training arguments with early stopping and learning rate tuning\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    lr_scheduler_type='linear'\n",
    ")\n",
    "\n",
    "# Initialize Custom Trainer with early stopping\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e1b475d-4133-4b55-9560-be143b650b13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4991 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 01:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.660072</td>\n",
       "      <td>0.763764</td>\n",
       "      <td>0.758415</td>\n",
       "      <td>0.776760</td>\n",
       "      <td>0.763764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.549216</td>\n",
       "      <td>0.799800</td>\n",
       "      <td>0.798341</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.799800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.541022</td>\n",
       "      <td>0.803804</td>\n",
       "      <td>0.802768</td>\n",
       "      <td>0.804465</td>\n",
       "      <td>0.803804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8038038038038038\n",
      "Validation F1 Score: 0.802767948892708\n",
      "Validation Precision: 0.8044653962170905\n",
      "Validation Recall: 0.8038038038038038\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "\n",
    "# Ensure no missing values in the columns\n",
    "data = data[['comment_full_text', 'level_0']].dropna()\n",
    "\n",
    "# Map the labels to integers for classification\n",
    "label_list = data['level_0'].unique().tolist()\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "data['labels'] = data['level_0'].map(label_to_id)\n",
    "\n",
    "# Tokenizer for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize and encode the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['comment_full_text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Convert the dataset to Hugging Face Dataset format\n",
    "dataset = Dataset.from_pandas(data)\n",
    "\n",
    "# Tokenize the dataset\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_dataset, val_dataset = dataset.train_test_split(test_size=0.2).values()\n",
    "\n",
    "# Define the model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_list))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\"\n",
    ")\n",
    "\n",
    "# Define metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93f9d7f4-bab5-43eb-834e-540734c1bf8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.622613</td>\n",
       "      <td>0.761762</td>\n",
       "      <td>0.750680</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.761762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.628815</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.745867</td>\n",
       "      <td>0.795821</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.610427</td>\n",
       "      <td>0.768769</td>\n",
       "      <td>0.761657</td>\n",
       "      <td>0.794423</td>\n",
       "      <td>0.768769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.550540566444397, metrics={'train_runtime': 19.6437, 'train_samples_per_second': 3.054, 'train_steps_per_second': 0.153, 'total_flos': 15786946805760.0, 'train_loss': 0.550540566444397, 'epoch': 3.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get N-shot examples per class (e.g., 5-shot)\n",
    "n_shot = 5\n",
    "train_samples = []\n",
    "\n",
    "for label in label_list:\n",
    "    label_subset = data[data['level_0'] == label].sample(n=n_shot, random_state=42)\n",
    "    train_samples.append(label_subset)\n",
    "\n",
    "# Concatenate all N-shot examples into a single DataFrame\n",
    "train_data_n_shot = pd.concat(train_samples)\n",
    "\n",
    "# Convert to Hugging Face dataset\n",
    "train_dataset = Dataset.from_pandas(train_data_n_shot)\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format to PyTorch tensors for training\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Fine-tune the model with these N-shot examples\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train and evaluate with limited N-shot examples\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbb1c10d-908b-4392-84b1-e935dfa6f18f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/spati/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/spati/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def synonym_replacement(text, n=2):\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word not in nltk.corpus.stopwords.words('english')]))\n",
    "    random.shuffle(random_word_list)\n",
    "    \n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = wordnet.synsets(random_word)\n",
    "        if synonyms:\n",
    "            synonym = synonyms[0].lemmas()[0].name()\n",
    "            if synonym != random_word:\n",
    "                new_words = [synonym if word == random_word else word for word in new_words]\n",
    "                num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "# Apply augmentation\n",
    "data['comment_full_text_augmented'] = data['comment_full_text'].apply(lambda x: synonym_replacement(x, n=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f33192c-87cc-4f06-9baf-74f718203fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   comment_full_text  \\\n",
      "0                                                Ok?   \n",
      "1  This has been discussed in the Executive Summa...   \n",
      "2  This has been discussed in the Executive Summa...   \n",
      "3  This has been discussed in the Executive Summa...   \n",
      "4    CODING\\n\\nCode qualitative data for WAVGUAGE03A   \n",
      "\n",
      "                         comment_full_text_augmented  \n",
      "0                                                Ok?  \n",
      "1  This has been discussed in the executive Summa...  \n",
      "2  This has been discussed in the Executive Summa...  \n",
      "3  This has been discussed in the Executive summa...  \n",
      "4  cryptography code qualitative data for WAVGUAG...  \n"
     ]
    }
   ],
   "source": [
    "# Preview the augmented comments\n",
    "print(data[['comment_full_text', 'comment_full_text_augmented']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d810c17c-c05b-4684-8f10-f038ec232cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4991 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the augmented dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['comment_full_text_augmented'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Convert the dataset to a format suitable for Hugging Face models\n",
    "from datasets import Dataset\n",
    "\n",
    "# Create a Hugging Face dataset from the augmented DataFrame\n",
    "train_dataset = Dataset.from_pandas(data)\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format for PyTorch tensors\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5190def3-39c2-4ff3-984d-dd1f11226bca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 01:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.581500</td>\n",
       "      <td>0.447029</td>\n",
       "      <td>0.830831</td>\n",
       "      <td>0.830729</td>\n",
       "      <td>0.832510</td>\n",
       "      <td>0.830831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.362124</td>\n",
       "      <td>0.844845</td>\n",
       "      <td>0.844144</td>\n",
       "      <td>0.845777</td>\n",
       "      <td>0.844845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304300</td>\n",
       "      <td>0.330386</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.873861</td>\n",
       "      <td>0.874274</td>\n",
       "      <td>0.873874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=234, training_loss=0.5014761472359682, metrics={'train_runtime': 80.4411, 'train_samples_per_second': 186.136, 'train_steps_per_second': 2.909, 'total_flos': 3939632575377408.0, 'train_loss': 0.5014761472359682, 'epoch': 3.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_list))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,  # Assuming you have a validation set prepared\n",
    "    compute_metrics=compute_metrics  # Assuming you have a function to compute metrics like accuracy, F1, etc.\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49b4e14e-9982-48c9-b05b-64f93af4e9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 02:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8738738738738738\n",
      "Validation F1 Score: 0.873860848025827\n",
      "Validation Precision: 0.8742736910814857\n",
      "Validation Recall: 0.8738738738738738\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2afc2261-a1da-47da-a0f9-4b1ad3abc60f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./augmented_fine_tuned_bert/tokenizer_config.json',\n",
       " './augmented_fine_tuned_bert/special_tokens_map.json',\n",
       " './augmented_fine_tuned_bert/vocab.txt',\n",
       " './augmented_fine_tuned_bert/added_tokens.json')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained('./augmented_fine_tuned_bert')\n",
    "tokenizer.save_pretrained('./augmented_fine_tuned_bert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3d07468-3d4f-4b4e-9a6e-5b677d5fc021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 01:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.383500</td>\n",
       "      <td>0.324851</td>\n",
       "      <td>0.871872</td>\n",
       "      <td>0.871397</td>\n",
       "      <td>0.875749</td>\n",
       "      <td>0.871872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>0.292802</td>\n",
       "      <td>0.865866</td>\n",
       "      <td>0.865793</td>\n",
       "      <td>0.866691</td>\n",
       "      <td>0.865866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.205600</td>\n",
       "      <td>0.273214</td>\n",
       "      <td>0.876877</td>\n",
       "      <td>0.876989</td>\n",
       "      <td>0.877911</td>\n",
       "      <td>0.876877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=234, training_loss=0.3095962155578483, metrics={'train_runtime': 82.1115, 'train_samples_per_second': 182.35, 'train_steps_per_second': 2.85, 'total_flos': 3939632575377408.0, 'train_loss': 0.3095962155578483, 'epoch': 3.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Get exactly 5 examples per class (5-shot learning)\n",
    "n_shot = 5\n",
    "train_samples = []\n",
    "\n",
    "for label in label_list:\n",
    "    label_subset = data[data['level_0'] == label].sample(n=n_shot, random_state=42)\n",
    "    train_samples.append(label_subset)\n",
    "\n",
    "# Concatenate all 5-shot examples into a single DataFrame\n",
    "train_data_n_shot = pd.concat(train_samples)\n",
    "\n",
    "# Continue with tokenization and training as usual\n",
    "train_dataset = Dataset.from_pandas(train_data_n_shot)\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Train the model on this limited N-shot dataset\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c2be3b5-fb90-4505-9e33-30dcda67d2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-shot dataset saved as 'n_shot_dataset.csv'. You can find it in your working directory.\n"
     ]
    }
   ],
   "source": [
    "# Saving the N-shot dataset to a CSV file locally\n",
    "train_data_n_shot.to_csv('n_shot_dataset.csv', index=False)\n",
    "\n",
    "print(\"N-shot dataset saved as 'n_shot_dataset.csv'. You can find it in your working directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e98eceb-38da-4285-a745-7fbc407b4395",
   "metadata": {},
   "source": [
    "N-shot Learning Explained:\n",
    "N-shot learning is a setup where a model is trained using only a limited number of examples per class, in this case, 5 examples per class (5-shot learning). This approach is particularly useful when you have very few labeled data points and want the model to generalize well with minimal supervision.\n",
    "\n",
    "How the Code Implements N-shot Learning:\n",
    "Limit the Training Data:\n",
    "\n",
    "The line label_subset = data[data['level_0'] == label].sample(n=n_shot, random_state=42) ensures that you select exactly 5 examples (n_shot = 5) from each class. This limits the training data, enforcing the N-shot condition.\n",
    "Concatenate the Samples:\n",
    "\n",
    "After selecting 5 examples from each class, you combine them into a single training dataset: train_data_n_shot = pd.concat(train_samples). This means your training data is now small, with only 5 examples per class, which is exactly the goal of 5-shot learning.\n",
    "Tokenization and Training:\n",
    "\n",
    "After defining the limited dataset, you tokenize it and format it for PyTorch as usual. Then, you train the model using this small set of examples per class (trainer.train()).\n",
    "Relation to N-shot Learning:\n",
    "Yes, this is directly related to N-shot learning because:\n",
    "\n",
    "You are training the model on a small, N-limited dataset (in this case, 5-shot, meaning 5 examples per class).\n",
    "The goal is for the model to generalize well even when trained with very few examples, which is a fundamental concept of few-shot learning.\n",
    "Results Interpretation:\n",
    "The results you achieved in the previous training (validation accuracy, F1 score, precision, recall) are based on training the model with exactly 5 examples per class. This confirms that your model was trained using N-shot learning principles, where N = 5.\n",
    "\n",
    "In summary:\n",
    "\n",
    "The code you've provided and run is performing N-shot learning with 5-shot learning for each class.\n",
    "The results (like validation accuracy, F1 score, etc.) reflect the model's performance based on training with this limited N-shot dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
