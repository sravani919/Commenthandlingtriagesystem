{"cells":[{"cell_type":"code","execution_count":null,"id":"4cc1c17b-a037-4870-8fe5-e5b3dddf2477","metadata":{"tags":[],"id":"4cc1c17b-a037-4870-8fe5-e5b3dddf2477","outputId":"88a03360-d1f8-46ef-d9fa-6e737e9a3642"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                   comment_full_text               level_0\n","0                                                Ok?  INFORMATION EXCHANGE\n","1  This has been discussed in the Executive Summa...          MODIFICATION\n","2  This has been discussed in the Executive Summa...  SOCIAL COMMUNICATION\n","3  This has been discussed in the Executive Summa...          MODIFICATION\n","4    CODING\\n\\nCode qualitative data for WAVGUAGE03A  INFORMATION EXCHANGE\n"]}],"source":["import pandas as pd\n","\n","# Load your dataset\n","data = pd.read_csv('labeled_comments_cleaned.csv')\n","\n","# Ensure there are no missing values in the relevant columns\n","data = data[['comment_full_text', 'level_0']].dropna()\n","\n","# Split the data into batches\n","batch_size = 50  # Adjust this based on your memory capacity\n","batches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n","\n","# Inspect the first batch\n","print(batches[0].head())\n","\n","# Example of how you might process each batch\n","for batch in batches:\n","    texts = batch['comment_full_text'].tolist()\n","    labels = batch['level_0'].tolist()\n","    # Here you would add your processing logic, e.g., zero-shot or n-shot predictions\n"]},{"cell_type":"code","execution_count":null,"id":"7c612b60-9b70-469d-8194-053d5e7aed79","metadata":{"tags":[],"id":"7c612b60-9b70-469d-8194-053d5e7aed79","outputId":"99f3b16e-5c11-4da1-e1dc-55e333bb297c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.47325185333600484\n","Precision: 0.49669816947247025\n","Recall: 0.47325185333600484\n","F1 Score: 0.4208836468269039\n"]},{"name":"stderr","output_type":"stream","text":["/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["import pandas as pd\n","from transformers import pipeline\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","\n","# Load your dataset\n","data = pd.read_csv('labeled_comments_cleaned.csv')  # Use your actual file path\n","\n","# Ensure there are no missing values in the relevant columns\n","data = data[['comment_full_text', 'level_0']].dropna()\n","\n","# Split the data into batches\n","batch_size = 100  # Adjust this based on your memory capacity\n","batches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n","\n","# Initialize the zero-shot classifier\n","zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n","\n","# Define candidate labels (this can be based on your specific use case)\n","candidate_labels = [\"INFORMATION EXCHANGE\", \"MODIFICATION\", \"SOCIAL COMMUNICATION\"]\n","\n","# Lists to hold true labels and predicted labels\n","all_true_labels = []\n","all_predicted_labels = []\n","\n","# Process each batch\n","for batch in batches:\n","    texts = batch['comment_full_text'].tolist()\n","    true_labels = batch['level_0'].tolist()\n","\n","    # Store true labels\n","    all_true_labels.extend(true_labels)\n","\n","    # Make predictions\n","    for text in texts:\n","        result = zero_shot_classifier(text, candidate_labels)\n","        predicted_label = result['labels'][0]  # Take the label with the highest score\n","        all_predicted_labels.append(predicted_label)\n","\n","# Calculate performance metrics\n","accuracy = accuracy_score(all_true_labels, all_predicted_labels)\n","precision = precision_score(all_true_labels, all_predicted_labels, average='weighted')\n","recall = recall_score(all_true_labels, all_predicted_labels, average='weighted')\n","f1 = f1_score(all_true_labels, all_predicted_labels, average='weighted')\n","\n","print(f\"Accuracy: {accuracy}\")\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"F1 Score: {f1}\")\n"]},{"cell_type":"code","execution_count":null,"id":"5790e8b8-e82c-4840-96c9-5ca28c7f0350","metadata":{"tags":[],"id":"5790e8b8-e82c-4840-96c9-5ca28c7f0350","outputId":"f976578f-8cb7-4145-9cd3-ac3283956397","colab":{"referenced_widgets":[""]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3992 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/999 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n","/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [96/96 00:44, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>1.320747</td>\n","      <td>0.515516</td>\n","      <td>0.364303</td>\n","      <td>0.433476</td>\n","      <td>0.515516</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>1.071949</td>\n","      <td>0.595596</td>\n","      <td>0.510645</td>\n","      <td>0.577812</td>\n","      <td>0.595596</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.820963</td>\n","      <td>0.690691</td>\n","      <td>0.633566</td>\n","      <td>0.595691</td>\n","      <td>0.690691</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/home/spati/.local/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4/4 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation Accuracy: 0.6906906906906907\n","Validation F1 Score: 0.6335664302872711\n","Validation Precision: 0.5956913793797542\n","Validation Recall: 0.6906906906906907\n"]},{"name":"stderr","output_type":"stream","text":["/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from datasets import Dataset\n","import numpy as np\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_fscore_support  # <-- Add this import\n","\n","# Load your dataset\n","data = pd.read_csv('labeled_comments_cleaned.csv')  # Use your actual file path\n","\n","# Ensure there are no missing values in the relevant columns\n","data = data[['comment_full_text', 'level_0']].dropna()\n","\n","# Map labels to integers\n","label_list = data['level_0'].unique().tolist()\n","label_to_id = {label: i for i, label in enumerate(label_list)}\n","data['labels'] = data['level_0'].map(label_to_id)\n","\n","# Split the data into training and validation sets\n","train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n","\n","# Load the tokenizer\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","# Tokenize the text\n","def tokenize(batch):\n","    return tokenizer(batch['comment_full_text'], padding=True, truncation=True)\n","\n","# Convert datasets to the Hugging Face `Dataset` format\n","train_dataset = Dataset.from_pandas(train_data)\n","val_dataset = Dataset.from_pandas(val_data)\n","\n","# Tokenize datasets\n","train_dataset = train_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n","val_dataset = val_dataset.map(tokenize, batched=True, remove_columns=['comment_full_text', 'level_0'])\n","\n","# Convert datasets to the Torch format\n","train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","# Load the model\n","model = DistilBertForSequenceClassification.from_pretrained(\n","    'distilbert-base-uncased',\n","    num_labels=len(label_list)\n",")\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=32,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    evaluation_strategy='epoch',\n","    save_strategy='epoch',\n",")\n","\n","# Define a function to compute metrics\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = np.argmax(pred.predictions, axis=1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Evaluate the model on the validation set\n","eval_results = trainer.evaluate()\n","\n","print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n","print(f\"Validation F1 Score: {eval_results['eval_f1']}\")\n","print(f\"Validation Precision: {eval_results['eval_precision']}\")\n","print(f\"Validation Recall: {eval_results['eval_recall']}\")\n"]},{"cell_type":"code","execution_count":null,"id":"f72fce30-2185-4118-8d93-e85b0f7b70b9","metadata":{"tags":[],"id":"f72fce30-2185-4118-8d93-e85b0f7b70b9"},"outputs":[],"source":["import pandas as pd\n","from transformers import pipeline\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Load your dataset\n","data = pd.read_csv('labeled_comments_cleaned.csv')\n","\n","# Ensure there are no missing values in the relevant columns\n","data = data[['comment_full_text', 'level_0']].dropna()\n","\n","# Split the data into batches\n","batch_size = 100  # Adjust this based on your memory capacity\n","batches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n","\n","# Initialize the zero-shot classifier\n","zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n","\n","# Define candidate labels\n","candidate_labels = [\"INFORMATION EXCHANGE\", \"MODIFICATION\", \"SOCIAL COMMUNICATION\"]\n","\n","# Lists to hold true labels and predicted labels\n","all_true_labels = []\n","all_predicted_labels = []\n","\n","# Process each batch\n","for i, batch in enumerate(batches):\n","    texts = batch['comment_full_text'].tolist()\n","    true_labels = batch['level_0'].tolist()\n","\n","    # Store true labels\n","    all_true_labels.extend(true_labels)\n","\n","    # Make predictions\n","    batch_predicted_labels = []\n","    for text in texts:\n","        result = zero_shot_classifier(text, candidate_labels)\n","        predicted_label = result['labels'][0]  # Take the label with the highest score\n","        batch_predicted_labels.append(predicted_label)\n","\n","    # Ensure that the lengths match\n","    if len(batch_predicted_labels) != len(true_labels):\n","        print(f\"Batch {i} has mismatched lengths: {len(true_labels)} true labels vs {len(batch_predicted_labels)} predicted labels\")\n","\n","    all_predicted_labels.extend(batch_predicted_labels)\n","\n","# After the loop, check the final lengths\n","if len(all_true_labels) != len(all_predicted_labels):\n","    print(f\"Final mismatch: {len(all_true_labels)} true labels vs {len(all_predicted_labels)} predicted labels\")\n","\n","# Calculate performance metrics\n","accuracy = accuracy_score(all_true_labels, all_predicted_labels)\n","precision = precision_score(all_true_labels, all_predicted_labels, average='weighted')\n","recall = recall_score(all_true_labels, all_predicted_labels, average='weighted')\n","f1 = f1_score(all_true_labels, all_predicted_labels, average='weighted')\n","\n","print(f\"Zero-shot Accuracy: {accuracy}\")\n","print(f\"Zero-shot Precision: {precision}\")\n","print(f\"Zero-shot Recall: {recall}\")\n","print(f\"Zero-shot F1 Score: {f1}\")\n","\n","# Generate confusion matrix\n","conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels, labels=candidate_labels)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=candidate_labels, yticklabels=candidate_labels)\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Zero-shot Learning Confusion Matrix')\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}