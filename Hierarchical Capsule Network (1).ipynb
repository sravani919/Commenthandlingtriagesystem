{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e23873-4dfa-4835-aa6e-62a5b67200ee",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44061f37-e699-4dd1-afa9-0b7e86a165fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0abcd-d95b-4125-ab2e-a17c8e155373",
   "metadata": {
    "tags": []
   },
   "source": [
    "Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51aeca95-0473-4b6f-af3f-7a5f5464b377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                file_id                            comment_id  \\\n",
      "0  ed88fa24-1a89-44fb-9a66-c7f554d87f5d  ffc97358-69e6-48fb-aaf0-6a844e26f653   \n",
      "1  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
      "2  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
      "3  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
      "4  f5208894-9572-4cb8-b023-00b3c03cee89  ff533813-4050-424d-8e01-3c8dbb392f4d   \n",
      "\n",
      "                               comment_date       anonymized_nickname  \\\n",
      "0  2013-04-09 09:30:00+00:00 00:00:00+00:00                    Editor   \n",
      "1  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
      "2  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
      "3  2011-12-08 15:51:00+00:00 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
      "4  2016-03-09 15:05:00+00:00 00:00:00+00:00            Alannah Kittle   \n",
      "\n",
      "                             document_paragraph_text document_selected_text  \\\n",
      "0  The experiments were carried out in a fluidize...                    NaN   \n",
      "1  In addition to the work mentioned above, the E...                    NaN   \n",
      "2  In addition to the work mentioned above, the E...                    NaN   \n",
      "3  In addition to the work mentioned above, the E...                    NaN   \n",
      "4                                                NaN                    NaN   \n",
      "\n",
      "   document_selected_sentences  \\\n",
      "0                          1.0   \n",
      "1                          1.0   \n",
      "2                          1.0   \n",
      "3                          1.0   \n",
      "4                          1.0   \n",
      "\n",
      "                                   comment_full_text  \\\n",
      "0                                                Ok?   \n",
      "1  This has been discussed in the Executive Summa...   \n",
      "2  This has been discussed in the Executive Summa...   \n",
      "3  This has been discussed in the Executive Summa...   \n",
      "4    CODING\\n\\nCode qualitative data for WAVGUAGE03A   \n",
      "\n",
      "                               comment_sentence_text  is_sentence  ...  \\\n",
      "0                                                Ok?            0  ...   \n",
      "1  This has been discussed in the Executive Summa...            1  ...   \n",
      "2    It is, however, very out of place sitting here.            1  ...   \n",
      "3  This has been discussed in the Executive Summa...            0  ...   \n",
      "4    CODING\\n\\nCode qualitative data for WAVGUAGE03A            0  ...   \n",
      "\n",
      "   spelling_errors  tracked_changes  next_action               level_0  \\\n",
      "0              0.0              2.0         KEEP  INFORMATION EXCHANGE   \n",
      "1              0.0              1.0         KEEP          MODIFICATION   \n",
      "2              0.0              1.0         KEEP  SOCIAL COMMUNICATION   \n",
      "3              0.0              1.0         KEEP          MODIFICATION   \n",
      "4              0.0              0.0         KEEP  INFORMATION EXCHANGE   \n",
      "\n",
      "      level_1                  level_2               level_3  level_4  \\\n",
      "0   REQUESTED  REQUESTING_CONFIRMATION      POTENTIAL_CHANGE      NaN   \n",
      "1   EXECUTION                  PROMISE                   NaN      NaN   \n",
      "2  DISCUSSION                  CONTENT  NOT_POTENTIAL_CHANGE      NaN   \n",
      "3   REQUESTED                  CONTENT              EXPLICIT      NaN   \n",
      "4    PROVIDED                REFERENCE      POTENTIAL_CHANGE      NaN   \n",
      "\n",
      "   date_column time_column  \n",
      "0   2013-04-09    09:30:00  \n",
      "1   2011-12-08    15:51:00  \n",
      "2   2011-12-08    15:51:00  \n",
      "3   2011-12-08    15:51:00  \n",
      "4   2016-03-09    15:05:00  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/slurm.221991/ipykernel_1370870/3188773764.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['comment_date'] = pd.to_datetime(df['comment_date'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                file_id                            comment_id  \\\n",
      "0  ed88fa24-1a89-44fb-9a66-c7f554d87f5d  ffc97358-69e6-48fb-aaf0-6a844e26f653   \n",
      "1  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
      "2  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
      "3  0c9c7a44-8bae-4bcf-a271-1b54ab0ef41e  ffa706dc-4877-492d-ac74-598d5f4d07c5   \n",
      "4  f5208894-9572-4cb8-b023-00b3c03cee89  ff533813-4050-424d-8e01-3c8dbb392f4d   \n",
      "\n",
      "               comment_date       anonymized_nickname  \\\n",
      "0 2013-04-09 00:00:00+00:00                    Editor   \n",
      "1 2011-12-08 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
      "2 2011-12-08 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
      "3 2011-12-08 00:00:00+00:00  Alicia R. Dalton-Tingler   \n",
      "4 2016-03-09 00:00:00+00:00            Alannah Kittle   \n",
      "\n",
      "                             document_paragraph_text document_selected_text  \\\n",
      "0  The experiments were carried out in a fluidize...                Unknown   \n",
      "1  In addition to the work mentioned above, the E...                Unknown   \n",
      "2  In addition to the work mentioned above, the E...                Unknown   \n",
      "3  In addition to the work mentioned above, the E...                Unknown   \n",
      "4                                            Unknown                Unknown   \n",
      "\n",
      "   document_selected_sentences  \\\n",
      "0                          1.0   \n",
      "1                          1.0   \n",
      "2                          1.0   \n",
      "3                          1.0   \n",
      "4                          1.0   \n",
      "\n",
      "                                   comment_full_text  \\\n",
      "0                                                Ok?   \n",
      "1  This has been discussed in the Executive Summa...   \n",
      "2  This has been discussed in the Executive Summa...   \n",
      "3  This has been discussed in the Executive Summa...   \n",
      "4    CODING\\n\\nCode qualitative data for WAVGUAGE03A   \n",
      "\n",
      "                               comment_sentence_text  is_sentence  ...  \\\n",
      "0                                                Ok?            0  ...   \n",
      "1  This has been discussed in the Executive Summa...            1  ...   \n",
      "2    It is, however, very out of place sitting here.            1  ...   \n",
      "3  This has been discussed in the Executive Summa...            0  ...   \n",
      "4    CODING\\n\\nCode qualitative data for WAVGUAGE03A            0  ...   \n",
      "\n",
      "   spelling_errors  tracked_changes  next_action               level_0  \\\n",
      "0              0.0              2.0         KEEP  INFORMATION EXCHANGE   \n",
      "1              0.0              1.0         KEEP          MODIFICATION   \n",
      "2              0.0              1.0         KEEP  SOCIAL COMMUNICATION   \n",
      "3              0.0              1.0         KEEP          MODIFICATION   \n",
      "4              0.0              0.0         KEEP  INFORMATION EXCHANGE   \n",
      "\n",
      "      level_1                  level_2               level_3  level_4  \\\n",
      "0   REQUESTED  REQUESTING_CONFIRMATION      POTENTIAL_CHANGE  Unknown   \n",
      "1   EXECUTION                  PROMISE               Unknown  Unknown   \n",
      "2  DISCUSSION                  CONTENT  NOT_POTENTIAL_CHANGE  Unknown   \n",
      "3   REQUESTED                  CONTENT              EXPLICIT  Unknown   \n",
      "4    PROVIDED                REFERENCE      POTENTIAL_CHANGE  Unknown   \n",
      "\n",
      "   date_column time_column  \n",
      "0   2013-04-09    00:00:00  \n",
      "1   2011-12-08    00:00:00  \n",
      "2   2011-12-08    00:00:00  \n",
      "3   2011-12-08    00:00:00  \n",
      "4   2016-03-09    00:00:00  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Standardize data formats and handle missing values\n",
    "df.fillna('Unknown', inplace=True)\n",
    "\n",
    "# Split the comment date and time into separate columns if not already done\n",
    "df['comment_date'] = pd.to_datetime(df['comment_date'])\n",
    "df['date_column'] = df['comment_date'].dt.date\n",
    "df['time_column'] = df['comment_date'].dt.time\n",
    "\n",
    "# Ensure no empty comments\n",
    "df = df[df['comment_full_text'].notna()]\n",
    "\n",
    "# Visualize the distribution of levels\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='level_0', data=df)\n",
    "plt.title('Distribution of Level 0 Comments')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='level_1', data=df)\n",
    "plt.title('Distribution of Level 1 Comments')\n",
    "plt.show()\n",
    "\n",
    "# Display the cleaned dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49c9cb-03e7-4d39-928a-f6dd2995c444",
   "metadata": {
    "tags": []
   },
   "source": [
    "Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0104f0-5d99-4cc7-87b8-c98b24367b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   level_0  level_1  level_2  level_3  level_4\n",
      "0        0        5        7        3        3\n",
      "1        1        2        5        4        3\n",
      "2        3        1        1        2        3\n",
      "3        1        5        1        0        3\n",
      "4        0        4        6        3        3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoders for each level\n",
    "label_encoders = {}\n",
    "for level in ['level_0', 'level_1', 'level_2', 'level_3', 'level_4']:\n",
    "    le = LabelEncoder()\n",
    "    df[level] = le.fit_transform(df[level].astype(str))\n",
    "    label_encoders[level] = le\n",
    "\n",
    "# Display the first few rows to verify encoding\n",
    "print(df[['level_0', 'level_1', 'level_2', 'level_3', 'level_4']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c0c2a-b342-4089-a411-12dc78f9cefb",
   "metadata": {},
   "source": [
    "splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3a7847-20ef-43e1-b153-7259ea300904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Comments Shape: (3992,)\n",
      "Validation Comments Shape: (999,)\n",
      "Train Labels Shape: (3992, 5)\n",
      "Validation Labels Shape: (999, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare Data\n",
    "comments = df['comment_full_text'].values\n",
    "labels = df[['level_0', 'level_1', 'level_2', 'level_3', 'level_4']].values\n",
    "\n",
    "# Split Data\n",
    "train_comments, val_comments, train_labels, val_labels = train_test_split(comments, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting arrays to verify the split\n",
    "print(f\"Train Comments Shape: {train_comments.shape}\")\n",
    "print(f\"Validation Comments Shape: {val_comments.shape}\")\n",
    "print(f\"Train Labels Shape: {train_labels.shape}\")\n",
    "print(f\"Validation Labels Shape: {val_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e7a74-264a-428c-a752-629522eeb832",
   "metadata": {},
   "source": [
    "Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a969bde5-53d1-4ea2-9132-cf57cc4ffda2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comment_text': ['To apply the correct style to this heading, indent it 0.5 in., use sentence case and bold, italic type. The heading ends with a period, and the text follows the period, on the same line as the heading title.', 'Im not following this sentence.  Because EISPC formed, DOE concurred with what study notion?', 'Walked how?', 'Delete if this is not a QAPP addendum.', 'Data should be handled confidentially. As long as it is necessary to be able to trace data to an individual subject, a subject identification code list can be used to link the data to the subject. The code should not be based on the patient initials and birth-date. \\n\\nThe key to the code should be safeguarded by the investigator or an independent person/committee (e.g. notary) in case the data or human material is kept for a longer period of time(see also the code of proper use: www.federa.org). \\n\\nThe handling of personal data should comply with the EU General Data Protection Regulation and the Dutch Act on Implementation of the General Data Protection Regulation. (in Dutch: Uitvoeringswet AVG, UAVG).', 'In my opinion, scout cars should run with 4 wheels (versus 3 + guide pin). Beyond tradition, the rationale for 4 wheels is that it ensures the car will stay on the track and not slide off the center rail and collide with another car. Of course, pin guides would address this, but then we would need some rules and guidelines around something that isnt even provided in the kit. Requiring the 4 wheels is easier.', 'This clause is mainly for customer comfort. \\xa0*\\xa0  This clause could lead to disputes about the scope of the work.', 'Inadequate slope coverage is a significant issue when wildfires occur. Does the ERS Workgroup want to mention coverage for post-fire events in this Plan?', 'In general, educational records are protected by FERPA, not HIPAA. There may be narrow circumstances where HIPAA applies. Counties should consult their attorneys to ensure appropriate treatment of all records. \\n\\nSee Joint Guidance, U.S. Departments of Education and Health and Human Services, Application of the Family Educational Rights and Privacy Act (FERPA) And the Health Insurance Portability and Accountability Act of 1996 (HIPAA) To Student Health Records available at \\nhttps://www2.ed.gov/policy/gen/guid/fpco/doc/ferpa-hipaa-guidance.pdf', 'Where is the output of this evaluation? What are INFNs recommendations concerning the use of Liferay social office and sync in this context?', 'Consider that this may create quite a burden on the Commission if this is undertaken annually and particularly if the risk-based approach is not clearly defined.  ISSF considers that it is important to not only continue to prioritize the obligations to be assessed, but to also clarify why these obligations have been selected.\\n\\nISSF reiterates its previous suggestion to develop criteria that identifies the highest priority CMMs based on a risk assessment of the impact of non-compliance on meeting the WCPF Convention objectives. \\nFor example: \\nCMMs with catch or effort limits. Non-compliance with such CMMs would undermine the conservation and management of the resource, which would have impacts on economic development opportunities and food security for coastal States; \\nCMMs with closed areas or prohibitions (e.g., FAD temporal/spatial closures; at-sea transshipment for purse seine vessels; shark finning, retention of certain shark species or whale shark encirclement); \\nCCMs with specific procedures that are pre-requisites to allowing a particular activity (i.e., at-sea transshipment for longline, troll and other vessels); \\nCCMs or decisions for data reporting, both for target and non-target species, including observer coverage requirements. Non-compliance with such CMMs would undermine the ability of the Commission to conduct stock assessments or other analyses, which would increase uncertainties in the scientific advice available to the Commission; and \\nCMMs that have provisions where differing interpretations are impacting effective implementation of the CMM itself, and therefore could impact the conservation and management of the stock.\\n\\nFinally, the current CMS CMM requires that successive instances of non-compliance triggers the escalation of the response to the non-compliance. But, it is not clear how these obligations would trigger this response if the obligation was assessed only every two or three years. Moreover, the delayed assessment provides a protracted period during which the non-compliance could continue. One approach may be that for lower prioritized obligations that are only assessed periodically, any non- compliance is automatically escalated to the second-tier response and re-assessed for that CCM the following year.', 'Name and address at top shows that you are a real person with real interest in the subject of the letter. Postal code shows that you are part of the said constituency.', \"In dmp we tend to avoid the word imitation to distinguish between imitating: copying the others exact movements and mirroring: picking up the others movements and his/her emotional state and motives. Thats why I put out the word imitation;. I hope you dont mind....Other than that the footnote sounds complete and very informative. Thank you very much for this!!!!\\n\\nS.D  but we need something to contrast your term 'mirroring' with a more classical therapeutic version (i.e. basically imitating.) - I.e we are not referring here to your use of the term Your term encompasses this and more  which is the focus of the footnote. what do you think?\", 'DBUTEZ VOTRE TEXTE ICI. \\n\\nNOTE\\xa0: NOUBLIEZ PAS DAPPUYER DEUX FOIS SUR LA TOUCHE \\xa0ENTRE\\xa0 ENTRE CHACUN DES PARAGRAPHES (TOUCHE \\xa0ENTER\\xa0 SUR LE CLAVIER ANGLAI8)\\n\\nRESPECTEZ CETTE EXIGENCE PARTOUT DANS LE GABARIT', 'FILLED IN COPIES OF FORM AP3 ARE NOT TO BE INCLUDED WITHIN THE CONFORMED BOOKS FOR AWARD.  THE FILLED IN FORM IS TO BE ATTACHED TO THE AWARD PACKAGE.', '1 line spacing is set.\\nThe abbreviation is bold, whereas the description is not.', 'not sure what to do with this, could be appropriate for Regent, Treasurer, Scribe Manuals, or perhaps made a Vice Regent task!', 'it is actually our language :) but i am crossing it out anyway', 'Deleted:re', 'Inserted: ,', 'We want and need contradiction, we want a plurality of approaches methods and models .\\nWe want to support emerging ideas, partnerships, innovation, and leadership.\\nWe are viral / enthusiasts\\nPromoting connections between people who use services, bottom up not top down', 'I think that ideally you would put the patient communication bit a little higher up. Did youhave any posters in clinic? Presumably there was quite aot of discussion between clinicians and patients also?', 'This paragraph is basically repeating comments made in analysis above. If this is your final Conclusion, you need to summarise what you have found out, making reference to your original research question. You also need to comment on your lit review- did the authors you read up on agree with you or not? Explain the reasons for your findings where possible.\\nYour completed Conclusion would normally be at least a couple of pages long', 'BOOK', 'Project(s with cost estimates of less than $100,000, are not required to submit Performance  Bond,.  Delete the pages from the book..  Also update indexes and table of contents.', 'This version of the roadmap is a significant improvement from previous versions. The USG would like to thank the Secretariat and the expert group for its good work and we look forward to participating in future efforts on this paper.', 'Please replace with function of the HDL-containing fraction of plasma for easier reading', 'I.e. Acts 20:35 (In all things I have shown you that by working hard in this way we must help the weak and remember the words of the Lord Jesus, how he himself said, it is more blessed to give than to receive; ESV).', 'Minta Rizal tambah.', 'The low barrier shelter should have a General Conduct section.  These provisions are just samples and should be tailored to each low barrier shelter.', 'Probably need a short definition between parenthesis', 'We dont mail ExComm meeting notices, we publish them in M-Pathy. We cant really include the minutes with M-Pathy so this is a better solution.'], 'input_ids': tensor([[ 101, 2000, 6611,  ...,    0,    0,    0],\n",
      "        [ 101, 1045, 1521,  ...,    0,    0,    0],\n",
      "        [ 101, 2939, 2129,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1996, 2659,  ...,    0,    0,    0],\n",
      "        [ 101, 2763, 2342,  ...,    0,    0,    0],\n",
      "        [ 101, 2057, 2123,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1, 5, 4, 0, 1],\n",
      "        [0, 4, 2, 2, 3],\n",
      "        [0, 5, 0, 2, 3],\n",
      "        [1, 5, 1, 0, 2],\n",
      "        [0, 4, 2, 2, 3],\n",
      "        [1, 5, 1, 2, 3],\n",
      "        [0, 4, 2, 3, 3],\n",
      "        [0, 4, 2, 2, 3],\n",
      "        [0, 4, 6, 3, 3],\n",
      "        [0, 5, 0, 3, 3],\n",
      "        [0, 4, 2, 2, 3],\n",
      "        [0, 4, 2, 3, 3],\n",
      "        [0, 5, 0, 2, 3],\n",
      "        [2, 6, 9, 4, 3],\n",
      "        [0, 4, 2, 2, 3],\n",
      "        [1, 5, 4, 1, 1],\n",
      "        [3, 3, 1, 3, 3],\n",
      "        [3, 1, 1, 3, 3],\n",
      "        [1, 2, 3, 4, 3],\n",
      "        [1, 2, 3, 4, 3],\n",
      "        [1, 5, 1, 0, 0],\n",
      "        [0, 5, 7, 3, 3],\n",
      "        [0, 5, 0, 3, 3],\n",
      "        [2, 6, 9, 4, 3],\n",
      "        [1, 5, 1, 0, 1],\n",
      "        [3, 3, 8, 2, 3],\n",
      "        [1, 5, 1, 0, 1],\n",
      "        [2, 6, 9, 4, 3],\n",
      "        [2, 6, 9, 4, 3],\n",
      "        [1, 5, 1, 0, 0],\n",
      "        [1, 5, 1, 0, 0],\n",
      "        [3, 1, 1, 3, 3]])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "class CommentsDataset(Dataset):\n",
    "    def __init__(self, comments, labels, tokenizer, max_len):\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        comment = self.comments[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'comment_text': comment,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Create Dataset Instances\n",
    "train_dataset = CommentsDataset(comments=train_comments, labels=train_labels, tokenizer=tokenizer, max_len=128)\n",
    "val_dataset = CommentsDataset(comments=val_comments, labels=val_labels, tokenizer=tokenizer, max_len=128)\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print a batch of data to verify\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5aa56-0796-4ff0-bebc-15b62cc61f4c",
   "metadata": {},
   "source": [
    "Define the capsule layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d47a828-a8ea-40b6-a0bb-2e332b70bf1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "class HierarchicalCapsuleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HierarchicalCapsuleNetwork, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=768, in_channels=768, out_channels=16)\n",
    "        self.fc = nn.Linear(16 * 10 * 128, 5)  # Adjusting for sequence length and output channels\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e543e574-3a90-4b94-8b78-b162bc589a1f",
   "metadata": {},
   "source": [
    "Initialize the model, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f44aad4-27bf-4d23-975f-82119e8a4c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, num_routes, in_channels, out_channels):\n",
    "        super(CapsuleLayer, self).__init__()\n",
    "        self.num_capsules = num_capsules\n",
    "        self.num_routes = num_routes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Linear(in_channels, out_channels)\n",
    "            for _ in range(num_capsules)\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        u = [capsule(x).unsqueeze(2) for capsule in self.capsules]\n",
    "        u = torch.cat(u, dim=2)\n",
    "        u = u.view(x.size(0), self.num_capsules, -1)\n",
    "        return self.squash(u)\n",
    "    def squash(self, x, dim=-1):\n",
    "        squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        return scale * x / torch.sqrt(squared_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15425ee2-9ee8-44de-8029-7fa910a4dee8",
   "metadata": {},
   "source": [
    "Define the Hierarchical Capsule Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab1303d-0183-4a9c-94a4-a102bce1186b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "class HierarchicalCapsuleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HierarchicalCapsuleNetwork, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=768, in_channels=768, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.batch_norm = nn.BatchNorm1d(16 * 10 * 128)\n",
    "        self.fc = nn.Linear(16 * 10 * 128, 5)  # Adjusting for sequence length and output channels\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ccbae-0942-4a6a-a8a9-931c66aae6cc",
   "metadata": {},
   "source": [
    "Initialize the model, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd1241e-4736-4458-8737-524196b673cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HierarchicalCapsuleNetwork().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Change to BCEWithLogitsLoss for multi-label classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "class HierarchicalCapsuleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HierarchicalCapsuleNetwork, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=768, in_channels=768, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(16 * 10 * 128, 5)  # Adjusting for sequence length and output channels\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HierarchicalCapsuleNetwork().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Correct loss for multi-label classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd5251-fc4f-4616-80ed-618c238a33db",
   "metadata": {},
   "source": [
    "Training the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f937dcbb-b5f1-4831-91ee-0e66da1440a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs: tensor([[-0.0019,  0.0200,  0.0128,  0.0144,  0.0145],\n",
      "        [ 0.0077,  0.0491, -0.0031, -0.0111, -0.0019],\n",
      "        [ 0.0306,  0.0252, -0.0131,  0.0061, -0.0171],\n",
      "        [ 0.0150,  0.0275,  0.0013,  0.0053, -0.0069],\n",
      "        [-0.0067,  0.0394, -0.0062, -0.0089, -0.0215]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Labels: tensor([[0., 4., 2., 3., 3.],\n",
      "        [2., 6., 9., 4., 3.],\n",
      "        [1., 5., 1., 0., 0.],\n",
      "        [1., 5., 1., 0., 0.],\n",
      "        [0., 4., 6., 3., 3.]], device='cuda:0')\n",
      "Epoch 1, Train Loss: -0.3510, Val Loss: -1.5249\n",
      "Epoch 2, Train Loss: -2.3483, Val Loss: -3.4552\n",
      "Epoch 3, Train Loss: -3.9962, Val Loss: -5.0687\n",
      "Epoch 4, Train Loss: -5.5069, Val Loss: -6.6438\n",
      "Epoch 5, Train Loss: -6.9950, Val Loss: -8.2171\n",
      "Epoch 6, Train Loss: -8.4932, Val Loss: -9.8031\n",
      "Epoch 7, Train Loss: -10.0104, Val Loss: -11.4092\n",
      "Epoch 8, Train Loss: -11.5423, Val Loss: -13.0438\n",
      "Epoch 9, Train Loss: -13.0935, Val Loss: -14.6899\n",
      "Epoch 10, Train Loss: -14.6620, Val Loss: -16.3469\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).float()  # Ensure labels are float for BCEWithLogitsLoss\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Check the range of outputs and labels\n",
    "        if epoch == 0 and batch_idx == 0:  # Only print for the first batch of the first epoch\n",
    "            print(f\"Outputs: {outputs[:5]}\")  # Print first 5 outputs for inspection\n",
    "            print(f\"Labels: {labels[:5]}\")  # Print first 5 labels for inspection\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Validation Loop\n",
    "def eval_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).float()  # Ensure labels are float for BCEWithLogitsLoss\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Training and Evaluation\n",
    "num_epochs = 10  # Adjust the number of epochs as needed\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    val_loss = eval_model(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0e34a-5ef7-47c0-86b6-5b5527ed81f7",
   "metadata": {},
   "source": [
    "Since the training loss is in negative values below is the updated code from data preprocesing to training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7da467-f132-4343-8858-3b426a2d359b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/slurm.221991/ipykernel_1370870/4230267556.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['comment_date'] = pd.to_datetime(df['comment_date'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.5590, Val Loss: 0.4585\n",
      "Epoch 2, Train Loss: 0.4226, Val Loss: 0.3928\n",
      "Epoch 3, Train Loss: 0.3806, Val Loss: 0.3635\n",
      "Epoch 4, Train Loss: 0.3476, Val Loss: 0.3370\n",
      "Epoch 5, Train Loss: 0.3172, Val Loss: 0.3229\n",
      "Epoch 6, Train Loss: 0.2951, Val Loss: 0.3113\n",
      "Epoch 7, Train Loss: 0.2809, Val Loss: 0.3056\n",
      "Epoch 8, Train Loss: 0.2666, Val Loss: 0.2949\n",
      "Epoch 9, Train Loss: 0.2537, Val Loss: 0.2869\n",
      "Epoch 10, Train Loss: 0.2407, Val Loss: 0.2801\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "df.fillna('Unknown', inplace=True)\n",
    "df['comment_date'] = pd.to_datetime(df['comment_date'])\n",
    "df['date_column'] = df['comment_date'].dt.date\n",
    "df['time_column'] = df['comment_date'].dt.time\n",
    "df = df[df['comment_full_text'].notna()]\n",
    "\n",
    "# Visualize the distribution of levels\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='level_0', data=df)\n",
    "plt.title('Distribution of Level 0 Comments')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='level_1', data=df)\n",
    "plt.title('Distribution of Level 1 Comments')\n",
    "plt.show()\n",
    "\n",
    "# Encode labels\n",
    "labels_combined = df[['level_0', 'level_1', 'level_2', 'level_3', 'level_4']].values\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_encoded = mlb.fit_transform(labels_combined)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "comments = df['comment_full_text'].values\n",
    "train_comments, val_comments, train_labels, val_labels = train_test_split(comments, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create dataset class\n",
    "class CommentsDataset(Dataset):\n",
    "    def __init__(self, comments, labels, tokenizer, max_len):\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        comment = self.comments[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'comment_text': comment,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Load tokenizer and create data loaders\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "train_dataset = CommentsDataset(comments=train_comments, labels=train_labels, tokenizer=tokenizer, max_len=128)\n",
    "val_dataset = CommentsDataset(comments=val_comments, labels=val_labels, tokenizer=tokenizer, max_len=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define capsule layer\n",
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, num_routes, in_channels, out_channels):\n",
    "        super(CapsuleLayer, self).__init__()\n",
    "        self.num_capsules = num_capsules\n",
    "        self.num_routes = num_routes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.capsules = nn.ModuleList([nn.Linear(in_channels, out_channels) for _ in range(num_capsules)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        u = [capsule(x).unsqueeze(2) for capsule in self.capsules]\n",
    "        u = torch.cat(u, dim=2)\n",
    "        u = u.view(x.size(0), self.num_capsules, -1)\n",
    "        return self.squash(u)\n",
    "    \n",
    "    def squash(self, x, dim=-1):\n",
    "        squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        return scale * x / torch.sqrt(squared_norm)\n",
    "\n",
    "# Define hierarchical capsule network\n",
    "class HierarchicalCapsuleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HierarchicalCapsuleNetwork, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=768, in_channels=768, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(16 * 10 * 128, labels_encoded.shape[1])  # Adjusting for sequence length and output channels\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HierarchicalCapsuleNetwork().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Correct loss for multi-label classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).float()  # Ensure labels are float for BCEWithLogitsLoss\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def eval_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).float()  # Ensure labels are float for BCEWithLogitsLoss\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Adjust the number of epochs as needed\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = eval_model(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad3a9f-149a-4599-a290-129e34af2cb3",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b31b95e-2671-48a1-8def-468cae7d3258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = \"hierarchical_capsule_network.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b641736-5565-49f4-b43c-4c40ac9627f8",
   "metadata": {},
   "source": [
    "Loading the model if needed later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de6704b-82e3-43ef-9bc0-1507320689b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierarchicalCapsuleNetwork(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (capsule_layer): CapsuleLayer(\n",
       "    (capsules): ModuleList(\n",
       "      (0-9): 10 x Linear(in_features=768, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=20480, out_features=27, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = HierarchicalCapsuleNetwork()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372503d-a772-450a-8d55-5cd5a3bafe7b",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a2ee60b-7b97-43a4-b724-116e3e7f4adc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1181, Precision: 0.2662, Recall: 0.2418, F1-Score: 0.2476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Add this import statement\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.sigmoid(outputs) > 0.5  # Apply sigmoid and threshold\n",
    "            \n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, val_loader, device)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0876f6-9185-4b8d-9764-f542f28d332c",
   "metadata": {},
   "source": [
    "\n",
    "The evaluation metrics indicate that while your model is learning, there is still room for improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791302d-6164-4e8b-83eb-bdc40a15143c",
   "metadata": {},
   "source": [
    "Learning Rate Scheduling and Model Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "967247a6-23c4-407f-aa39-62811a6b0fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.2311, Val Loss: 0.2801\n",
      "Epoch 2, Train Loss: 0.2309, Val Loss: 0.2801\n",
      "Epoch 3, Train Loss: 0.2307, Val Loss: 0.2801\n",
      "Epoch 4, Train Loss: 0.2309, Val Loss: 0.2801\n",
      "Epoch 5, Train Loss: 0.2310, Val Loss: 0.2801\n",
      "Epoch 6, Train Loss: 0.2310, Val Loss: 0.2801\n",
      "Epoch 7, Train Loss: 0.2310, Val Loss: 0.2801\n",
      "Epoch 8, Train Loss: 0.2310, Val Loss: 0.2801\n",
      "Epoch 9, Train Loss: 0.2308, Val Loss: 0.2801\n",
      "Epoch 10, Train Loss: 0.2312, Val Loss: 0.2801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Define the number of training steps\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Training Loop with Scheduler and Checkpointing\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = eval_model(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0ab30-33b6-4be7-8958-6a70f2121e2e",
   "metadata": {},
   "source": [
    "The training and validation loss values indicate that the model has reached a plateau and is not improving further. This suggests that the current model configuration might not be sufficient to achieve better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd819047-e796-4223-acaf-b390a9827994",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54b0eb83-1973-4e0b-ae14-567d8de5fce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optuna in ./.local/lib/python3.11/site-packages (3.6.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./.local/lib/python3.11/site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: colorlog in ./.local/lib/python3.11/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in ./.local/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in ./.local/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c1c05b2-850c-40b2-a2f7-52ba62b5dd92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-30 15:45:08,891] A new study created in memory with name: no-name-9652bdfb-560f-4f69-b1ee-c53175120571\n",
      "[I 2024-06-30 15:45:47,520] Trial 0 finished with value: 0.44459265656769276 and parameters: {'learning_rate': 1.4509973328781145e-05, 'batch_size': 63, 'dropout_rate': 0.2658801745991122}. Best is trial 0 with value: 0.44459265656769276.\n",
      "[I 2024-06-30 15:46:28,497] Trial 1 finished with value: 0.33044921278953554 and parameters: {'learning_rate': 3.748730662882497e-05, 'batch_size': 41, 'dropout_rate': 0.44908440335618083}. Best is trial 1 with value: 0.33044921278953554.\n",
      "[I 2024-06-30 15:47:09,027] Trial 2 finished with value: 0.32570428333499213 and parameters: {'learning_rate': 4.581994455767256e-05, 'batch_size': 46, 'dropout_rate': 0.3387384881868761}. Best is trial 2 with value: 0.32570428333499213.\n",
      "[I 2024-06-30 15:47:48,588] Trial 3 finished with value: 0.3184753850102425 and parameters: {'learning_rate': 4.9973083978834355e-05, 'batch_size': 52, 'dropout_rate': 0.10191181263578036}. Best is trial 3 with value: 0.3184753850102425.\n",
      "[I 2024-06-30 15:48:28,251] Trial 4 finished with value: 0.38388387858867645 and parameters: {'learning_rate': 2.4617514617180966e-05, 'batch_size': 57, 'dropout_rate': 0.12257539597512435}. Best is trial 3 with value: 0.3184753850102425.\n",
      "[I 2024-06-30 15:49:09,820] Trial 5 finished with value: 0.3335855808109045 and parameters: {'learning_rate': 2.8250968953503488e-05, 'batch_size': 32, 'dropout_rate': 0.35141146418141855}. Best is trial 3 with value: 0.3184753850102425.\n",
      "[I 2024-06-30 15:49:54,131] Trial 6 finished with value: 0.27802348633607227 and parameters: {'learning_rate': 4.32271222637411e-05, 'batch_size': 16, 'dropout_rate': 0.3830604743575037}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:50:33,370] Trial 7 finished with value: 0.35803029070729797 and parameters: {'learning_rate': 2.874861581483952e-05, 'batch_size': 45, 'dropout_rate': 0.49167401511995623}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:51:13,384] Trial 8 finished with value: 0.32555670323579206 and parameters: {'learning_rate': 4.500339915681626e-05, 'batch_size': 44, 'dropout_rate': 0.39938282093756794}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:51:54,586] Trial 9 finished with value: 0.3194040384362726 and parameters: {'learning_rate': 3.4669785319456216e-05, 'batch_size': 30, 'dropout_rate': 0.3082994998208545}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:52:37,970] Trial 10 finished with value: 0.2901858571222273 and parameters: {'learning_rate': 3.86212342711828e-05, 'batch_size': 17, 'dropout_rate': 0.23133226372608012}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:53:22,102] Trial 11 finished with value: 0.2832288207515838 and parameters: {'learning_rate': 3.79299333549846e-05, 'batch_size': 16, 'dropout_rate': 0.17924166159008242}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:54:04,157] Trial 12 finished with value: 0.2871520274451801 and parameters: {'learning_rate': 4.1015127892437864e-05, 'batch_size': 18, 'dropout_rate': 0.17338025480046418}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:54:46,127] Trial 13 finished with value: 0.33675109371542933 and parameters: {'learning_rate': 2.0263085120984607e-05, 'batch_size': 25, 'dropout_rate': 0.2148216235983862}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:55:28,143] Trial 14 finished with value: 0.3138455488742926 and parameters: {'learning_rate': 3.497952253407813e-05, 'batch_size': 26, 'dropout_rate': 0.4092643509580093}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:56:12,293] Trial 15 finished with value: 0.28094924205825444 and parameters: {'learning_rate': 4.379631865944939e-05, 'batch_size': 16, 'dropout_rate': 0.17427570520153485}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:56:52,629] Trial 16 finished with value: 0.31198817388764744 and parameters: {'learning_rate': 4.899995429834679e-05, 'batch_size': 35, 'dropout_rate': 0.28047530590606096}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:57:34,467] Trial 17 finished with value: 0.2945745635939681 and parameters: {'learning_rate': 4.2627102527071194e-05, 'batch_size': 22, 'dropout_rate': 0.38062268116123643}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:58:17,350] Trial 18 finished with value: 0.3837150450457226 and parameters: {'learning_rate': 1.1111409150514138e-05, 'batch_size': 23, 'dropout_rate': 0.15244143585938394}. Best is trial 6 with value: 0.27802348633607227.\n",
      "[I 2024-06-30 15:58:57,771] Trial 19 finished with value: 0.3293055367880854 and parameters: {'learning_rate': 3.2178387236031295e-05, 'batch_size': 35, 'dropout_rate': 0.2361456300316586}. Best is trial 6 with value: 0.27802348633607227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 4.32271222637411e-05, 'batch_size': 16, 'dropout_rate': 0.3830604743575037}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "\n",
    "    # Create model with suggested hyperparameters\n",
    "    class HierarchicalCapsuleNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(HierarchicalCapsuleNetwork, self).__init__()\n",
    "            self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "            self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=768, in_channels=768, out_channels=16)\n",
    "            self.dropout = nn.Dropout(p=dropout_rate)\n",
    "            self.fc = nn.Linear(16 * 10 * 128, labels_encoded.shape[1])\n",
    "\n",
    "        def forward(self, input_ids, attention_mask):\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            x = outputs.last_hidden_state\n",
    "            x = self.capsule_layer(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.dropout(x)\n",
    "            logits = self.fc(x)\n",
    "            return logits\n",
    "\n",
    "    model = HierarchicalCapsuleNetwork().to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Train the model for a few epochs\n",
    "    num_epochs = 3\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = eval_model(model, val_loader, criterion, device)\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "# Create a study and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289800e1-60b5-404e-874a-48a4fed8276e",
   "metadata": {},
   "source": [
    "Implementing the Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18324ea6-3207-4153-b32e-666e74942966",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.4362, Val Loss: 0.3551\n",
      "Epoch 2, Train Loss: 0.3235, Val Loss: 0.3091\n",
      "Epoch 3, Train Loss: 0.2756, Val Loss: 0.2832\n",
      "Epoch 4, Train Loss: 0.2413, Val Loss: 0.2686\n",
      "Epoch 5, Train Loss: 0.2208, Val Loss: 0.2565\n",
      "Epoch 6, Train Loss: 0.2054, Val Loss: 0.2505\n",
      "Epoch 7, Train Loss: 0.1935, Val Loss: 0.2458\n",
      "Epoch 8, Train Loss: 0.1840, Val Loss: 0.2486\n",
      "Epoch 9, Train Loss: 0.1756, Val Loss: 0.2481\n",
      "Epoch 10, Train Loss: 0.1694, Val Loss: 0.2493\n",
      "Accuracy: 0.2052, Precision: 0.4115, Recall: 0.3510, F1-Score: 0.3621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Using the best hyperparameters from Optuna\n",
    "best_learning_rate = 4.2924087428836385e-05\n",
    "best_batch_size = 18\n",
    "best_dropout_rate = 0.1054314957225924\n",
    "\n",
    "# Create model with the best hyperparameters\n",
    "class HierarchicalCapsuleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HierarchicalCapsuleNetwork, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=768, in_channels=768, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=best_dropout_rate)\n",
    "        self.fc = nn.Linear(16 * 10 * 128, labels_encoded.shape[1])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "model = HierarchicalCapsuleNetwork().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_batch_size, shuffle=False)\n",
    "\n",
    "# Define the number of training steps\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Training Loop with Scheduler and Checkpointing\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = eval_model(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_final.pth')\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model_final.pth'))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, val_loader, device)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85198d1a-2d7b-4710-8401-a5501f09c881",
   "metadata": {},
   "source": [
    "The results show significant improvement compared to the initial training. Here's a breakdown of the output:\n",
    "\n",
    "Results\n",
    "Train Loss: The training loss steadily decreases, indicating that the model is learning well.\n",
    "Validation Loss: The validation loss also decreases, reaching a minimum value of 0.2474.\n",
    "Metrics:\n",
    "Accuracy: 0.2052, Precision: 0.4115, Recall: 0.3510, F1-Score: 0.3621\n",
    "Analysis\n",
    "The F1-Score and Precision have significantly improved, indicating the model's better performance in handling multi-label classification.\n",
    "The warning about precision and F-score being ill-defined suggests that there are some labels for which no samples were predicted. This could be due to an imbalance in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb03637-8488-4c86-bf8e-5a6ace1f26d9",
   "metadata": {},
   "source": [
    "To further improve the model, consider the following steps:\n",
    "\n",
    "Addressing Class Imbalance: Use techniques like class weighting or oversampling/undersampling to handle class imbalance.\n",
    "\n",
    "Hyperparameter Fine-Tuning: Further fine-tune the hyperparameters based on the current best settings.\n",
    "\n",
    "Model Architecture Improvements: Experiment with different model architectures or deeper models.\n",
    "\n",
    "Additional Regularization: Apply techniques like dropout, weight decay, or early stopping to prevent overfitting.\n",
    "\n",
    "Data Augmentation: Increase the size of your dataset using augmentation techniques to improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bcb35d-24c4-4c7b-98fa-20ce074e795e",
   "metadata": {},
   "source": [
    "Implementing Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d127264-3856-4a8b-a813-ba3c94192733",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/slurm.221991/ipykernel_1370870/3957727947.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  class_weights_tensor = torch.tensor([class_weights[i] for i in range(labels_encoded.shape[1])], dtype=torch.float).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.6964, Val Loss: 0.2454\n",
      "Epoch 2, Train Loss: 1.4995, Val Loss: 0.2460\n",
      "Epoch 3, Train Loss: 1.4119, Val Loss: 0.2495\n",
      "Epoch 4, Train Loss: 1.3558, Val Loss: 0.2465\n",
      "Epoch 5, Train Loss: 1.3076, Val Loss: 0.2509\n",
      "Epoch 6, Train Loss: 1.2710, Val Loss: 0.2496\n",
      "Epoch 7, Train Loss: 1.2366, Val Loss: 0.2507\n",
      "Epoch 8, Train Loss: 1.2130, Val Loss: 0.2623\n",
      "Epoch 9, Train Loss: 1.1831, Val Loss: 0.2627\n",
      "Epoch 10, Train Loss: 1.1655, Val Loss: 0.2627\n",
      "Accuracy: 0.2743, Precision: 0.4547, Recall: 0.3970, F1-Score: 0.4121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = {}\n",
    "for i in range(labels_encoded.shape[1]):\n",
    "    class_weights[i] = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels[:, i]), y=train_labels[:, i])\n",
    "\n",
    "class_weights_tensor = torch.tensor([class_weights[i] for i in range(labels_encoded.shape[1])], dtype=torch.float).to(device)\n",
    "\n",
    "# Update the training loop to use class weights\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device, class_weights):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).float()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Apply class weights\n",
    "        weighted_loss = (loss * class_weights).mean()\n",
    "        \n",
    "        weighted_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += weighted_loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Training Loop with Class Weights\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device, class_weights_tensor)\n",
    "    val_loss = eval_model(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights.pth')\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model_with_weights.pth'))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, val_loader, device)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c13245-f025-406f-9ba0-e921a8b2f449",
   "metadata": {},
   "source": [
    "Increasing Epochs and Adding Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4351dcd0-954d-49d7-8062-61527a68a160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.4922, Val Loss: 0.2496\n",
      "Epoch 2, Train Loss: 1.4140, Val Loss: 0.2464\n",
      "Epoch 3, Train Loss: 1.3618, Val Loss: 0.2443\n",
      "Epoch 4, Train Loss: 1.3159, Val Loss: 0.2492\n",
      "Epoch 5, Train Loss: 1.2888, Val Loss: 0.2575\n",
      "Epoch 6, Train Loss: 1.2646, Val Loss: 0.2577\n",
      "Epoch 7, Train Loss: 1.2392, Val Loss: 0.2570\n",
      "Epoch 8, Train Loss: 1.2098, Val Loss: 0.2610\n",
      "Early stopping triggered\n",
      "Accuracy: 0.2933, Precision: 0.5413, Recall: 0.4238, F1-Score: 0.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the number of training epochs\n",
    "num_epochs = 30  # Increased epochs\n",
    "patience = 5  # Early stopping patience\n",
    "\n",
    "# Training Loop with Early Stopping\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device, class_weights_tensor)\n",
    "    val_loss = eval_model(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights.pth')\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model_with_weights.pth'))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, val_loader, device)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f4231-f27a-4efa-adab-b38241ef9df8",
   "metadata": {},
   "source": [
    "Implementing Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beda75df-33bc-4142-8859-1c244cc0fb88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/spati/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/spati/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The quick brown fox jumps over the lazy dog\n",
      "Augmented: The quick brown fox jump over the lazy dog\n",
      "Epoch 1, Train Loss: 1.3633, Val Loss: 0.2496\n",
      "Epoch 2, Train Loss: 1.2872, Val Loss: 0.2506\n",
      "Epoch 3, Train Loss: 1.2484, Val Loss: 0.2638\n",
      "Epoch 4, Train Loss: 1.2173, Val Loss: 0.2570\n",
      "Epoch 5, Train Loss: 1.1922, Val Loss: 0.2581\n",
      "Epoch 6, Train Loss: 1.1552, Val Loss: 0.2717\n",
      "Early stopping triggered\n",
      "Accuracy: 0.3053, Precision: 0.5414, Recall: 0.4497, F1-Score: 0.4731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def synonym_replacement(sentence, n):\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))\n",
    "    random.shuffle(random_word_list)\n",
    "    \n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = wordnet.synsets(random_word)\n",
    "        if synonyms:\n",
    "            synonym = synonyms[0].lemmas()[0].name()\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:  # Only replace up to n words\n",
    "            break\n",
    "\n",
    "    sentence = ' '.join(new_words)\n",
    "    return sentence\n",
    "\n",
    "# Example usage\n",
    "original_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "augmented_sentence = synonym_replacement(original_sentence, 2)\n",
    "print(f\"Original: {original_sentence}\")\n",
    "print(f\"Augmented: {augmented_sentence}\")\n",
    "\n",
    "# Applying data augmentation to the dataset\n",
    "augmented_comments = [synonym_replacement(comment, 2) for comment in comments]\n",
    "\n",
    "# Split Data\n",
    "train_comments_aug, val_comments_aug, train_labels_aug, val_labels_aug = train_test_split(augmented_comments, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Dataset Instances\n",
    "train_dataset_aug = CommentsDataset(comments=train_comments_aug, labels=train_labels_aug, tokenizer=tokenizer, max_len=128)\n",
    "val_dataset_aug = CommentsDataset(comments=val_comments_aug, labels=val_labels_aug, tokenizer=tokenizer, max_len=128)\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=32, shuffle=True)\n",
    "val_loader_aug = DataLoader(val_dataset_aug, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training Loop with Early Stopping on Augmented Data\n",
    "best_val_loss_aug = float('inf')\n",
    "epochs_no_improve_aug = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_aug = train_epoch(model, train_loader_aug, criterion, optimizer, device, class_weights_tensor)\n",
    "    val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss_aug:.4f}, Val Loss: {val_loss_aug:.4f}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if val_loss_aug < best_val_loss_aug:\n",
    "        best_val_loss_aug = val_loss_aug\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights_aug.pth')\n",
    "        epochs_no_improve_aug = 0\n",
    "    else:\n",
    "        epochs_no_improve_aug += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_no_improve_aug >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model_with_weights_aug.pth'))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_aug, precision_aug, recall_aug, f1_aug = evaluate_model(model, val_loader_aug, device)\n",
    "print(f\"Accuracy: {accuracy_aug:.4f}, Precision: {precision_aug:.4f}, Recall: {recall_aug:.4f}, F1-Score: {f1_aug:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfc8fc-c242-45a1-bd87-182597a92d6f",
   "metadata": {},
   "source": [
    "Using BERT-large and Learning Rate Scheduling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00f64515-e221-4e1b-b611-b3f75aa8cbae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/slurm.221991/ipykernel_1370870/3454555749.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['comment_date'] = pd.to_datetime(df['comment_date'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/YAAAIhCAYAAADkVCF3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABSAklEQVR4nO3deVgVdf//8dcRBETgyCIgimblmqSl5Za5i+SadruVe1p3ZpGapm3W3VezMltM875TtHK7KzXLsiiXNLXMwi3X0tRbcEVwBcXP748u5ufhAAKCMPV8XNe5Ls5n3jPzmTkz55wXsxyHMcYIAAAAAADYUqni7gAAAAAAACg4gj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AoMBmz54th8NhPXx8fBQeHq6WLVtq4sSJOnr0qNs448ePl8PhyNd8zp07p/Hjx2vVqlX5Gi+7ed1www3q2LFjvqZzNfPmzdMbb7yR7TCHw6Hx48cX6vwK27fffqsGDRqobNmycjgcWrJkSbZ1+/fvl8Ph0GuvvXZ9O5hHLVq0UIsWLfJU+/PPP6tNmzby8/NTuXLl1K1bN/3+++95nldaWpqmTp2qu+66S4GBgfLy8lLFihXVo0cPrV69uoBL8NczYcKEHLcnAEDhIdgDAK5ZXFyc1q9fr/j4eL3zzjuqV6+eJk2apFq1aumbb75xqX3wwQe1fv36fE3/3LlzeuGFF/Id7Asyr4LILdivX79eDz74YJH3oaCMMerRo4dKly6tpUuXav369WrevHlxd6tI7dy5Uy1atFB6err++9//atasWdq9e7eaNWumY8eOXXX848ePq2nTphoxYoTq1Kmj2bNn69tvv9XkyZPl4eGh1q1ba/PmzddhSUo+gj0AXB+exd0BAID91alTRw0aNLCed+/eXU888YTuuusudevWTXv27FFYWJgkqVKlSqpUqVKR9ufcuXPy9fW9LvO6mkaNGhXr/K/m8OHDOnnypO699161bt26uLtzXTz33HPy9vbW559/roCAAElS/fr1Va1aNb322muaNGlSruP369dPmzdv1ldffaVWrVq5DOvVq5dGjBihwMDAIus/AABZccQeAFAkKleurMmTJ+v06dOaMWOG1Z7d6fErVqxQixYtFBwcrDJlyqhy5crq3r27zp07p/3796t8+fKSpBdeeME67X/AgAEu0/v555913333KTAwUDfddFOO88q0ePFi3XrrrfLx8dGNN96ot956y2V45mUG+/fvd2lftWqVHA6HdfZAixYttGzZMv3xxx8ulyVkyu5U/G3btqlLly4KDAyUj4+P6tWrpzlz5mQ7n/nz5+vpp59WRESEAgIC1KZNG+3atSvnFX+FtWvXqnXr1vL395evr6+aNGmiZcuWWcPHjx9v/eNjzJgxcjgcuuGGG/I07dykpqZq1KhRqlq1qnWKemxsrM6ePWvV3HbbbWrWrJnbuBkZGapYsaK6detmtaWnp+ull15SzZo15e3trfLly2vgwIF5Orqe1aVLl/T555+re/fuVqiXpCpVqqhly5ZavHhxruNv2rRJX375pQYPHuwW6jPdcccdqly5svU8P6/3vHnzNGbMGFWoUEF+fn7q1KmTjhw5otOnT2vo0KEKCQlRSEiIBg4cqDNnzrhMw+Fw6NFHH1VcXJxq1KihMmXKqEGDBtqwYYOMMXr11VdVtWpV+fn5qVWrVtq7d69b37/55hu1bt1aAQEB8vX1VdOmTfXtt9+61GTuV9u3b1fv3r3ldDoVFhamQYMGKSUlxaU/Z8+e1Zw5c6z9IvNSiXPnzlnbiI+Pj4KCgtSgQQPNnz8/1/UPAMgeR+wBAEXmnnvukYeHh7777rsca/bv368OHTqoWbNmmjVrlsqVK6f//e9/Wr58udLT01WhQgUtX75c7du31+DBg63T2jPDfqZu3bqpV69eevjhh10CZHYSEhIUGxur8ePHKzw8XHPnztXjjz+u9PR0jRo1Kl/LOG3aNA0dOlS//fbbVUOhJO3atUtNmjRRaGio3nrrLQUHB+vDDz/UgAEDdOTIEY0ePdqlfty4cWratKnee+89paamasyYMerUqZN27NghDw+PHOezevVqtW3bVrfeeqtmzpwpb29vTZs2TZ06ddL8+fPVs2dPPfjgg6pbt666deum4cOHq0+fPvL29s7X8md17tw5NW/eXIcOHdK4ceN06623avv27Xruuee0detWffPNN3I4HBo4cKAef/xx7dmzR9WqVbPG//rrr3X48GENHDhQknT58mV16dJFa9as0ejRo9WkSRP98ccfev7559WiRQv99NNPKlOmTJ7799tvv+n8+fO69dZb3Ybdeuutio+P14ULF+Tj45Pt+F9//bUkqWvXrnmaX0Fe75YtW2r27Nnav3+/Ro0apd69e8vT01N169bV/Pnz9csvv2jcuHHy9/d3+4fU559/rl9++UUvv/yyHA6HxowZow4dOqh///76/fffNXXqVKWkpGjEiBHq3r27EhISrH9Effjhh+rXr5+6dOmiOXPmqHTp0poxY4aio6P11VdfuZ3R0b17d/Xs2VODBw/W1q1bNXbsWEnSrFmzJP15GUqrVq3UsmVLPfvss5Jk/TNlxIgR+uCDD/TSSy/ptttu09mzZ7Vt2zadOHEiT+sVAJCFAQCggOLi4owks3HjxhxrwsLCTK1ataznzz//vLny4+fjjz82kkxCQkKO0zh27JiRZJ5//nm3YZnTe+6553IcdqUqVaoYh8PhNr+2bduagIAAc/bsWZdl27dvn0vdypUrjSSzcuVKq61Dhw6mSpUq2fY9a7979eplvL29zYEDB1zqYmJijK+vrzl16pTLfO655x6Xuv/+979Gklm/fn2288vUqFEjExoaak6fPm21Xbp0ydSpU8dUqlTJXL582RhjzL59+4wk8+qrr+Y6vbzWTpw40ZQqVcptm8h8nb/44gtjjDHHjx83Xl5eZty4cS51PXr0MGFhYebixYvGGGPmz59vJJlPPvnEpW7jxo1Gkpk2bZrV1rx5c9O8efNcl+H77783ksz8+fPdhk2YMMFIMocPH85x/IcffthIMjt37sx1Ppny+3p36tTJpS42NtZIMo899phLe9euXU1QUJBLmyQTHh5uzpw5Y7UtWbLESDL16tWzXnNjjHnjjTeMJLNlyxZjjDFnz541QUFBbvPPyMgwdevWNXfeeafVlrlfvfLKKy61jzzyiPHx8XGZT9myZU3//v3d1kudOnVM165d3doBAAXDqfgAgCJljMl1eL169eTl5aWhQ4dqzpw5+boz+ZW6d++e59pbbrlFdevWdWnr06ePUlNT9fPPPxdo/nm1YsUKtW7dWpGRkS7tAwYM0Llz59xu9te5c2eX55lHmv/4448c53H27Fn98MMPuu++++Tn52e1e3h4qG/fvjp06FCeT+fPr88//1x16tRRvXr1dOnSJesRHR3tcglDcHCwOnXqpDlz5ujy5cuSpOTkZH366afq16+fPD09remVK1dOnTp1cplevXr1FB4enu8bKmbK7ZcZ8vurDbnJ7+ud9RcbatWqJUnq0KGDW/vJkyfdTsdv2bKlypYt6zZ+TEyMy3JltmduR+vWrdPJkyfVv39/l/V8+fJltW/fXhs3bnQ7Eya7bfPChQvZ/hpGVnfeeae+/PJLPfXUU1q1apXOnz9/1XEAADkj2AMAiszZs2d14sQJRURE5Fhz00036ZtvvlFoaKiGDRumm266STfddJPefPPNfM2rQoUKea4NDw/Psa2oTwU+ceJEtn3NXEdZ5x8cHOzyPPNU+dyCUHJysowx+ZpPYTly5Ii2bNmi0qVLuzz8/f1ljNHx48et2kGDBul///uf4uPjJUnz589XWlqadf+EzOmdOnVKXl5ebtNMSkpymV5eZK7P7Jb/5MmTcjgcKleuXI7jZ147v2/fvjzNL7+vd1BQkMtzLy+vXNsvXLhQKOMfOXJEknTfffe5redJkybJGKOTJ0+6TKMg22amt956S2PGjNGSJUvUsmVLBQUFqWvXrtqzZ89VxwUAuOMaewBAkVm2bJkyMjKu+tvizZo1U7NmzZSRkaGffvpJb7/9tmJjYxUWFqZevXrlaV75OcqalJSUY1tmWMm8xjotLc2lLr9BMqvg4GAlJia6tR8+fFiSFBISck3Tl6TAwECVKlWqyOeTnZCQEJUpU8a6zjq74Zmio6MVERGhuLg4RUdHKy4uTg0bNlTt2rVd6oODg7V8+fJsp+fv75+v/t10000qU6aMtm7d6jZs69atuvnmm3O8vj6zz+PGjdOSJUvUvn37q87verzehSGzH2+//XaOv+SQ+csWhaFs2bJ64YUX9MILL+jIkSPW0ftOnTpp586dhTYfAPi74Ig9AKBIHDhwQKNGjZLT6dRDDz2Up3E8PDzUsGFDvfPOO5JknRafnyOBebF9+3a33xmfN2+e/P39dfvtt0uSdXf4LVu2uNQtXbrUbXre3t557lvr1q21YsUKK9hlev/99+Xr61soP49XtmxZNWzYUIsWLXLp1+XLl/Xhhx+qUqVKql69+jXPJzsdO3bUb7/9puDgYDVo0MDtceVd9zMvDViyZInWrFmjn376SYMGDXKb3okTJ5SRkZHt9GrUqJGv/nl6eqpTp05atGiRTp8+bbUfOHBAK1eudLkbf3Zuv/12xcTEaObMmVqxYkW2NT/99JMOHDgg6fq83oWhadOmKleunH799dds13ODBg2so/z5kZd9IywsTAMGDFDv3r21a9cunTt3rqCLAQB/WxyxBwBcs23btlnX5B49elRr1qxRXFycPDw8tHjxYrc72F/p3Xff1YoVK9ShQwdVrlxZFy5csI72tmnTRtKfR2WrVKmiTz/9VK1bt1ZQUJBCQkIK/NNsERER6ty5s8aPH68KFSroww8/VHx8vCZNmiRfX19Jf/5kWY0aNTRq1ChdunRJgYGBWrx4sdauXes2vaioKC1atEjTp09X/fr1VapUKTVo0CDbeT///PP6/PPP1bJlSz333HMKCgrS3LlztWzZMr3yyityOp0FWqasJk6cqLZt26ply5YaNWqUvLy8NG3aNG3btk3z58+/puvIt27dqo8//tit/Y477lBsbKw++eQT3X333XriiSd066236vLlyzpw4IC+/vprjRw5Ug0bNrTGGTRokCZNmqQ+ffqoTJky6tmzp8s0e/Xqpblz5+qee+7R448/rjvvvFOlS5fWoUOHtHLlSnXp0kX33ntvvvr/wgsv6I477lDHjh311FNP6cKFC3ruuecUEhKikSNHXnX8999/X+3bt1dMTIwGDRqkmJgYBQYGKjExUZ999pnmz5+vTZs2qXLlytft9b5Wfn5+evvtt9W/f3+dPHlS9913n0JDQ3Xs2DFt3rxZx44d0/Tp0/M93aioKK1atUqfffaZKlSoIH9/f9WoUUMNGzZUx44ddeuttyowMFA7duzQBx98oMaNG1v7IAAgH4r33n0AADvLvHN85sPLy8uEhoaa5s2bmwkTJpijR4+6jZP1TvXr16839957r6lSpYrx9vY2wcHBpnnz5mbp0qUu433zzTfmtttuM97e3kaSdaftzOkdO3bsqvMy5s+74nfo0MF8/PHH5pZbbjFeXl7mhhtuMK+//rrb+Lt37zbt2rUzAQEBpnz58mb48OFm2bJlbnfFP3nypLnvvvtMuXLljMPhcJmnsrmb/9atW02nTp2M0+k0Xl5epm7duiYuLs6lJvMu6R999JFLe+ad6bPWZ2fNmjWmVatWpmzZsqZMmTKmUaNG5rPPPst2evm5K35Oj8w+nTlzxjzzzDOmRo0axsvLyzidThMVFWWeeOIJk5SU5DbdJk2aGEnm/vvvz3a+Fy9eNK+99pqpW7eu8fHxMX5+fqZmzZrmoYceMnv27LHq8nJX/Ew//fSTad26tfH19TUBAQGma9euZu/evXka1xhjzp8/b9566y3TuHFjExAQYDw9PU1ERITp1q2bWbZsmUvttbzeOf3yRHbbvSQzbNgwl7qcXt+c5rd69WrToUMHExQUZEqXLm0qVqxoOnTo4FKX0z6X3S9JJCQkmKZNmxpfX18jyXp9nnrqKdOgQQMTGBhovL29zY033mieeOIJc/z4cQMAyD+HMVe5XTEAAAAAACixuMYeAAAAAAAbI9gDAAAAAGBjBHsAAAAAAGyMYA8AAAAAgI0R7AEAAAAAsDGCPQAAAAAANuZZ3B2wi8uXL+vw4cPy9/eXw+Eo7u4AAAAAAP7ijDE6ffq0IiIiVKpUzsflCfZ5dPjwYUVGRhZ3NwAAAAAAfzMHDx5UpUqVchxOsM8jf39/SX+u0ICAgGLuDQAAAADgry41NVWRkZFWHs0JwT6PMk+/DwgIINgDAAAAAK6bq10Ozs3zAAAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANhYsQb7iRMn6o477pC/v79CQ0PVtWtX7dq1y6VmwIABcjgcLo9GjRq51KSlpWn48OEKCQlR2bJl1blzZx06dMilJjk5WX379pXT6ZTT6VTfvn116tSpol5EAAAAAACKVLEG+9WrV2vYsGHasGGD4uPjdenSJbVr105nz551qWvfvr0SExOtxxdffOEyPDY2VosXL9aCBQu0du1anTlzRh07dlRGRoZV06dPHyUkJGj58uVavny5EhIS1Ldv3+uynAAAAAAAFBWHMcYUdycyHTt2TKGhoVq9erXuvvtuSX8esT916pSWLFmS7TgpKSkqX768PvjgA/Xs2VOSdPjwYUVGRuqLL75QdHS0duzYodq1a2vDhg1q2LChJGnDhg1q3Lixdu7cqRo1aly1b6mpqXI6nUpJSVFAQEDhLDAAAAAAADnIaw4tUdfYp6SkSJKCgoJc2letWqXQ0FBVr15dQ4YM0dGjR61hmzZt0sWLF9WuXTurLSIiQnXq1NG6deskSevXr5fT6bRCvSQ1atRITqfTqskqLS1NqampLg8AAAAAAEqaEhPsjTEaMWKE7rrrLtWpU8dqj4mJ0dy5c7VixQpNnjxZGzduVKtWrZSWliZJSkpKkpeXlwIDA12mFxYWpqSkJKsmNDTUbZ6hoaFWTVYTJ060rsd3Op2KjIwsrEUFAAAAAKDQeBZ3BzI9+uij2rJli9auXevSnnl6vSTVqVNHDRo0UJUqVbRs2TJ169Ytx+kZY+RwOKznV/6dU82Vxo4dqxEjRljPU1NTCfcAAAAAgBKnRByxHz58uJYuXaqVK1eqUqVKudZWqFBBVapU0Z49eyRJ4eHhSk9PV3Jyskvd0aNHFRYWZtUcOXLEbVrHjh2zarLy9vZWQECAywMAAAAAgJKmWI/YG2M0fPhwLV68WKtWrVLVqlWvOs6JEyd08OBBVahQQZJUv359lS5dWvHx8erRo4ckKTExUdu2bdMrr7wiSWrcuLFSUlL0448/6s4775Qk/fDDD0pJSVGTJk2KaOnyp/6T7xd3F4Ait+nVfsXdBQAAAOAvp1iD/bBhwzRv3jx9+umn8vf3t653dzqdKlOmjM6cOaPx48ere/fuqlChgvbv369x48YpJCRE9957r1U7ePBgjRw5UsHBwQoKCtKoUaMUFRWlNm3aSJJq1aql9u3ba8iQIZoxY4YkaejQoerYsWOe7ogPAAAAAEBJVazBfvr06ZKkFi1auLTHxcVpwIAB8vDw0NatW/X+++/r1KlTqlChglq2bKmFCxfK39/fqp8yZYo8PT3Vo0cPnT9/Xq1bt9bs2bPl4eFh1cydO1ePPfaYdff8zp07a+rUqUW/kAAAAAAAFKES9Tv2JVlR/449p+Lj74BT8QEAAIC8s+Xv2AMAAAAAgPwh2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwsWIN9hMnTtQdd9whf39/hYaGqmvXrtq1a5dLjTFG48ePV0REhMqUKaMWLVpo+/btLjVpaWkaPny4QkJCVLZsWXXu3FmHDh1yqUlOTlbfvn3ldDrldDrVt29fnTp1qqgXEQAAAACAIlWswX716tUaNmyYNmzYoPj4eF26dEnt2rXT2bNnrZpXXnlFr7/+uqZOnaqNGzcqPDxcbdu21enTp62a2NhYLV68WAsWLNDatWt15swZdezYURkZGVZNnz59lJCQoOXLl2v58uVKSEhQ3759r+vyAgAAAABQ2BzGGFPcnch07NgxhYaGavXq1br77rtljFFERIRiY2M1ZswYSX8enQ8LC9OkSZP00EMPKSUlReXLl9cHH3ygnj17SpIOHz6syMhIffHFF4qOjtaOHTtUu3ZtbdiwQQ0bNpQkbdiwQY0bN9bOnTtVo0aNq/YtNTVVTqdTKSkpCggIKPRlr//k+4U+TaCk2fRqv+LuAgAAAGAbec2hJeoa+5SUFElSUFCQJGnfvn1KSkpSu3btrBpvb281b95c69atkyRt2rRJFy9edKmJiIhQnTp1rJr169fL6XRaoV6SGjVqJKfTadVklZaWptTUVJcHAAAAAAAlTYkJ9sYYjRgxQnfddZfq1KkjSUpKSpIkhYWFudSGhYVZw5KSkuTl5aXAwMBca0JDQ93mGRoaatVkNXHiROt6fKfTqcjIyGtbQAAAAAAAikCJCfaPPvqotmzZovnz57sNczgcLs+NMW5tWWWtya4+t+mMHTtWKSkp1uPgwYN5WQwAAAAAAK6rEhHshw8frqVLl2rlypWqVKmS1R4eHi5JbkfVjx49ah3FDw8PV3p6upKTk3OtOXLkiNt8jx075nY2QCZvb28FBAS4PAAAAAAAKGmKNdgbY/Too49q0aJFWrFihapWreoyvGrVqgoPD1d8fLzVlp6ertWrV6tJkyaSpPr166t06dIuNYmJidq2bZtV07hxY6WkpOjHH3+0an744QelpKRYNQAAAAAA2JFncc582LBhmjdvnj799FP5+/tbR+adTqfKlCkjh8Oh2NhYTZgwQdWqVVO1atU0YcIE+fr6qk+fPlbt4MGDNXLkSAUHBysoKEijRo1SVFSU2rRpI0mqVauW2rdvryFDhmjGjBmSpKFDh6pjx455uiM+AAAAAAAlVbEG++nTp0uSWrRo4dIeFxenAQMGSJJGjx6t8+fP65FHHlFycrIaNmyor7/+Wv7+/lb9lClT5OnpqR49euj8+fNq3bq1Zs+eLQ8PD6tm7ty5euyxx6y753fu3FlTp04t2gUEAAAAAKCIlajfsS/J+B174NrxO/YAAABA3tnyd+wBAAAAAED+EOwBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2JhncXcAAOzgwItRxd0FoMhVfm5rcXcBAAAUAEfsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRVrsP/uu+/UqVMnRUREyOFwaMmSJS7DBwwYIIfD4fJo1KiRS01aWpqGDx+ukJAQlS1bVp07d9ahQ4dcapKTk9W3b185nU45nU717dtXp06dKuKlAwAAAACg6BVrsD979qzq1q2rqVOn5ljTvn17JSYmWo8vvvjCZXhsbKwWL16sBQsWaO3atTpz5ow6duyojIwMq6ZPnz5KSEjQ8uXLtXz5ciUkJKhv375FtlwAAAAAAFwvnsU585iYGMXExORa4+3trfDw8GyHpaSkaObMmfrggw/Upk0bSdKHH36oyMhIffPNN4qOjtaOHTu0fPlybdiwQQ0bNpQk/ec//1Hjxo21a9cu1ahRo3AXCgAAAACA66jEX2O/atUqhYaGqnr16hoyZIiOHj1qDdu0aZMuXryodu3aWW0RERGqU6eO1q1bJ0lav369nE6nFeolqVGjRnI6nVZNdtLS0pSamuryAAAAAACgpCnRwT4mJkZz587VihUrNHnyZG3cuFGtWrVSWlqaJCkpKUleXl4KDAx0GS8sLExJSUlWTWhoqNu0Q0NDrZrsTJw40bom3+l0KjIyshCXDAAAAACAwlGsp+JfTc+ePa2/69SpowYNGqhKlSpatmyZunXrluN4xhg5HA7r+ZV/51ST1dixYzVixAjreWpqKuEeAAAAAFDilOgj9llVqFBBVapU0Z49eyRJ4eHhSk9PV3Jyskvd0aNHFRYWZtUcOXLEbVrHjh2zarLj7e2tgIAAlwcAAAAAACWNrYL9iRMndPDgQVWoUEGSVL9+fZUuXVrx8fFWTWJiorZt26YmTZpIkho3bqyUlBT9+OOPVs0PP/yglJQUqwYAAAAAALsq1lPxz5w5o71791rP9+3bp4SEBAUFBSkoKEjjx49X9+7dVaFCBe3fv1/jxo1TSEiI7r33XkmS0+nU4MGDNXLkSAUHBysoKEijRo1SVFSUdZf8WrVqqX379hoyZIhmzJghSRo6dKg6duzIHfEBAAAAALZXrMH+p59+UsuWLa3nmde09+/fX9OnT9fWrVv1/vvv69SpU6pQoYJatmyphQsXyt/f3xpnypQp8vT0VI8ePXT+/Hm1bt1as2fPloeHh1Uzd+5cPfbYY9bd8zt37qypU6dep6UEAAAAAKDoOIwxprg7YQepqalyOp1KSUkpkuvt6z/5fqFPEyhpNr3ar7i7UGAHXowq7i4ARa7yc1uLuwsAAOAKec2htrrGHgAAAAAAuCLYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsrEDBvlWrVjp16pRbe2pqqlq1anWtfQIAAAAAAHlUoGC/atUqpaenu7VfuHBBa9asueZOAQAAAACAvPHMT/GWLVusv3/99VclJSVZzzMyMrR8+XJVrFix8HoHAAAAAAByla9gX69ePTkcDjkcjmxPuS9TpozefvvtQuscAAAAAADIXb6C/b59+2SM0Y033qgff/xR5cuXt4Z5eXkpNDRUHh4ehd5JAAAAAACQvXwF+ypVqkiSLl++XCSdAQAAAAAA+ZOvYH+l3bt3a9WqVTp69Khb0H/uueeuuWMAAAAAAODqChTs//Of/+if//ynQkJCFB4eLofDYQ1zOBwEewAAAAAArpMCBfuXXnpJ//d//6cxY8YUdn8AAAAAAEA+FOh37JOTk/WPf/yjsPsCAAAAAADyqUDB/h//+Ie+/vrrwu4LAAAAAADIpwKdin/zzTfr2Wef1YYNGxQVFaXSpUu7DH/ssccKpXMAAAAAACB3BQr2//73v+Xn56fVq1dr9erVLsMcDgfBHgAAAACA66RAwX7fvn2F3Q8AAAAAAFAABbrGHgAAAAAAlAwFOmI/aNCgXIfPmjWrQJ0BAAAAAAD5U6Bgn5yc7PL84sWL2rZtm06dOqVWrVoVSscAAAAAAMDVFSjYL1682K3t8uXLeuSRR3TjjTdec6cAAAAAAEDeFNo19qVKldITTzyhKVOmFNYkAQAAAADAVRTqzfN+++03Xbp0qTAnCQAAAAAAclGgU/FHjBjh8twYo8TERC1btkz9+/cvlI4BAAAAAICrK1Cw/+WXX1yelypVSuXLl9fkyZOvesd8AAAAAABQeAoU7FeuXFnY/QAAAAAAAAVQoGCf6dixY9q1a5ccDoeqV6+u8uXLF1a/AAAAAABAHhTo5nlnz57VoEGDVKFCBd19991q1qyZIiIiNHjwYJ07d66w+wgAAAAAAHJQoGA/YsQIrV69Wp999plOnTqlU6dO6dNPP9Xq1as1cuTIwu4jAAAAAADIQYFOxf/kk0/08ccfq0WLFlbbPffcozJlyqhHjx6aPn16YfUPAAAAAADkokBH7M+dO6ewsDC39tDQUE7FBwAAAADgOipQsG/cuLGef/55XbhwwWo7f/68XnjhBTVu3LjQOgcAAAAAAHJXoFPx33jjDcXExKhSpUqqW7euHA6HEhIS5O3tra+//rqw+wgAAAAAAHJQoGAfFRWlPXv26MMPP9TOnTtljFGvXr10//33q0yZMoXdRwAAAAAAkIMCBfuJEycqLCxMQ4YMcWmfNWuWjh07pjFjxhRK5wAAAAAAQO4KdI39jBkzVLNmTbf2W265Re++++41dwoAAAAAAORNgYJ9UlKSKlSo4NZevnx5JSYmXnOnAAAAAABA3hQo2EdGRur77793a//+++8VERFxzZ0CAAAAAAB5U6Br7B988EHFxsbq4sWLatWqlSTp22+/1ejRozVy5MhC7SAAAAAAAMhZgYL96NGjdfLkST3yyCNKT0+XJPn4+GjMmDEaO3ZsoXYQAAAAAADkrEDB3uFwaNKkSXr22We1Y8cOlSlTRtWqVZO3t3dh9w8AAAAAAOSiQME+k5+fn+64447C6gsAAAAAAMinAt08DwAAAAAAlAwEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwsWIN9t999506deqkiIgIORwOLVmyxGW4MUbjx49XRESEypQpoxYtWmj79u0uNWlpaRo+fLhCQkJUtmxZde7cWYcOHXKpSU5OVt++feV0OuV0OtW3b1+dOnWqiJcOAAAAAICiV6zB/uzZs6pbt66mTp2a7fBXXnlFr7/+uqZOnaqNGzcqPDxcbdu21enTp62a2NhYLV68WAsWLNDatWt15swZdezYURkZGVZNnz59lJCQoOXLl2v58uVKSEhQ3759i3z5AAAAAAAoap7FOfOYmBjFxMRkO8wYozfeeENPP/20unXrJkmaM2eOwsLCNG/ePD300ENKSUnRzJkz9cEHH6hNmzaSpA8//FCRkZH65ptvFB0drR07dmj58uXasGGDGjZsKEn6z3/+o8aNG2vXrl2qUaNGtvNPS0tTWlqa9Tw1NbUwFx0AAAAAgEJRYq+x37dvn5KSktSuXTurzdvbW82bN9e6deskSZs2bdLFixddaiIiIlSnTh2rZv369XI6nVaol6RGjRrJ6XRaNdmZOHGideq+0+lUZGRkYS8iAAAAAADXrMQG+6SkJElSWFiYS3tYWJg1LCkpSV5eXgoMDMy1JjQ01G36oaGhVk12xo4dq5SUFOtx8ODBa1oeAAAAAACKQrGeip8XDofD5bkxxq0tq6w12dVfbTre3t7y9vbOZ28BAAAAALi+SuwR+/DwcElyO6p+9OhR6yh+eHi40tPTlZycnGvNkSNH3KZ/7Ngxt7MBAAAAAACwmxIb7KtWrarw8HDFx8dbbenp6Vq9erWaNGkiSapfv75Kly7tUpOYmKht27ZZNY0bN1ZKSop+/PFHq+aHH35QSkqKVQMAAAAAgF0V66n4Z86c0d69e63n+/btU0JCgoKCglS5cmXFxsZqwoQJqlatmqpVq6YJEybI19dXffr0kSQ5nU4NHjxYI0eOVHBwsIKCgjRq1ChFRUVZd8mvVauW2rdvryFDhmjGjBmSpKFDh6pjx4453hEfAAAAAAC7KNZg/9NPP6lly5bW8xEjRkiS+vfvr9mzZ2v06NE6f/68HnnkESUnJ6thw4b6+uuv5e/vb40zZcoUeXp6qkePHjp//rxat26t2bNny8PDw6qZO3euHnvsMevu+Z07d9bUqVOv01ICAAAAAFB0HMYYU9ydsIPU1FQ5nU6lpKQoICCg0Kdf/8n3C32aQEmz6dV+xd2FAjvwYlRxdwEocpWf21rcXQAAAFfIaw4tsdfYAwAAAACAqyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALCxEh3sx48fL4fD4fIIDw+3hhtjNH78eEVERKhMmTJq0aKFtm/f7jKNtLQ0DR8+XCEhISpbtqw6d+6sQ4cOXe9FAQAAAACgSJToYC9Jt9xyixITE63H1q1brWGvvPKKXn/9dU2dOlUbN25UeHi42rZtq9OnT1s1sbGxWrx4sRYsWKC1a9fqzJkz6tixozIyMopjcQAAAAAAKFSexd2Bq/H09HQ5Sp/JGKM33nhDTz/9tLp16yZJmjNnjsLCwjRv3jw99NBDSklJ0cyZM/XBBx+oTZs2kqQPP/xQkZGR+uabbxQdHX1dlwUAAAAAgMJW4o/Y79mzRxEREapatap69eql33//XZK0b98+JSUlqV27dlatt7e3mjdvrnXr1kmSNm3apIsXL7rUREREqE6dOlZNTtLS0pSamuryAAAAAACgpCnRwb5hw4Z6//339dVXX+k///mPkpKS1KRJE504cUJJSUmSpLCwMJdxwsLCrGFJSUny8vJSYGBgjjU5mThxopxOp/WIjIwsxCUDAAAAAKBwlOhgHxMTo+7duysqKkpt2rTRsmXLJP15yn0mh8PhMo4xxq0tq7zUjB07VikpKdbj4MGDBVwKAAAAAACKTokO9lmVLVtWUVFR2rNnj3XdfdYj70ePHrWO4oeHhys9PV3Jyck51uTE29tbAQEBLg8AAAAAAEoaWwX7tLQ07dixQxUqVFDVqlUVHh6u+Ph4a3h6erpWr16tJk2aSJLq16+v0qVLu9QkJiZq27ZtVg0AAAAAAHZWou+KP2rUKHXq1EmVK1fW0aNH9dJLLyk1NVX9+/eXw+FQbGysJkyYoGrVqqlatWqaMGGCfH191adPH0mS0+nU4MGDNXLkSAUHBysoKEijRo2yTu0HAAAAAMDuSnSwP3TokHr37q3jx4+rfPnyatSokTZs2KAqVapIkkaPHq3z58/rkUceUXJysho2bKivv/5a/v7+1jSmTJkiT09P9ejRQ+fPn1fr1q01e/ZseXh4FNdiAQAAAABQaBzGGFPcnbCD1NRUOZ1OpaSkFMn19vWffL/QpwmUNJte7VfcXSiwAy9GFXcXgCJX+bmtxd0FAABwhbzmUFtdYw8AAAAAAFwR7AEAAAAAsDGCPQAAAAAANkawBwAAAADAxgj2AAAAAADYGMEeAAAAAAAbI9gDAAAAAGBjBHsAAAAAAGyMYA8AAAAAgI0R7AEAAAAAsDGCPQAAAAAANkawBwAAAADAxgj2AAAAAADYGMEeAAAAAAAbI9gDAAAAAGBjBHsAAAAAAGyMYA8AAAAAgI0R7AEAAAAAsDGCPQAAAAAANkawBwAAAADAxjyLuwMAAADXounbTYu7C0CR+37498XdBQAlGEfsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABsj2AMAAAAAYGMEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANiYZ3F3AAAAAMBf1+q7mxd3F4Ai1/y71cU6f47YAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALAxgj0AAAAAADZGsAcAAAAAwMYI9gAAAAAA2BjBHgAAAAAAGyPYAwAAAABgYwR7AAAAAABsjGAPAAAAAICNEewBAAAAALCxv1WwnzZtmqpWrSofHx/Vr19fa9asKe4uAQAAAABwTf42wX7hwoWKjY3V008/rV9++UXNmjVTTEyMDhw4UNxdAwAAAACgwP42wf7111/X4MGD9eCDD6pWrVp64403FBkZqenTpxd31wAAAAAAKDDP4u7A9ZCenq5Nmzbpqaeecmlv166d1q1bl+04aWlpSktLs56npKRIklJTU4ukjxlp54tkukBJUlT7z/Vw+kJGcXcBKHJ23Ucvnb9U3F0Aipxd909JOnuJfRR/fUW1j2ZO1xiTa93fItgfP35cGRkZCgsLc2kPCwtTUlJStuNMnDhRL7zwglt7ZGRkkfQR+Dtwvv1wcXcBQG4mOou7BwBy4BzD/gmUaM6i3UdPnz4tZy7z+FsE+0wOh8PluTHGrS3T2LFjNWLECOv55cuXdfLkSQUHB+c4DuwjNTVVkZGROnjwoAICAoq7OwCyYB8FSi72T6BkYx/9azHG6PTp04qIiMi17m8R7ENCQuTh4eF2dP7o0aNuR/EzeXt7y9vb26WtXLlyRdVFFJOAgADe8IASjH0UKLnYP4GSjX30ryO3I/WZ/hY3z/Py8lL9+vUVHx/v0h4fH68mTZoUU68AAAAAALh2f4sj9pI0YsQI9e3bVw0aNFDjxo3173//WwcOHNDDD3PNLwAAAADAvv42wb5nz546ceKEXnzxRSUmJqpOnTr64osvVKVKleLuGoqBt7e3nn/+ebfLLQCUDOyjQMnF/gmUbOyjf08Oc7X75gMAAAAAgBLrb3GNPQAAAAAAf1UEewAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYJ9CTZgwAB17drV5bnD4dDLL7/sUrdkyRI5HA7r+apVq+RwONwezzzzjFWTkZGhKVOm6NZbb5WPj4/KlSunmJgYff/99y7Tnj17tss0wsLC1KlTJ23fvt2trw6HI9ufD3zkkUfkcDg0YMAAt2Hr1q2Th4eH2rdv7zat3B7ZrR9JOnjwoAYPHqyIiAh5eXmpSpUqevzxx3XixAmXuhYtWsjhcGjBggUu7W+88YZuuOEGt35eKac+ZU5r2rRpKleunA4ePOgy3qOPPqrq1avr3LlzkqS9e/dq4MCBqlSpkry9vVW1alX17t1bP/30k8u8lixZ4taH7JY9p/WZaf/+/XI4HAoNDdXp06ddhtWrV0/jx493adu7d68GDRqkypUry9vbWxUrVlTr1q01d+5cXbp0Kc/rA9dffvfH/O43DofD2iY6deqkRYsWuc0n67ab3TZy11135VgvSStXrtQ999yj4OBg+fr6qnbt2ho5cqT+97//uc2vRo0a8vLysobl9D545WP27NlW3alTp6xp5ff9Mev+durUKTkcDq1atcqtn7i+jh49qoceesh6HwsPD1d0dLTWr1/vUrdu3Trdc889CgwMlI+Pj6KiojR58mRlZGS4TfNq22V221SmrNvplVq0aKHY2Nh8LV9SUpKGDx+uG2+8Ud7e3oqMjFSnTp307bffFmj5MveNDRs2uLSnpaUpODjYbbvOT33mZ1BCQoLbcnTt2tXlPSmvn9GzZ89WuXLlXGrS09P1yiuvqG7duvL19VVISIiaNm2quLg4Xbx40W292O07CP56cttuMveb3B7jx4/Pdf/K+t5y5Wf5lY8rvzNc2e7n56e6detq9uzZRb8ycE0I9jbj4+OjSZMmKTk5+aq1u3btUmJiovV46qmnJEnGGPXq1UsvvviiHnvsMe3YsUOrV69WZGSkWrRo4fblOiAgQImJiTp8+LCWLVums2fPqkOHDkpPT3epi4yM1IIFC3T+/Hmr7cKFC5o/f74qV66cbR9nzZql4cOHa+3atTpw4IAk6c0333TptyTFxcW5tWX1+++/q0GDBtq9e7fmz5+vvXv36t1339W3336rxo0b6+TJk27r8plnnnH7oM+LrP1JTEy0PuD/+c9/6s4779TgwYOt+hUrVmjGjBmaPXu2fH199dNPP6l+/fravXu3ZsyYoV9//VWLFy9WzZo1NXLkyHz3J1N26zOr06dP67XXXst1Oj/++KNuv/127dixQ++88462bdumzz//XIMGDdK7777r9o+d3NYHikde98f87jdDhgxRYmKi9u7dq08++US1a9dWr169NHTo0Kv2Ket2snTp0hxrZ8yYoTZt2ig8PFyffPKJfv31V7377rtKSUnR5MmTXWrXrl2rCxcu6B//+If1xaNJkyYu8+rRo4fat2/v0tazZ0+3+eb3/dHT01PffvutVq5cedXlx/XXvXt3bd68WXPmzNHu3bu1dOlStWjRwmW7Xrx4sZo3b65KlSpp5cqV2rlzpx5//HH93//9n3r16qUrfzwoP9tlVtltp9di//79ql+/vlasWKFXXnlFW7du1fLly9WyZUsNGzasQMsn/fneERcX59K2ePFi+fn5ZduP/NbnVUE+o9PT0xUdHa2XX35ZQ4cO1bp16/Tjjz9q2LBhevvtt90+u+z6HQR/HVfbbvz9/V22vZEjR+qWW25xaRs1alS+55v5WX7l45VXXnGpydzuN2/erJ49e2rgwIH66quvCmvRURQMSqz+/fubLl26uDzv2LGjqVmzpnnyySet9sWLF5srX8qVK1caSSY5OTnb6S5YsMBIMkuXLnUb1q1bNxMcHGzOnDljjDEmLi7OOJ1Ol5qlS5caSWbLli1ufY2KijIffvih1T537lwTFRVlunTpYvr37+8ynTNnzhh/f3+zc+dO07NnT/PCCy9k219JZvHixW7tWddP+/btTaVKlcy5c+dc6hITE42vr695+OGHrbbmzZubgQMHmpCQEPPOO+9Y7VOmTDFVqlTJth9X68+VDhw4YJxOp5k+fbpJSUkxlStXtl6zy5cvm1tuucXUr1/fZGRkuI175euW12U35urrc9++fUaSefLJJ42fn585cuSINaxu3brm+eeft/pXq1atHPuXWXO1PqL45Gd/zO9+8/jjj7vNb9asWUaSiY+Pt9qybhdX206uHH7w4EHj5eVlYmNjs63N+t42YMAA89RTT5kvv/zS3HjjjS7bZ6bs9hlj3N8vC/L+OGTIEHPnnXe69E+SWblyZY7Li6KX+TqsWrUqx5ozZ86Y4OBg061bN7dhmZ91CxYsMMbkfbvM6TP4attpTvtXTmJiYkzFihWt7TG7vuRn+Yz5cz985plnTEBAgMt7Qtu2bc2zzz7rtl3npz7zM+iXX35x60vW7wh5/YzO+h1l0qRJplSpUubnn392m0d6errLurLrdxD8teRnuzHGmOeff97UrVvXbTq57V9Z31vy8l6T3XYfFBRkRowYket4KF4csbcZDw8PTZgwQW+//bYOHTpUoGnMmzdP1atXV6dOndyGjRw5UidOnFB8fHy24546dUrz5s2TJJUuXdpt+MCBA13+cz9r1iwNGjQo22ktXLhQNWrUUI0aNfTAAw8oLi7O7chBXp08eVJfffWVHnnkEZUpU8ZlWHh4uO6//34tXLjQZfoBAQEaN26cXnzxRZ09e7ZA881JZGSkpkyZoieffFIPPPCA/Pz89K9//UuSlJCQoO3bt2vkyJEqVcp9F8x6WmFe5XV99u7dWzfffLNefPHFbKeTkJCgHTt2aNSoUdn2T5LLpR8oua62PxZkv8lO//79FRgYmO0p+QXx0UcfKT09XaNHj852+JX7yOnTp/XRRx/pgQceUNu2bXX27NlrOgW+IO+P48eP19atW/Xxxx8XeL4ofH5+fvLz89OSJUuUlpaWbc3XX3+tEydOZHvEq1OnTqpevbrmz58vKX/bZVaFvZ2ePHlSy5cv17Bhw1S2bNkc+5Kf5ctUv359Va1aVZ988omkP08T/u6779S3b99s+5Lf+rwqyGf03Llz1aZNG912221uw0qXLu2yrv7K30FgD4X1GVzUMjIy9N///lcnT57M9rs/Sg6CvQ3de++9qlevnp5//vlc6ypVqmR9sfHz87Ou8dq9e7dq1aqV7TiZ7bt377baUlJS5Ofnp7JlyyowMFALFixQ586dVbNmTbfx+/btq7Vr12r//v36448/9P333+uBBx7Idl4zZ860hrVv315nzpxxuy4wr/bs2SNjTK7LlZycrGPHjrm0P/LII/Lx8dHrr7+er/n17t3bZd36+fnp999/d6kZOHCg6tSpo88++0xxcXHy9va2+iop2/WX13nNnTvXrS6v6zPzPg3//ve/9dtvv7kNz3zta9SoYbUdPXrUZf7Tpk3L9/rA9Xe1/bGg+01WpUqVUvXq1bV///5c67JuJ9ndPyKzXwEBAapQoUKu05OkBQsWqFq1arrlllvk4eGhXr16aebMmVcdLyf5fX+UpIiICD3++ON6+umnXe4/geLl6emp2bNna86cOSpXrpyaNm2qcePGacuWLVZN5muZ02tes2ZNqyY/22VWhb2d7t27V8aYq36O5Gf5rjRw4EDNmjVL0p+n495zzz0qX758jvPJb31e5fczes+ePXn+bLXzdxD8NRTWZ/CVmjRp4vZ9bM2aNW5106ZNc6ubM2eOS03mZ7a3t7d69uypoKAgPfjgg/lbSFxXBHubmjRpkubMmaNff/01x5o1a9YoISHBegQGBuZ5+lcekfX391dCQoI2bdqkd999VzfddJPefffdbMcLCQlRhw4dNGfOHMXFxalDhw4KCQlxq9u1a5d+/PFH9erVS9KfX8B69uxpfTEobJn/7cx6pNnb21svvviiXn31VR0/fjzP05syZYrLuk1ISFBkZKRLzebNm7Vp0yb5+vq6vKnm1Jf8zKtz584uNfldn9HR0brrrrv07LPP5jjfK/sXHBxszbtcuXJu91fIy/rA9ZfX/TEn+dlWjTFXrcu6nbRt27bA08p05ZdzSXrggQe0aNGibG9cVliy69uYMWN07NixInsPQ8F0795dhw8f1tKlSxUdHa1Vq1bp9ttvd7vGPacjYldui/nZLrMq7O00v58jeVm+Kz3wwANav369fv/9d82ePTvHM+8KWp9X+f2MzutrZPfvIPh7yO9+Lv15JkrW72MNGjRwq7v//vvd6u69916XmszP7Pj4eNWrV09TpkzRzTfffG0LhSJFsLepu+++W9HR0Ro3blyONVWrVtXNN99sPTJPq65evXqO/xDYsWOHJKlatWpWW6lSpXTzzTerZs2aeuihh9S3b99sbzqVadCgQdZRkpw+3GfOnKlLly6pYsWK8vT0lKenp6ZPn65Fixbl6caAWd18881yOBw5LtfOnTsVGBiYbah54IEHdMMNN+ill17K8/zCw8Nd1u3NN9/scnpSenq6+vXrp969e2vGjBl65plnrKMi1atXl/T/13VB5uXv7+9SU5D1+fLLL2vhwoX65ZdfXNozX/udO3dabR4eHta8PT09870+UHxy2x+vZb+5UkZGhvbs2aOqVavmWpd1O8nuFGLpz30kJSUlx5tUZfr111/1ww8/aPTo0dZ236hRI50/f97t9OK8yu/7Y6Zy5cpp7NixeuGFF6xfvkDJ4OPjo7Zt2+q5557TunXrNGDAAOuMt6u9H+/cudN6vfO6XWZVFNtptWrV5HA4rvo5kp/lu1JwcLA6duyowYMH68KFC4qJicl1Pnmpdzqdkv48CzCrU6dOWcOzys9ndPXq1fP02Wr37yD4ayisz+ArRUZGun0fy3qav/Tn/pi1LiAgwKUm8zO7ZcuW+uijjzRs2LBcDyii+BHsbezll1/WZ599pnXr1uVrvF69emnPnj367LPP3IZNnjxZwcHBOR5Jk6QnnnhCmzdv1uLFi7Md3r59e6Wnp1t3p83q0qVLev/99zV58mSX/xRu3rxZVapUyfY086vJ7PO0adNc7gIu/flzQHPnzlXPnj2z/a9nqVKlNHHiRE2fPv2qpxLn1YsvvqgTJ07ozTff1AMPPKDo6GgNHDhQly9fVr169VS7dm1NnjxZly9fdhs3v0dwCro+77zzTnXr1s36tYRMt912m2rWrKnXXnst2/7BXnLbH69lv7nSnDlzlJycrO7duxdKn++77z55eXm53aE3U+Y+MnPmTN19993avHmzy7Y/evToAp/mfC3vj8OHD1epUqX05ptvFmjeuD5q165tXdPcrl07BQUFZXtH+6VLl2rPnj3q3bu3pLxvl1kVxXYaFBSk6OhovfPOO9len53Zl/wsX1aDBg3SqlWr1K9fP3l4eFy1T1erDwwMVPny5bVx40aX9vPnz2v79u0ul39dKT+f0X369NE333zj9g9r6c/PyrNnz/4tvoPAHgrrM/h6uPnmm9W9e3eNHTu2uLuC3Fyvu/Qh/7K7K37Wuzr37dvX+Pj45Ouu+JcvXzb33nuvCQwMNO+9957Zt2+f2bx5sxk6dKjx9PR0uQtmdnfFN8aYESNGmKioKOuuvln7lpKSYlJSUqznV97xdvHixcbLy8ucOnXKbbrjxo0z9erVc2lTHu9Iu3v3bhMSEmKaNWtmVq9ebQ4cOGC+/PJLU6dOHVOtWjVz4sQJqza7O4I2a9bM+Pj45Omu+HFxcSYxMdHlkXm33Y0bNxpPT0/z5ZdfWuMkJiaaoKAg89prrxljjPnhhx+Mv7+/adq0qVm2bJn57bffzObNm81LL71k7r777nwte17XZ3Z3TN21a5fx9PQ0Pj4+1l3xjTFm/fr1xs/PzzRq1Mh8+umnZvfu3Wb79u1m+vTpxtfX17z11lt5Xh+4/vKzP+Z3vxkyZIhJTEw0Bw8eNBs2bDCjR482pUuXNv/85z9d+pB1281pW85p+DvvvGMcDocZNGiQWbVqldm/f79Zu3atGTp0qBkxYoRJT0835cuXN9OnT3eb1u7du40kk5CQkOM6yZT1/fJa3x9nzpxpvSdzV/zidfz4cdOyZUvzwQcfmM2bN5vff//d/Pe//zVhYWFm0KBBVt1HH31kPDw8zJAhQ8zmzZvNvn37zHvvvWcCAwPNfffd53L3+qttl8a4blP52U6bN29u+vTpY3755ReXR2JiYrbL9/vvv5vw8HBTu3Zt8/HHH5vdu3ebX3/91bz55pumZs2aBVq+K/fDy5cvm2PHjpm0tDRjTPa/9pDf+kmTJpnAwEDz/vvvm71795qNGzea++67z4SHh7u8R+X1MzrrPnjhwgXTrFkzExgYaKZOnWoSEhLMb7/9ZhYuXGhuv/1288svv9j+Owj+WvKz3RhTeHfFz/wsv/Jx8uRJqya77X7Lli3G4XCYjRs3XssiowgR7EuwvAT7/fv3G29v73wFe2OMuXjxonnttdfMLbfcYry9vU1AQICJjo42a9ascanLKdj/8ccfxtPT0yxcuDDHvl3pyiDRsWNHc88992Rbt2nTJiPJbNq0yWrL64eqMX+ujwEDBpjw8HBTunRpExkZaYYPH26OHz/uUpfdh+q6deuMpDwF++weEydONBcuXDC1a9c2Q4YMcRtv7ty5xsfHx+zcudMY82eo7tevn4mIiDBeXl6mSpUqpnfv3i4/05OXZc/r+szpTX/o0KFGkkuwz+xf//79TaVKlYynp6dxOp3m7rvvNjNmzDAXL17M0/pA8cjP/mhM/vabzNfXy8vLVKhQwXTs2NEsWrTIbR7XGuyNMSY+Pt5ER0ebwMBA4+PjY2rWrGlGjRplDh8+bD7++GNTqlQpk5SUlO30oqKizPDhw6+6TrJ7v7yW98dLly6Z2rVrE+xLgAsXLpinnnrK3H777cbpdBpfX19To0YN88wzz7j9tNR3331n2rdvb5xOp/Hy8jK1a9c2r732mrl06ZLbdHPbLo1x3abys51euX9d+cj63nylw4cPm2HDhpkqVaoYLy8vU7FiRdO5c2e3bS+vy5fbfnq1YJ+X+oyMDPPOO++YW2+91ZQtW9ZUrFjRdO/e3ezZs8dl3Lx+Rme3D164cMFMnDjRREVFGR8fHxMUFGSaNm1qZs+ebS5evGj77yD468nrdmNM4QX77N5roqOjrZqctvu2bduamJiYgiwmrgOHMcX8GwoAAAAAAKDAuMYeAAAAAAAbI9gDAAAAAGBjBHsAAAAAAGyMYA8AAAAAgI0R7AEAAAAAsDGCPQAAAAAANkawBwAAAADAxgj2AAAAAADYGMEeAABIklq0aKHY2NjrNr8BAwaoa9eu121+AAD8VRHsAQCALUybNk1Vq1aVj4+P6tevrzVr1hR3lwAAKBEI9gAAoMRbuHChYmNj9fTTT+uXX35Rs2bNFBMTowMHDhR31wAAKHYEewAA4CY9PV2jR49WxYoVVbZsWTVs2FCrVq2SJKWkpKhMmTJavny5yziLFi1S2bJldebMGUnS//73P/Xs2VOBgYEKDg5Wly5dtH///gL15/XXX9fgwYP14IMPqlatWnrjjTcUGRmp6dOnX8tiAgDwl0CwBwAAbgYOHKjvv/9eCxYs0JYtW/SPf/xD7du31549e+R0OtWhQwfNnTvXZZx58+apS5cu8vPz07lz59SyZUv5+fnpu+++09q1a+Xn56f27dsrPT09X31JT0/Xpk2b1K5dO5f2du3aad26dde8rAAA2J1ncXcAAACULL/99pvmz5+vQ4cOKSIiQpI0atQoLV++XHFxcZowYYLuv/9+9evXT+fOnZOvr69SU1O1bNkyffLJJ5KkBQsWqFSpUnrvvffkcDgkSXFxcSpXrpxWrVrlFtJzc/z4cWVkZCgsLMylPSwsTElJSYW01AAA2BfBHgAAuPj5559ljFH16tVd2tPS0hQcHCxJ6tChgzw9PbV06VL16tVLn3zyifz9/a3AvmnTJu3du1f+/v4u07hw4YJ+++23AvUr8x8EmYwxbm0AAPwdEewBAICLy5cvy8PDQ5s2bZKHh4fLMD8/P0mSl5eX7rvvPs2bN0+9evXSvHnz1LNnT3l6elrTqF+/vtvp+pJUvnz5fPUnJCREHh4ebkfnjx496nYUHwCAvyOCPQAAcHHbbbcpIyNDR48eVbNmzXKsu//++9WuXTtt375dK1eu1L/+9S9r2O23366FCxcqNDRUAQEB19QfLy8v1a9fX/Hx8br33nut9vj4eHXp0uWapg0AwF8BN88DAAAuqlevbl1Dv2jRIu3bt08bN27UpEmT9MUXX1h1zZs3V1hYmO6//37dcMMNatSokTXs/vvvV0hIiLp06aI1a9Zo3759Wr16tR5//HEdOnQo330aMWKE3nvvPc2aNUs7duzQE088oQMHDujhhx8ulGUGAMDOCPYAAMBNXFyc+vXrp5EjR6pGjRrq3LmzfvjhB0VGRlo1DodDvXv31ubNm3X//fe7jO/r66vvvvtOlStXVrdu3VSrVi0NGjRI58+fL9AR/J49e+qNN97Qiy++qHr16um7777TF198oSpVqlzzsgIAYHcOY4wp7k4AAAAAAICC4Yg9AAAAAAA2RrAHAADF6sCBA/Lz88vxceDAgeLuIgAAJRqn4gMAgGJ16dIl7d+/P8fhN9xwg/UzegAAwB3BHgAAAAAAG+NUfAAAAAAAbIxgDwAAAACAjRHsAQAAAACwMYI9AAAAAAA2RrAHAAAAAMDGCPYAAAAAANgYwR4AAAAAABv7fyfDSrYqX9VaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 5.5937, Val Loss: 0.6416\n",
      "Epoch 2, Train Loss: 5.2973, Val Loss: 0.6266\n",
      "Epoch 3, Train Loss: 5.1831, Val Loss: 0.5976\n",
      "Epoch 4, Train Loss: 5.1004, Val Loss: 0.5944\n",
      "Epoch 5, Train Loss: 5.0121, Val Loss: 0.5759\n",
      "Epoch 6, Train Loss: 4.9427, Val Loss: 0.5732\n",
      "Epoch 7, Train Loss: 4.8702, Val Loss: 0.5653\n",
      "Epoch 8, Train Loss: 4.8134, Val Loss: 0.5740\n",
      "Epoch 9, Train Loss: 4.7605, Val Loss: 0.5499\n",
      "Epoch 10, Train Loss: 4.6974, Val Loss: 0.5461\n",
      "Accuracy: 0.1982, Precision: 0.3384, Recall: 0.4558, F1-Score: 0.3704\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('labeled_comments_cleaned.csv')\n",
    "df.fillna('Unknown', inplace=True)\n",
    "df['comment_date'] = pd.to_datetime(df['comment_date'])\n",
    "df['date_column'] = df['comment_date'].dt.date\n",
    "df['time_column'] = df['comment_date'].dt.time\n",
    "df = df[df['comment_full_text'].notna()]\n",
    "\n",
    "# Visualize the distribution of levels\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='level_0', data=df)\n",
    "plt.title('Distribution of Level 0 Comments')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='level_1', data=df)\n",
    "plt.title('Distribution of Level 1 Comments')\n",
    "plt.show()\n",
    "\n",
    "# Encode labels\n",
    "labels_combined = df[['level_0', 'level_1', 'level_2', 'level_3', 'level_4']].values\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_encoded = mlb.fit_transform(labels_combined)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "comments = df['comment_full_text'].values\n",
    "train_comments, val_comments, train_labels, val_labels = train_test_split(comments, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create dataset class\n",
    "class CommentsDataset(Dataset):\n",
    "    def __init__(self, comments, labels, tokenizer, max_len):\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        comment = self.comments[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'comment_text': comment,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create dataset and data loaders\n",
    "train_dataset_aug = CommentsDataset(comments=train_comments, labels=train_labels, tokenizer=tokenizer, max_len=128)\n",
    "val_dataset_aug = CommentsDataset(comments=val_comments, labels=val_labels, tokenizer=tokenizer, max_len=128)\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=16, shuffle=True)\n",
    "val_loader_aug = DataLoader(val_dataset_aug, batch_size=16, shuffle=False)\n",
    "\n",
    "# Define the Capsule Layer\n",
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, num_routes, in_channels, out_channels):\n",
    "        super(CapsuleLayer, self).__init__()\n",
    "        self.num_capsules = num_capsules\n",
    "        self.num_routes = num_routes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.capsules = nn.ModuleList([nn.Linear(in_channels, out_channels) for _ in range(num_capsules)])\n",
    "        self.bn = nn.ModuleList([nn.BatchNorm1d(out_channels) for _ in range(num_capsules)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        u = [self.bn[i](capsule(x)).unsqueeze(2) for i, capsule in enumerate(self.capsules)]\n",
    "        u = torch.cat(u, dim=2)\n",
    "        u = u.view(x.size(0), self.num_capsules, -1)\n",
    "        return self.squash(u)\n",
    "    \n",
    "    def squash(self, x, dim=-1):\n",
    "        squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        return scale * x / torch.sqrt(squared_norm)\n",
    "\n",
    "# Define the model\n",
    "class HierarchicalCapsuleNetworkBERTBase(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(HierarchicalCapsuleNetworkBERTBase, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=768, in_channels=768, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(16 * 10 * 1, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# Define the number of labels\n",
    "num_labels = labels_encoded.shape[1]\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-5  # Lower learning rate\n",
    "batch_size = 16  # Smaller batch size to handle memory issues\n",
    "\n",
    "# Model, criterion, and optimizer\n",
    "model = HierarchicalCapsuleNetworkBERTBase(num_labels=num_labels).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "best_val_loss_aug = float('inf')\n",
    "epochs_no_improve_aug = 0\n",
    "patience = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_aug = train_epoch(model, train_loader_aug, criterion, optimizer, device, class_weights_tensor)\n",
    "    val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss_aug:.4f}, Val Loss: {val_loss_aug:.4f}\")\n",
    "\n",
    "    if val_loss_aug < best_val_loss_aug:\n",
    "        best_val_loss_aug = val_loss_aug\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights_aug_bert_base.pth')\n",
    "        epochs_no_improve_aug = 0\n",
    "    else:\n",
    "        epochs_no_improve_aug += 1\n",
    "\n",
    "    if epochs_no_improve_aug >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_with_weights_aug_bert_base.pth'))\n",
    "accuracy_aug, precision_aug, recall_aug, f1_aug = evaluate_model(model, val_loader_aug, device)\n",
    "print(f\"Accuracy: {accuracy_aug:.4f}, Precision: {precision_aug:.4f}, Recall: {recall_aug:.4f}, F1-Score: {f1_aug:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23c8df-c3bd-4475-b4a8-ac6e547d4579",
   "metadata": {},
   "source": [
    "Implementing Gradient Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4116d618-b298-45de-9c21-2033951898bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 5.4315, Val Loss: 0.6197\n",
      "Epoch 2, Train Loss: 5.1016, Val Loss: 0.5780\n",
      "Epoch 3, Train Loss: 4.9551, Val Loss: 0.5752\n",
      "Epoch 4, Train Loss: 4.7939, Val Loss: 0.5543\n",
      "Epoch 5, Train Loss: 4.6827, Val Loss: 0.5252\n",
      "Epoch 6, Train Loss: 4.5554, Val Loss: 0.5242\n",
      "Epoch 7, Train Loss: 4.4409, Val Loss: 0.4973\n",
      "Epoch 8, Train Loss: 4.3601, Val Loss: 0.5132\n",
      "Epoch 9, Train Loss: 4.2428, Val Loss: 0.4880\n",
      "Epoch 10, Train Loss: 4.1474, Val Loss: 0.4815\n",
      "Accuracy: 0.1872, Precision: 0.3762, Recall: 0.5505, F1-Score: 0.4086\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Hyperparameters\n",
    "gradient_accumulation_steps = 2  # Accumulate gradients over this many steps\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = HierarchicalCapsuleNetworkBERTBase(num_labels=num_labels).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Adjust the train_epoch function to use gradient accumulation\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device, class_weights, accumulation_steps):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, batch in enumerate(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).float()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Apply class weights\n",
    "        weighted_loss = (loss * class_weights).mean()\n",
    "        weighted_loss.backward()\n",
    "\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += weighted_loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Training Loop with Early Stopping\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "patience = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device, class_weights_tensor, gradient_accumulation_steps)\n",
    "    val_loss = eval_model(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights_aug_bert_base.pth')\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_with_weights_aug_bert_base.pth'))\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, val_loader, device)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b194592-7189-4fc6-a42a-8cc5926d72de",
   "metadata": {},
   "source": [
    "Adjust class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "316a195a-9c7c-41d7-b87e-56af19b4a9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights for multi-label classification\n",
    "class_weights = np.zeros(labels_encoded.shape[1])\n",
    "for i in range(labels_encoded.shape[1]):\n",
    "    class_weights[i] = compute_class_weight('balanced', classes=[0, 1], y=train_labels[:, i]).tolist()[1]\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define the BCEWithLogitsLoss with class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20542e-c199-4fe7-8aec-687629f067af",
   "metadata": {},
   "source": [
    "Define a Model with Increased Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b11bde2-5f32-4848-97f4-4df8d612adbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, criterion, optimizer, device, class_weights, accumulation_steps):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, batch in enumerate(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).float()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Apply class weights\n",
    "        weighted_loss = (loss * class_weights).mean()\n",
    "        weighted_loss.backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += weighted_loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf64c92-f5be-43e9-aa03-7953b202da31",
   "metadata": {},
   "source": [
    "Training Loop with Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40806211-b150-4999-b441-fb59f973cc41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 10.9460, Val Loss: 0.6781\n",
      "Epoch 2, Train Loss: 10.0836, Val Loss: 0.6665\n",
      "Epoch 3, Train Loss: 9.6265, Val Loss: 0.6519\n",
      "Epoch 4, Train Loss: 9.2781, Val Loss: 0.6360\n",
      "Epoch 5, Train Loss: 9.0067, Val Loss: 0.6275\n",
      "Epoch 6, Train Loss: 8.8200, Val Loss: 0.6142\n",
      "Epoch 7, Train Loss: 8.5984, Val Loss: 0.6087\n",
      "Epoch 8, Train Loss: 8.4320, Val Loss: 0.6074\n",
      "Epoch 9, Train Loss: 8.2020, Val Loss: 0.5991\n",
      "Epoch 10, Train Loss: 8.0860, Val Loss: 0.5959\n",
      "Accuracy: 0.1642, Precision: 0.4238, Recall: 0.7588, F1-Score: 0.5085\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "num_epochs = 10\n",
    "best_val_loss_aug = float('inf')\n",
    "epochs_no_improve_aug = 0\n",
    "accumulation_steps = 2  # Set accumulation steps\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_aug = train_epoch(model, train_loader_aug, criterion, optimizer, device, class_weights_tensor, accumulation_steps)\n",
    "    val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss_aug:.4f}, Val Loss: {val_loss_aug:.4f}\")\n",
    "\n",
    "    if val_loss_aug < best_val_loss_aug:\n",
    "        best_val_loss_aug = val_loss_aug\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights_aug_bert_base.pth')\n",
    "        epochs_no_improve_aug = 0\n",
    "    else:\n",
    "        epochs_no_improve_aug += 1\n",
    "\n",
    "    if epochs_no_improve_aug >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model_with_weights_aug_bert_base.pth'))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_aug, precision_aug, recall_aug, f1_aug = evaluate_model(model, val_loader_aug, device)\n",
    "print(f\"Accuracy: {accuracy_aug:.4f}, Precision: {precision_aug:.4f}, Recall: {recall_aug:.4f}, F1-Score: {f1_aug:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2f887-d661-47fc-9a6a-fdb21435414f",
   "metadata": {},
   "source": [
    "The results show that the model's loss is decreasing, indicating that it is learning. However, the accuracy is still quite low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d6b741-9fb6-4aa3-aa72-cac333182cb4",
   "metadata": {},
   "source": [
    "Define the Updated Model with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0a46e78-b296-4492-b62b-1821f3555d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, num_routes, in_channels, out_channels):\n",
    "        super(CapsuleLayer, self).__init__()\n",
    "        self.num_capsules = num_capsules\n",
    "        self.num_routes = num_routes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.capsules = nn.ModuleList([nn.Linear(in_channels, out_channels) for _ in range(num_capsules)])\n",
    "        self.bn = nn.ModuleList([nn.BatchNorm1d(out_channels) for _ in range(num_capsules)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        u = [self.bn[i](capsule(x)).unsqueeze(2) for i, capsule in enumerate(self.capsules)]\n",
    "        u = torch.cat(u, dim=2)\n",
    "        u = u.view(x.size(0), self.num_capsules, -1)\n",
    "        return self.squash(u)\n",
    "    \n",
    "    def squash(self, x, dim=-1):\n",
    "        squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        return scale * x / torch.sqrt(squared_norm)\n",
    "\n",
    "class HierarchicalCapsuleNetworkBERTBase(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(HierarchicalCapsuleNetworkBERTBase, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=768, in_channels=768, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(16 * 10 * 1, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b926d8-4f84-426f-9f0e-ae43a057fcb0",
   "metadata": {},
   "source": [
    "Define the Training Loop with a Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1905870-334a-4c87-8fed-b49303f29b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 10.8224, Val Loss: 0.6489\n",
      "Epoch 2, Train Loss: 10.4424, Val Loss: 0.6321\n",
      "Epoch 3, Train Loss: 10.2557, Val Loss: 0.6223\n",
      "Epoch 4, Train Loss: 10.0989, Val Loss: 0.6092\n",
      "Epoch 5, Train Loss: 9.9636, Val Loss: 0.6019\n",
      "Epoch 6, Train Loss: 9.8577, Val Loss: 0.5882\n",
      "Epoch 7, Train Loss: 9.7594, Val Loss: 0.5858\n",
      "Epoch 8, Train Loss: 9.6666, Val Loss: 0.5813\n",
      "Epoch 9, Train Loss: 9.5767, Val Loss: 0.5811\n",
      "Epoch 10, Train Loss: 9.4969, Val Loss: 0.5649\n",
      "Accuracy: 0.1682, Precision: 0.3199, Recall: 0.4184, F1-Score: 0.3377\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-5  # Lower learning rate\n",
    "batch_size = 16  # Smaller batch size to handle memory issues\n",
    "\n",
    "# DataLoaders\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=batch_size, shuffle=True)\n",
    "val_loader_aug = DataLoader(val_dataset_aug, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Model, criterion, and optimizer\n",
    "model = HierarchicalCapsuleNetworkBERTBase(num_labels=num_labels).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the number of training steps\n",
    "total_steps = len(train_loader_aug) * num_epochs\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "best_val_loss_aug = float('inf')\n",
    "epochs_no_improve_aug = 0\n",
    "patience = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_aug = train_epoch(model, train_loader_aug, criterion, optimizer, device, class_weights_tensor, accumulation_steps=2)\n",
    "    val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss_aug:.4f}, Val Loss: {val_loss_aug:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_loss_aug < best_val_loss_aug:\n",
    "        best_val_loss_aug = val_loss_aug\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights_aug_bert_base.pth')\n",
    "        epochs_no_improve_aug = 0\n",
    "    else:\n",
    "        epochs_no_improve_aug += 1\n",
    "\n",
    "    if epochs_no_improve_aug >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_with_weights_aug_bert_base.pth'))\n",
    "accuracy_aug, precision_aug, recall_aug, f1_aug = evaluate_model(model, val_loader_aug, device)\n",
    "print(f\"Accuracy: {accuracy_aug:.4f}, Precision: {precision_aug:.4f}, Recall: {recall_aug:.4f}, F1-Score: {f1_aug:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e365f-7ed5-44e9-8f03-b43bfde36ed2",
   "metadata": {},
   "source": [
    "Updated Training Loop with More Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27e94cf7-ff28-4717-a531-706f350e9f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 9.3937, Val Loss: 0.5678\n",
      "Epoch 2, Train Loss: 9.3717, Val Loss: 0.5653\n",
      "Epoch 3, Train Loss: 9.2917, Val Loss: 0.5573\n",
      "Epoch 4, Train Loss: 9.2245, Val Loss: 0.5554\n",
      "Epoch 5, Train Loss: 9.1218, Val Loss: 0.5470\n",
      "Epoch 6, Train Loss: 9.0700, Val Loss: 0.5431\n",
      "Epoch 7, Train Loss: 9.0166, Val Loss: 0.5528\n",
      "Epoch 8, Train Loss: 8.9724, Val Loss: 0.5319\n",
      "Epoch 9, Train Loss: 8.9041, Val Loss: 0.5665\n",
      "Epoch 10, Train Loss: 8.8303, Val Loss: 0.5318\n",
      "Epoch 11, Train Loss: 8.7965, Val Loss: 0.5232\n",
      "Epoch 12, Train Loss: 8.7276, Val Loss: 0.5161\n",
      "Epoch 13, Train Loss: 8.6642, Val Loss: 0.5167\n",
      "Epoch 14, Train Loss: 8.6037, Val Loss: 0.5187\n",
      "Epoch 15, Train Loss: 8.5393, Val Loss: 0.5162\n",
      "Early stopping triggered\n",
      "Accuracy: 0.1762, Precision: 0.3217, Recall: 0.4162, F1-Score: 0.3407\n"
     ]
    }
   ],
   "source": [
    "# Updated Training Loop with More Epochs\n",
    "num_epochs = 20  # Increase the number of epochs\n",
    "best_val_loss_aug = float('inf')\n",
    "epochs_no_improve_aug = 0\n",
    "patience = 3  # You can also increase the patience if necessary\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_aug = train_epoch(model, train_loader_aug, criterion, optimizer, device, class_weights_tensor, accumulation_steps=2)\n",
    "    val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss_aug:.4f}, Val Loss: {val_loss_aug:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_loss_aug < best_val_loss_aug:\n",
    "        best_val_loss_aug = val_loss_aug\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights_aug_bert_base.pth')\n",
    "        epochs_no_improve_aug = 0\n",
    "    else:\n",
    "        epochs_no_improve_aug += 1\n",
    "\n",
    "    if epochs_no_improve_aug >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_with_weights_aug_bert_base.pth'))\n",
    "accuracy_aug, precision_aug, recall_aug, f1_aug = evaluate_model(model, val_loader_aug, device)\n",
    "print(f\"Accuracy: {accuracy_aug:.4f}, Precision: {precision_aug:.4f}, Recall: {recall_aug:.4f}, F1-Score: {f1_aug:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c696d8a-3ca9-4ba6-a67e-4c8142a2d8df",
   "metadata": {},
   "source": [
    "Implement Weight Decay Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ab8db1e-ee70-4f75-8cac-35f99c8e6b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 8.6348, Val Loss: 0.5233\n",
      "Epoch 2, Train Loss: 8.5701, Val Loss: 0.5148\n",
      "Epoch 3, Train Loss: 8.5412, Val Loss: 0.5221\n",
      "Epoch 4, Train Loss: 8.4944, Val Loss: 0.5077\n",
      "Epoch 5, Train Loss: 8.4213, Val Loss: 0.5108\n",
      "Epoch 6, Train Loss: 8.3649, Val Loss: 0.5018\n",
      "Epoch 7, Train Loss: 8.3135, Val Loss: 0.4831\n",
      "Epoch 8, Train Loss: 8.2961, Val Loss: 0.5084\n",
      "Epoch 9, Train Loss: 8.2613, Val Loss: 0.4905\n",
      "Epoch 10, Train Loss: 8.1510, Val Loss: 0.4777\n",
      "Epoch 11, Train Loss: 8.1260, Val Loss: 0.4815\n",
      "Epoch 12, Train Loss: 8.1158, Val Loss: 0.4716\n",
      "Epoch 13, Train Loss: 8.0196, Val Loss: 0.4673\n",
      "Epoch 14, Train Loss: 7.9411, Val Loss: 0.4665\n",
      "Epoch 15, Train Loss: 7.9421, Val Loss: 0.4699\n",
      "Epoch 16, Train Loss: 7.8276, Val Loss: 0.4676\n",
      "Epoch 17, Train Loss: 7.8185, Val Loss: 0.4585\n",
      "Epoch 18, Train Loss: 7.7874, Val Loss: 0.4544\n",
      "Epoch 19, Train Loss: 7.7066, Val Loss: 0.4496\n",
      "Epoch 20, Train Loss: 7.6757, Val Loss: 0.4556\n",
      "Accuracy: 0.1852, Precision: 0.3483, Recall: 0.3713, F1-Score: 0.3485\n"
     ]
    }
   ],
   "source": [
    "# Model, criterion, and optimizer with weight decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)  # Add weight decay\n",
    "\n",
    "# Training Loop with Weight Decay\n",
    "num_epochs = 20  # Increase the number of epochs\n",
    "best_val_loss_aug = float('inf')\n",
    "epochs_no_improve_aug = 0\n",
    "patience = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_aug = train_epoch(model, train_loader_aug, criterion, optimizer, device, class_weights_tensor, accumulation_steps=2)\n",
    "    val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss_aug:.4f}, Val Loss: {val_loss_aug:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_loss_aug < best_val_loss_aug:\n",
    "        best_val_loss_aug = val_loss_aug\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights_aug_bert_base.pth')\n",
    "        epochs_no_improve_aug = 0\n",
    "    else:\n",
    "        epochs_no_improve_aug += 1\n",
    "\n",
    "    if epochs_no_improve_aug >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_with_weights_aug_bert_base.pth'))\n",
    "accuracy_aug, precision_aug, recall_aug, f1_aug = evaluate_model(model, val_loader_aug, device)\n",
    "print(f\"Accuracy: {accuracy_aug:.4f}, Precision: {precision_aug:.4f}, Recall: {recall_aug:.4f}, F1-Score: {f1_aug:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e10e3-5912-4cd6-8d9f-f4314f70f5aa",
   "metadata": {},
   "source": [
    "To further improve the F1 score and accuracy, consider the following advanced techniques:\n",
    "\n",
    "Use a Larger Pre-trained Model: Switching to a larger pre-trained model like BERT-large can significantly improve performance.\n",
    "\n",
    "Advanced Regularization Techniques: Implementing dropout, layer normalization, and weight decay effectively.\n",
    "\n",
    "Handling Imbalanced Data: Ensuring balanced class distribution during training can help improve the model's performance.\n",
    "\n",
    "Ensemble Methods: Combining multiple models to form an ensemble can help capture more nuances in the data.\n",
    "\n",
    "Hyperparameter Tuning: Continue optimizing hyperparameters using techniques like Optuna.\n",
    "\n",
    "Data Augmentation: Further augmenting the training data can help improve generalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412358cf-c57a-4d96-ba45-08c4c283ab55",
   "metadata": {},
   "source": [
    "Using BERT-large and Advanced Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcb0cd9c-13ee-46b6-a2dd-e57d8b2a8466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 14.2205, Val Loss: 0.8594\n",
      "Epoch 2, Train Loss: 13.3803, Val Loss: 0.8274\n",
      "Epoch 3, Train Loss: 12.9533, Val Loss: 0.8104\n",
      "Epoch 4, Train Loss: 12.6602, Val Loss: 0.8016\n",
      "Epoch 5, Train Loss: 12.4142, Val Loss: 0.7902\n",
      "Epoch 6, Train Loss: 12.2398, Val Loss: 0.7847\n",
      "Epoch 7, Train Loss: 12.0663, Val Loss: 0.7770\n",
      "Epoch 8, Train Loss: 11.8990, Val Loss: 0.7750\n",
      "Epoch 9, Train Loss: 11.7695, Val Loss: 0.7704\n",
      "Epoch 10, Train Loss: 11.6557, Val Loss: 0.7668\n",
      "Epoch 11, Train Loss: 11.4985, Val Loss: 0.7666\n",
      "Epoch 12, Train Loss: 11.4230, Val Loss: 0.7596\n",
      "Epoch 13, Train Loss: 11.3047, Val Loss: 0.7592\n",
      "Epoch 14, Train Loss: 11.2224, Val Loss: 0.7578\n",
      "Epoch 15, Train Loss: 11.1196, Val Loss: 0.7570\n",
      "Epoch 16, Train Loss: 11.0371, Val Loss: 0.7502\n",
      "Epoch 17, Train Loss: 10.9381, Val Loss: 0.7508\n",
      "Epoch 18, Train Loss: 10.8521, Val Loss: 0.7498\n",
      "Epoch 19, Train Loss: 10.7485, Val Loss: 0.7519\n",
      "Epoch 20, Train Loss: 10.6945, Val Loss: 0.7468\n",
      "Accuracy: 0.0180, Precision: 0.3613, Recall: 0.8154, F1-Score: 0.4462\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Define the improved model with BERT-large\n",
    "class HierarchicalCapsuleNetworkBERTLarge(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(HierarchicalCapsuleNetworkBERTLarge, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=1024, in_channels=1024, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(16 * 10 * 1, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Update the dataset class for BERT-large\n",
    "class CommentsDataset(Dataset):\n",
    "    def __init__(self, comments, labels, tokenizer, max_len):\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        comment = self.comments[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'comment_text': comment,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create dataset and data loaders\n",
    "train_dataset_aug = CommentsDataset(comments=train_comments_aug, labels=train_labels_aug, tokenizer=tokenizer, max_len=128)\n",
    "val_dataset_aug = CommentsDataset(comments=val_comments_aug, labels=val_labels_aug, tokenizer=tokenizer, max_len=128)\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=16, shuffle=True)\n",
    "val_loader_aug = DataLoader(val_dataset_aug, batch_size=16, shuffle=False)\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = HierarchicalCapsuleNetworkBERTLarge(num_labels=num_labels).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# Define the number of training steps\n",
    "total_steps = len(train_loader_aug) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Training loop with early stopping\n",
    "num_epochs = 20\n",
    "best_val_loss_aug = float('inf')\n",
    "epochs_no_improve_aug = 0\n",
    "patience = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_aug = train_epoch(model, train_loader_aug, criterion, optimizer, device, class_weights_tensor, accumulation_steps=2)\n",
    "    val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss_aug:.4f}, Val Loss: {val_loss_aug:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_loss_aug < best_val_loss_aug:\n",
    "        best_val_loss_aug = val_loss_aug\n",
    "        torch.save(model.state_dict(), 'best_model_with_weights_aug_bert_large.pth')\n",
    "        epochs_no_improve_aug = 0\n",
    "    else:\n",
    "        epochs_no_improve_aug += 1\n",
    "\n",
    "    if epochs_no_improve_aug >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_with_weights_aug_bert_large.pth'))\n",
    "accuracy_aug, precision_aug, recall_aug, f1_aug = evaluate_model(model, val_loader_aug, device)\n",
    "print(f\"Accuracy: {accuracy_aug:.4f}, Precision: {precision_aug:.4f}, Recall: {recall_aug:.4f}, F1-Score: {f1_aug:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c497e30-2e7f-4304-bfd3-3f18dfeb4c05",
   "metadata": {},
   "source": [
    "Further Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61825119-8071-445e-8b88-0041983a84ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-30 17:02:33,689] A new study created in memory with name: no-name-07b19300-52e9-4f53-acd2-f66e4989f8ca\n",
      "[I 2024-06-30 17:08:03,412] Trial 0 finished with value: 0.7461080410901237 and parameters: {'learning_rate': 6.471252446540611e-05, 'batch_size': 30, 'dropout_rate': 0.3725932585908288}. Best is trial 0 with value: 0.7461080410901237.\n",
      "[I 2024-06-30 17:13:42,136] Trial 1 finished with value: 0.8625087373786502 and parameters: {'learning_rate': 2.329881938051178e-06, 'batch_size': 28, 'dropout_rate': 0.2055150226356023}. Best is trial 0 with value: 0.7461080410901237.\n",
      "[I 2024-06-30 17:19:17,352] Trial 2 finished with value: 0.7967782241957528 and parameters: {'learning_rate': 1.23859304562617e-05, 'batch_size': 29, 'dropout_rate': 0.32950236035766023}. Best is trial 0 with value: 0.7461080410901237.\n",
      "[I 2024-06-30 17:25:13,485] Trial 3 finished with value: 0.7587194585088474 and parameters: {'learning_rate': 2.2166842536254307e-05, 'batch_size': 15, 'dropout_rate': 0.19111524096660043}. Best is trial 0 with value: 0.7461080410901237.\n",
      "[I 2024-06-30 17:30:59,530] Trial 4 finished with value: 0.7382106197916943 and parameters: {'learning_rate': 5.822654007917762e-05, 'batch_size': 22, 'dropout_rate': 0.38192916353140205}. Best is trial 4 with value: 0.7382106197916943.\n",
      "[I 2024-06-30 17:36:35,029] Trial 5 finished with value: 0.76980368409838 and parameters: {'learning_rate': 2.7518086990501414e-05, 'batch_size': 29, 'dropout_rate': 0.3193635675425587}. Best is trial 4 with value: 0.7382106197916943.\n",
      "[I 2024-06-30 17:42:13,874] Trial 6 finished with value: 0.8415960503949059 and parameters: {'learning_rate': 3.880514823511324e-06, 'batch_size': 28, 'dropout_rate': 0.3313832090674834}. Best is trial 4 with value: 0.7382106197916943.\n",
      "[I 2024-06-30 17:48:24,273] Trial 7 finished with value: 0.786381425956885 and parameters: {'learning_rate': 5.126693842526073e-05, 'batch_size': 14, 'dropout_rate': 0.2551281904997066}. Best is trial 4 with value: 0.7382106197916943.\n",
      "[I 2024-06-30 17:54:23,894] Trial 8 finished with value: 0.8449005292633832 and parameters: {'learning_rate': 2.6119220112824222e-06, 'batch_size': 17, 'dropout_rate': 0.17603089515724113}. Best is trial 4 with value: 0.7382106197916943.\n",
      "[I 2024-06-30 18:00:28,952] Trial 9 finished with value: 0.7642759788036346 and parameters: {'learning_rate': 1.583530322731072e-05, 'batch_size': 10, 'dropout_rate': 0.3979857334274781}. Best is trial 4 with value: 0.7382106197916943.\n",
      "[I 2024-06-30 18:06:14,879] Trial 10 finished with value: 0.8067197929257932 and parameters: {'learning_rate': 7.213008138198517e-06, 'batch_size': 22, 'dropout_rate': 0.4923260452105132}. Best is trial 4 with value: 0.7382106197916943.\n",
      "[I 2024-06-30 18:11:52,548] Trial 11 finished with value: 0.7256882407448508 and parameters: {'learning_rate': 7.463137938419832e-05, 'batch_size': 23, 'dropout_rate': 0.4214214480979091}. Best is trial 11 with value: 0.7256882407448508.\n",
      "[I 2024-06-30 18:17:30,092] Trial 12 finished with value: 0.7664328854192387 and parameters: {'learning_rate': 8.614474526404834e-05, 'batch_size': 23, 'dropout_rate': 0.4530111135103435}. Best is trial 11 with value: 0.7256882407448508.\n",
      "[I 2024-06-30 18:23:07,620] Trial 13 finished with value: 0.7549239193851297 and parameters: {'learning_rate': 3.6802656359399046e-05, 'batch_size': 23, 'dropout_rate': 0.4324157786216658}. Best is trial 11 with value: 0.7256882407448508.\n",
      "[I 2024-06-30 18:28:56,722] Trial 14 finished with value: 0.7241549154497543 and parameters: {'learning_rate': 9.876123724279424e-05, 'batch_size': 19, 'dropout_rate': 0.38479429062497467}. Best is trial 14 with value: 0.7241549154497543.\n",
      "[I 2024-06-30 18:34:45,700] Trial 15 finished with value: 0.885380109505994 and parameters: {'learning_rate': 1.0911899058185565e-06, 'batch_size': 18, 'dropout_rate': 0.2625336419990187}. Best is trial 14 with value: 0.7241549154497543.\n",
      "[I 2024-06-30 18:40:22,353] Trial 16 finished with value: 0.7196855992078781 and parameters: {'learning_rate': 7.982487079172157e-05, 'batch_size': 25, 'dropout_rate': 0.11822056212249324}. Best is trial 16 with value: 0.7196855992078781.\n",
      "[I 2024-06-30 18:45:57,154] Trial 17 finished with value: 0.7137139332600129 and parameters: {'learning_rate': 9.00873469960247e-05, 'batch_size': 26, 'dropout_rate': 0.10228576247508345}. Best is trial 17 with value: 0.7137139332600129.\n",
      "[I 2024-06-30 18:51:31,798] Trial 18 finished with value: 0.7545915032044436 and parameters: {'learning_rate': 3.715943597725957e-05, 'batch_size': 26, 'dropout_rate': 0.10199669729789625}. Best is trial 17 with value: 0.7137139332600129.\n",
      "[I 2024-06-30 18:57:07,413] Trial 19 finished with value: 0.7681919045937367 and parameters: {'learning_rate': 1.9428632104489886e-05, 'batch_size': 26, 'dropout_rate': 0.10842189695456457}. Best is trial 17 with value: 0.7137139332600129.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 9.00873469960247e-05, 'batch_size': 26, 'dropout_rate': 0.10228576247508345}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # Suggest hyperparameters\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-4, log=True)\n",
    "        batch_size = trial.suggest_int('batch_size', 8, 32)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "\n",
    "        # Ensure batch size is greater than 1\n",
    "        batch_size = max(batch_size, 2)\n",
    "\n",
    "        # Create model with suggested hyperparameters\n",
    "        class HierarchicalCapsuleNetworkBERTLarge(nn.Module):\n",
    "            def __init__(self, num_labels):\n",
    "                super(HierarchicalCapsuleNetworkBERTLarge, self).__init__()\n",
    "                self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "                self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=1024, in_channels=1024, out_channels=16)\n",
    "                self.dropout = nn.Dropout(p=dropout_rate)\n",
    "                self.fc = nn.Linear(16 * 10 * 1, num_labels)\n",
    "            \n",
    "            def forward(self, input_ids, attention_mask):\n",
    "                outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                x = outputs.last_hidden_state[:, 0, :]\n",
    "                x = self.capsule_layer(x)\n",
    "                x = x.view(x.size(0), -1)\n",
    "                x = self.dropout(x)\n",
    "                logits = self.fc(x)\n",
    "                return logits\n",
    "\n",
    "        model = HierarchicalCapsuleNetworkBERTLarge(num_labels=num_labels).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        train_loader_aug = DataLoader(train_dataset_aug, batch_size=batch_size, shuffle=True)\n",
    "        val_loader_aug = DataLoader(val_dataset_aug, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Train the model for a few epochs\n",
    "        num_epochs = 5\n",
    "        best_val_loss = float('inf')\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = train_epoch(model, train_loader_aug, criterion, optimizer, device, class_weights_tensor, accumulation_steps=2)\n",
    "            val_loss = eval_model(model, val_loader_aug, criterion, device)\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "        return best_val_loss\n",
    "    \n",
    "    except ValueError as e:\n",
    "        if \"Expected more than 1 value per channel\" in str(e):\n",
    "            # Return a high loss value if this specific error occurs\n",
    "            return float('inf')\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "# Create a study and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6592a9-9dc3-43df-83f5-bad01ed4f85a",
   "metadata": {},
   "source": [
    "Train Multiple Models with Ensemble Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d423dd0-f554-4514-b19b-b89cab4b3bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.0030, Precision: 0.5988, Recall: 0.7263, F1-Score: 0.6197\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the best hyperparameters\n",
    "best_learning_rate = 9.00873469960247e-05\n",
    "best_batch_size = 26\n",
    "best_dropout_rate = 0.10228576247508345\n",
    "num_models = 3\n",
    "models = []\n",
    "\n",
    "# Create model class with best dropout rate\n",
    "class HierarchicalCapsuleNetworkBERTLarge(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(HierarchicalCapsuleNetworkBERTLarge, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=1024, in_channels=1024, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=best_dropout_rate)\n",
    "        self.fc = nn.Linear(16 * 10 * 1, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# Train multiple models with mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "for i in range(num_models):\n",
    "    model = HierarchicalCapsuleNetworkBERTLarge(num_labels=num_labels).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=best_learning_rate)\n",
    "    \n",
    "    best_val_loss_aug = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_aug = 0\n",
    "        for batch in train_loader_aug:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss_aug += loss.item()\n",
    "        \n",
    "        train_loss_aug /= len(train_loader_aug)\n",
    "        val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "        \n",
    "        if val_loss_aug < best_val_loss_aug:\n",
    "            best_val_loss_aug = val_loss_aug\n",
    "            torch.save(model.state_dict(), f'best_model_with_weights_aug_bert_large_{i}.pth')\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'best_model_with_weights_aug_bert_large_{i}.pth'))\n",
    "    models.append(model)\n",
    "\n",
    "# Averaging predictions\n",
    "def ensemble_predict(models, data_loader, device):\n",
    "    all_preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "        all_preds.append(np.concatenate(preds, axis=0))\n",
    "    \n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds > 0.5  # Apply threshold\n",
    "\n",
    "# Evaluate the predictions\n",
    "def evaluate_predictions(predictions, true_labels):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Prepare validation labels\n",
    "val_labels = torch.cat([batch['labels'] for batch in val_loader_aug], dim=0).cpu().numpy()\n",
    "\n",
    "# Get ensemble predictions\n",
    "ensemble_preds = ensemble_predict(models, val_loader_aug, device)\n",
    "accuracy, precision, recall, f1 = evaluate_predictions(ensemble_preds, val_labels)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95c17f45-094c-47cd-b585-7a7b5875d9fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (999, 27), Labels shape: (999, 27)\n",
      "Sample predictions: [[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      " [0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      " [0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1]], Sample labels: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 1. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0.]]\n",
      "Ensemble Accuracy: 0.0260, Precision: 0.5976, Recall: 0.6455, F1-Score: 0.5963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Accuracy: 0.0000, Precision: 0.5471, Recall: 0.7442, F1-Score: 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Accuracy: 0.0000, Precision: 0.1981, Recall: 0.3388, F1-Score: 0.2453\n",
      "Model 3 - Accuracy: 0.0000, Precision: 0.1185, Recall: 0.1591, F1-Score: 0.1356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the best hyperparameters\n",
    "best_learning_rate = 9.00873469960247e-05\n",
    "best_batch_size = 26\n",
    "best_dropout_rate = 0.10228576247508345\n",
    "num_models = 3\n",
    "models = []\n",
    "\n",
    "# Create model class with best dropout rate\n",
    "class HierarchicalCapsuleNetworkBERTLarge(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(HierarchicalCapsuleNetworkBERTLarge, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=1024, in_channels=1024, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=best_dropout_rate)\n",
    "        self.fc = nn.Linear(16 * 10 * 1, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# Train multiple models with mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "for i in range(num_models):\n",
    "    model = HierarchicalCapsuleNetworkBERTLarge(num_labels=num_labels).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=best_learning_rate)\n",
    "    \n",
    "    best_val_loss_aug = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_aug = 0\n",
    "        for batch in train_loader_aug:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss_aug += loss.item()\n",
    "        \n",
    "        train_loss_aug /= len(train_loader_aug)\n",
    "        val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "        \n",
    "        if val_loss_aug < best_val_loss_aug:\n",
    "            best_val_loss_aug = val_loss_aug\n",
    "            torch.save(model.state_dict(), f'best_model_with_weights_aug_bert_large_{i}.pth')\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'best_model_with_weights_aug_bert_large_{i}.pth'))\n",
    "    models.append(model)\n",
    "\n",
    "# Averaging predictions\n",
    "def ensemble_predict(models, data_loader, device):\n",
    "    all_preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "        all_preds.append(np.concatenate(preds, axis=0))\n",
    "    \n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds > 0.5  # Apply threshold\n",
    "\n",
    "# Evaluate the predictions\n",
    "def evaluate_predictions(predictions, true_labels):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Prepare validation labels\n",
    "val_labels = torch.cat([batch['labels'] for batch in val_loader_aug], dim=0).cpu().numpy()\n",
    "\n",
    "# Get ensemble predictions\n",
    "ensemble_preds = ensemble_predict(models, val_loader_aug, device)\n",
    "\n",
    "# Ensure predictions are in the correct shape and binary format\n",
    "ensemble_preds = ensemble_preds.astype(int)\n",
    "\n",
    "# Debug: print shapes and a few samples\n",
    "print(f\"Predictions shape: {ensemble_preds.shape}, Labels shape: {val_labels.shape}\")\n",
    "print(f\"Sample predictions: {ensemble_preds[:10]}, Sample labels: {val_labels[:10]}\")\n",
    "\n",
    "accuracy, precision, recall, f1 = evaluate_predictions(ensemble_preds, val_labels)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Optional: evaluate individual models\n",
    "for i, model in enumerate(models):\n",
    "    model_preds = ensemble_predict([model], val_loader_aug, device).astype(int)\n",
    "    acc, prec, rec, f1_ind = evaluate_predictions(model_preds, val_labels)\n",
    "    print(f\"Model {i+1} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1_ind:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83d47e31-f52e-4002-91d1-ddd84accb243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (999, 27), Labels shape: (999, 27)\n",
      "Sample predictions: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]], Sample labels: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 1. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0.]]\n",
      "Ensemble Accuracy: 0.0000, Precision: 0.1185, Recall: 0.1585, F1-Score: 0.1356\n",
      "Class 0 Confusion Matrix:\n",
      "[[993   0]\n",
      " [  6   0]]\n",
      "Class 0 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       993\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.99       999\n",
      "   macro avg       0.50      0.50      0.50       999\n",
      "weighted avg       0.99      0.99      0.99       999\n",
      "\n",
      "Class 1 Confusion Matrix:\n",
      "[[861   0]\n",
      " [138   0]]\n",
      "Class 1 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.93       861\n",
      "         1.0       0.00      0.00      0.00       138\n",
      "\n",
      "    accuracy                           0.86       999\n",
      "   macro avg       0.43      0.50      0.46       999\n",
      "weighted avg       0.74      0.86      0.80       999\n",
      "\n",
      "Class 2 Confusion Matrix:\n",
      "[[890   0]\n",
      " [109   0]]\n",
      "Class 2 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94       890\n",
      "         1.0       0.00      0.00      0.00       109\n",
      "\n",
      "    accuracy                           0.89       999\n",
      "   macro avg       0.45      0.50      0.47       999\n",
      "weighted avg       0.79      0.89      0.84       999\n",
      "\n",
      "Class 3 Confusion Matrix:\n",
      "[[915   0]\n",
      " [ 84   0]]\n",
      "Class 3 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96       915\n",
      "         1.0       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.92       999\n",
      "   macro avg       0.46      0.50      0.48       999\n",
      "weighted avg       0.84      0.92      0.88       999\n",
      "\n",
      "Class 4 Confusion Matrix:\n",
      "[[752   0]\n",
      " [247   0]]\n",
      "Class 4 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86       752\n",
      "         1.0       0.00      0.00      0.00       247\n",
      "\n",
      "    accuracy                           0.75       999\n",
      "   macro avg       0.38      0.50      0.43       999\n",
      "weighted avg       0.57      0.75      0.65       999\n",
      "\n",
      "Class 5 Confusion Matrix:\n",
      "[[704   0]\n",
      " [295   0]]\n",
      "Class 5 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      1.00      0.83       704\n",
      "         1.0       0.00      0.00      0.00       295\n",
      "\n",
      "    accuracy                           0.70       999\n",
      "   macro avg       0.35      0.50      0.41       999\n",
      "weighted avg       0.50      0.70      0.58       999\n",
      "\n",
      "Class 6 Confusion Matrix:\n",
      "[[969   0]\n",
      " [ 30   0]]\n",
      "Class 6 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       969\n",
      "         1.0       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.97       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.94      0.97      0.96       999\n",
      "\n",
      "Class 7 Confusion Matrix:\n",
      "[[967   0]\n",
      " [ 32   0]]\n",
      "Class 7 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       967\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.97       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.94      0.97      0.95       999\n",
      "\n",
      "Class 8 Confusion Matrix:\n",
      "[[937   0]\n",
      " [ 62   0]]\n",
      "Class 8 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97       937\n",
      "         1.0       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.94       999\n",
      "   macro avg       0.47      0.50      0.48       999\n",
      "weighted avg       0.88      0.94      0.91       999\n",
      "\n",
      "Class 9 Confusion Matrix:\n",
      "[[934   0]\n",
      " [ 65   0]]\n",
      "Class 9 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.97       934\n",
      "         1.0       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.93       999\n",
      "   macro avg       0.47      0.50      0.48       999\n",
      "weighted avg       0.87      0.93      0.90       999\n",
      "\n",
      "Class 10 Confusion Matrix:\n",
      "[[751   0]\n",
      " [248   0]]\n",
      "Class 10 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86       751\n",
      "         1.0       0.00      0.00      0.00       248\n",
      "\n",
      "    accuracy                           0.75       999\n",
      "   macro avg       0.38      0.50      0.43       999\n",
      "weighted avg       0.57      0.75      0.65       999\n",
      "\n",
      "Class 11 Confusion Matrix:\n",
      "[[956   0]\n",
      " [ 43   0]]\n",
      "Class 11 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       956\n",
      "         1.0       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.96       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.92      0.96      0.94       999\n",
      "\n",
      "Class 12 Confusion Matrix:\n",
      "[[929   0]\n",
      " [ 70   0]]\n",
      "Class 12 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       929\n",
      "         1.0       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.93       999\n",
      "   macro avg       0.46      0.50      0.48       999\n",
      "weighted avg       0.86      0.93      0.90       999\n",
      "\n",
      "Class 13 Confusion Matrix:\n",
      "[[491   0]\n",
      " [508   0]]\n",
      "Class 13 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      1.00      0.66       491\n",
      "         1.0       0.00      0.00      0.00       508\n",
      "\n",
      "    accuracy                           0.49       999\n",
      "   macro avg       0.25      0.50      0.33       999\n",
      "weighted avg       0.24      0.49      0.32       999\n",
      "\n",
      "Class 14 Confusion Matrix:\n",
      "[[657   0]\n",
      " [342   0]]\n",
      "Class 14 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      1.00      0.79       657\n",
      "         1.0       0.00      0.00      0.00       342\n",
      "\n",
      "    accuracy                           0.66       999\n",
      "   macro avg       0.33      0.50      0.40       999\n",
      "weighted avg       0.43      0.66      0.52       999\n",
      "\n",
      "Class 15 Confusion Matrix:\n",
      "[[977   0]\n",
      " [ 22   0]]\n",
      "Class 15 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       977\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.98       999\n",
      "   macro avg       0.49      0.50      0.49       999\n",
      "weighted avg       0.96      0.98      0.97       999\n",
      "\n",
      "Class 16 Confusion Matrix:\n",
      "[[797   0]\n",
      " [202   0]]\n",
      "Class 16 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89       797\n",
      "         1.0       0.00      0.00      0.00       202\n",
      "\n",
      "    accuracy                           0.80       999\n",
      "   macro avg       0.40      0.50      0.44       999\n",
      "weighted avg       0.64      0.80      0.71       999\n",
      "\n",
      "Class 17 Confusion Matrix:\n",
      "[[931   0]\n",
      " [ 68   0]]\n",
      "Class 17 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       931\n",
      "         1.0       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.93       999\n",
      "   macro avg       0.47      0.50      0.48       999\n",
      "weighted avg       0.87      0.93      0.90       999\n",
      "\n",
      "Class 18 Confusion Matrix:\n",
      "[[611   0]\n",
      " [388   0]]\n",
      "Class 18 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76       611\n",
      "         1.0       0.00      0.00      0.00       388\n",
      "\n",
      "    accuracy                           0.61       999\n",
      "   macro avg       0.31      0.50      0.38       999\n",
      "weighted avg       0.37      0.61      0.46       999\n",
      "\n",
      "Class 19 Confusion Matrix:\n",
      "[[996   0]\n",
      " [  3   0]]\n",
      "Class 19 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       996\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           1.00       999\n",
      "   macro avg       0.50      0.50      0.50       999\n",
      "weighted avg       0.99      1.00      1.00       999\n",
      "\n",
      "Class 20 Confusion Matrix:\n",
      "[[630   0]\n",
      " [369   0]]\n",
      "Class 20 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      1.00      0.77       630\n",
      "         1.0       0.00      0.00      0.00       369\n",
      "\n",
      "    accuracy                           0.63       999\n",
      "   macro avg       0.32      0.50      0.39       999\n",
      "weighted avg       0.40      0.63      0.49       999\n",
      "\n",
      "Class 21 Confusion Matrix:\n",
      "[[925   0]\n",
      " [ 74   0]]\n",
      "Class 21 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       925\n",
      "         1.0       0.00      0.00      0.00        74\n",
      "\n",
      "    accuracy                           0.93       999\n",
      "   macro avg       0.46      0.50      0.48       999\n",
      "weighted avg       0.86      0.93      0.89       999\n",
      "\n",
      "Class 22 Confusion Matrix:\n",
      "[[583   0]\n",
      " [416   0]]\n",
      "Class 22 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74       583\n",
      "         1.0       0.00      0.00      0.00       416\n",
      "\n",
      "    accuracy                           0.58       999\n",
      "   macro avg       0.29      0.50      0.37       999\n",
      "weighted avg       0.34      0.58      0.43       999\n",
      "\n",
      "Class 23 Confusion Matrix:\n",
      "[[969   0]\n",
      " [ 30   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 23 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       969\n",
      "         1.0       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.97       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.94      0.97      0.96       999\n",
      "\n",
      "Class 24 Confusion Matrix:\n",
      "[[918   0]\n",
      " [ 81   0]]\n",
      "Class 24 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96       918\n",
      "         1.0       0.00      0.00      0.00        81\n",
      "\n",
      "    accuracy                           0.92       999\n",
      "   macro avg       0.46      0.50      0.48       999\n",
      "weighted avg       0.84      0.92      0.88       999\n",
      "\n",
      "Class 25 Confusion Matrix:\n",
      "[[964   0]\n",
      " [ 35   0]]\n",
      "Class 25 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       964\n",
      "         1.0       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.96       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.93      0.96      0.95       999\n",
      "\n",
      "Class 26 Confusion Matrix:\n",
      "[[  0 252]\n",
      " [  0 747]]\n",
      "Class 26 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       252\n",
      "         1.0       0.75      1.00      0.86       747\n",
      "\n",
      "    accuracy                           0.75       999\n",
      "   macro avg       0.37      0.50      0.43       999\n",
      "weighted avg       0.56      0.75      0.64       999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Accuracy: 0.0000, Precision: 0.1733, Recall: 0.2662, F1-Score: 0.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Accuracy: 0.0000, Precision: 0.1580, Recall: 0.2940, F1-Score: 0.1928\n",
      "Model 3 - Accuracy: 0.0000, Precision: 0.2022, Recall: 0.3445, F1-Score: 0.2505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the best hyperparameters\n",
    "best_learning_rate = 9.00873469960247e-05\n",
    "best_batch_size = 26\n",
    "best_dropout_rate = 0.10228576247508345\n",
    "num_models = 3\n",
    "models = []\n",
    "\n",
    "# Create model class with best dropout rate\n",
    "class HierarchicalCapsuleNetworkBERTLarge(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(HierarchicalCapsuleNetworkBERTLarge, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=1024, in_channels=1024, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=best_dropout_rate)\n",
    "        self.fc = nn.Linear(16 * 10 * 1, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# Train multiple models with mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "for i in range(num_models):\n",
    "    model = HierarchicalCapsuleNetworkBERTLarge(num_labels=num_labels).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=best_learning_rate)\n",
    "    \n",
    "    best_val_loss_aug = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_aug = 0\n",
    "        for batch in train_loader_aug:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss_aug += loss.item()\n",
    "        \n",
    "        train_loss_aug /= len(train_loader_aug)\n",
    "        val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "        \n",
    "        if val_loss_aug < best_val_loss_aug:\n",
    "            best_val_loss_aug = val_loss_aug\n",
    "            torch.save(model.state_dict(), f'best_model_with_weights_aug_bert_large_{i}.pth')\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'best_model_with_weights_aug_bert_large_{i}.pth'))\n",
    "    models.append(model)\n",
    "\n",
    "# Averaging predictions\n",
    "def ensemble_predict(models, data_loader, device):\n",
    "    all_preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "        all_preds.append(np.concatenate(preds, axis=0))\n",
    "    \n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds > 0.5  # Apply threshold\n",
    "\n",
    "# Evaluate the predictions\n",
    "def evaluate_predictions(predictions, true_labels):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Prepare validation labels\n",
    "val_labels = torch.cat([batch['labels'] for batch in val_loader_aug], dim=0).cpu().numpy()\n",
    "\n",
    "# Get ensemble predictions\n",
    "ensemble_preds = ensemble_predict(models, val_loader_aug, device)\n",
    "\n",
    "# Ensure predictions are in the correct shape and binary format\n",
    "ensemble_preds = ensemble_preds.astype(int)\n",
    "\n",
    "# Debug: print shapes and a few samples\n",
    "print(f\"Predictions shape: {ensemble_preds.shape}, Labels shape: {val_labels.shape}\")\n",
    "print(f\"Sample predictions: {ensemble_preds[:10]}, Sample labels: {val_labels[:10]}\")\n",
    "\n",
    "accuracy, precision, recall, f1 = evaluate_predictions(ensemble_preds, val_labels)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "for i in range(val_labels.shape[1]):\n",
    "    print(f\"Class {i} Confusion Matrix:\\n{confusion_matrix(val_labels[:, i], ensemble_preds[:, i])}\")\n",
    "    print(f\"Class {i} Classification Report:\\n{classification_report(val_labels[:, i], ensemble_preds[:, i])}\")\n",
    "\n",
    "# Optional: evaluate individual models\n",
    "for i, model in enumerate(models):\n",
    "    model_preds = ensemble_predict([model], val_loader_aug, device).astype(int)\n",
    "    acc, prec, rec, f1_ind = evaluate_predictions(model_preds, val_labels)\n",
    "    print(f\"Model {i+1} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1_ind:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de36c0-4a8e-4974-a45d-ed5709dbf18b",
   "metadata": {},
   "source": [
    "ased on the results, it appears that the models are generally better at predicting some classes than others. The low ensemble accuracy suggests the models struggle with some of the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701911e4-7040-42fa-a5db-07fe88c2956f",
   "metadata": {},
   "source": [
    "Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93030e54-faf4-48d6-85cd-447720fe02db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (999, 27), Labels shape: (999, 27)\n",
      "Sample predictions: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]], Sample labels: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 1. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0.]]\n",
      "Ensemble Accuracy: 0.0000, Precision: 0.1552, Recall: 0.2467, F1-Score: 0.1875\n",
      "Class 0 Confusion Matrix:\n",
      "[[993   0]\n",
      " [  6   0]]\n",
      "Class 0 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       993\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.99       999\n",
      "   macro avg       0.50      0.50      0.50       999\n",
      "weighted avg       0.99      0.99      0.99       999\n",
      "\n",
      "Class 1 Confusion Matrix:\n",
      "[[861   0]\n",
      " [138   0]]\n",
      "Class 1 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.93       861\n",
      "         1.0       0.00      0.00      0.00       138\n",
      "\n",
      "    accuracy                           0.86       999\n",
      "   macro avg       0.43      0.50      0.46       999\n",
      "weighted avg       0.74      0.86      0.80       999\n",
      "\n",
      "Class 2 Confusion Matrix:\n",
      "[[890   0]\n",
      " [109   0]]\n",
      "Class 2 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94       890\n",
      "         1.0       0.00      0.00      0.00       109\n",
      "\n",
      "    accuracy                           0.89       999\n",
      "   macro avg       0.45      0.50      0.47       999\n",
      "weighted avg       0.79      0.89      0.84       999\n",
      "\n",
      "Class 3 Confusion Matrix:\n",
      "[[915   0]\n",
      " [ 84   0]]\n",
      "Class 3 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96       915\n",
      "         1.0       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.92       999\n",
      "   macro avg       0.46      0.50      0.48       999\n",
      "weighted avg       0.84      0.92      0.88       999\n",
      "\n",
      "Class 4 Confusion Matrix:\n",
      "[[752   0]\n",
      " [247   0]]\n",
      "Class 4 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86       752\n",
      "         1.0       0.00      0.00      0.00       247\n",
      "\n",
      "    accuracy                           0.75       999\n",
      "   macro avg       0.38      0.50      0.43       999\n",
      "weighted avg       0.57      0.75      0.65       999\n",
      "\n",
      "Class 5 Confusion Matrix:\n",
      "[[704   0]\n",
      " [295   0]]\n",
      "Class 5 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      1.00      0.83       704\n",
      "         1.0       0.00      0.00      0.00       295\n",
      "\n",
      "    accuracy                           0.70       999\n",
      "   macro avg       0.35      0.50      0.41       999\n",
      "weighted avg       0.50      0.70      0.58       999\n",
      "\n",
      "Class 6 Confusion Matrix:\n",
      "[[969   0]\n",
      " [ 30   0]]\n",
      "Class 6 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       969\n",
      "         1.0       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.97       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.94      0.97      0.96       999\n",
      "\n",
      "Class 7 Confusion Matrix:\n",
      "[[967   0]\n",
      " [ 32   0]]\n",
      "Class 7 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       967\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.97       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.94      0.97      0.95       999\n",
      "\n",
      "Class 8 Confusion Matrix:\n",
      "[[937   0]\n",
      " [ 62   0]]\n",
      "Class 8 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97       937\n",
      "         1.0       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.94       999\n",
      "   macro avg       0.47      0.50      0.48       999\n",
      "weighted avg       0.88      0.94      0.91       999\n",
      "\n",
      "Class 9 Confusion Matrix:\n",
      "[[934   0]\n",
      " [ 65   0]]\n",
      "Class 9 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.97       934\n",
      "         1.0       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.93       999\n",
      "   macro avg       0.47      0.50      0.48       999\n",
      "weighted avg       0.87      0.93      0.90       999\n",
      "\n",
      "Class 10 Confusion Matrix:\n",
      "[[751   0]\n",
      " [248   0]]\n",
      "Class 10 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86       751\n",
      "         1.0       0.00      0.00      0.00       248\n",
      "\n",
      "    accuracy                           0.75       999\n",
      "   macro avg       0.38      0.50      0.43       999\n",
      "weighted avg       0.57      0.75      0.65       999\n",
      "\n",
      "Class 11 Confusion Matrix:\n",
      "[[956   0]\n",
      " [ 43   0]]\n",
      "Class 11 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       956\n",
      "         1.0       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.96       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.92      0.96      0.94       999\n",
      "\n",
      "Class 12 Confusion Matrix:\n",
      "[[929   0]\n",
      " [ 70   0]]\n",
      "Class 12 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       929\n",
      "         1.0       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.93       999\n",
      "   macro avg       0.46      0.50      0.48       999\n",
      "weighted avg       0.86      0.93      0.90       999\n",
      "\n",
      "Class 13 Confusion Matrix:\n",
      "[[491   0]\n",
      " [508   0]]\n",
      "Class 13 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      1.00      0.66       491\n",
      "         1.0       0.00      0.00      0.00       508\n",
      "\n",
      "    accuracy                           0.49       999\n",
      "   macro avg       0.25      0.50      0.33       999\n",
      "weighted avg       0.24      0.49      0.32       999\n",
      "\n",
      "Class 14 Confusion Matrix:\n",
      "[[657   0]\n",
      " [342   0]]\n",
      "Class 14 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      1.00      0.79       657\n",
      "         1.0       0.00      0.00      0.00       342\n",
      "\n",
      "    accuracy                           0.66       999\n",
      "   macro avg       0.33      0.50      0.40       999\n",
      "weighted avg       0.43      0.66      0.52       999\n",
      "\n",
      "Class 15 Confusion Matrix:\n",
      "[[977   0]\n",
      " [ 22   0]]\n",
      "Class 15 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       977\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.98       999\n",
      "   macro avg       0.49      0.50      0.49       999\n",
      "weighted avg       0.96      0.98      0.97       999\n",
      "\n",
      "Class 16 Confusion Matrix:\n",
      "[[797   0]\n",
      " [202   0]]\n",
      "Class 16 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89       797\n",
      "         1.0       0.00      0.00      0.00       202\n",
      "\n",
      "    accuracy                           0.80       999\n",
      "   macro avg       0.40      0.50      0.44       999\n",
      "weighted avg       0.64      0.80      0.71       999\n",
      "\n",
      "Class 17 Confusion Matrix:\n",
      "[[931   0]\n",
      " [ 68   0]]\n",
      "Class 17 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       931\n",
      "         1.0       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.93       999\n",
      "   macro avg       0.47      0.50      0.48       999\n",
      "weighted avg       0.87      0.93      0.90       999\n",
      "\n",
      "Class 18 Confusion Matrix:\n",
      "[[611   0]\n",
      " [388   0]]\n",
      "Class 18 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76       611\n",
      "         1.0       0.00      0.00      0.00       388\n",
      "\n",
      "    accuracy                           0.61       999\n",
      "   macro avg       0.31      0.50      0.38       999\n",
      "weighted avg       0.37      0.61      0.46       999\n",
      "\n",
      "Class 19 Confusion Matrix:\n",
      "[[996   0]\n",
      " [  3   0]]\n",
      "Class 19 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       996\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           1.00       999\n",
      "   macro avg       0.50      0.50      0.50       999\n",
      "weighted avg       0.99      1.00      1.00       999\n",
      "\n",
      "Class 20 Confusion Matrix:\n",
      "[[630   0]\n",
      " [369   0]]\n",
      "Class 20 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      1.00      0.77       630\n",
      "         1.0       0.00      0.00      0.00       369\n",
      "\n",
      "    accuracy                           0.63       999\n",
      "   macro avg       0.32      0.50      0.39       999\n",
      "weighted avg       0.40      0.63      0.49       999\n",
      "\n",
      "Class 21 Confusion Matrix:\n",
      "[[925   0]\n",
      " [ 74   0]]\n",
      "Class 21 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       925\n",
      "         1.0       0.00      0.00      0.00        74\n",
      "\n",
      "    accuracy                           0.93       999\n",
      "   macro avg       0.46      0.50      0.48       999\n",
      "weighted avg       0.86      0.93      0.89       999\n",
      "\n",
      "Class 22 Confusion Matrix:\n",
      "[[  0 583]\n",
      " [  0 416]]\n",
      "Class 22 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       583\n",
      "         1.0       0.42      1.00      0.59       416\n",
      "\n",
      "    accuracy                           0.42       999\n",
      "   macro avg       0.21      0.50      0.29       999\n",
      "weighted avg       0.17      0.42      0.24       999\n",
      "\n",
      "Class 23 Confusion Matrix:\n",
      "[[969   0]\n",
      " [ 30   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 23 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       969\n",
      "         1.0       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.97       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.94      0.97      0.96       999\n",
      "\n",
      "Class 24 Confusion Matrix:\n",
      "[[918   0]\n",
      " [ 81   0]]\n",
      "Class 24 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96       918\n",
      "         1.0       0.00      0.00      0.00        81\n",
      "\n",
      "    accuracy                           0.92       999\n",
      "   macro avg       0.46      0.50      0.48       999\n",
      "weighted avg       0.84      0.92      0.88       999\n",
      "\n",
      "Class 25 Confusion Matrix:\n",
      "[[964   0]\n",
      " [ 35   0]]\n",
      "Class 25 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       964\n",
      "         1.0       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.96       999\n",
      "   macro avg       0.48      0.50      0.49       999\n",
      "weighted avg       0.93      0.96      0.95       999\n",
      "\n",
      "Class 26 Confusion Matrix:\n",
      "[[  0 252]\n",
      " [  0 747]]\n",
      "Class 26 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       252\n",
      "         1.0       0.75      1.00      0.86       747\n",
      "\n",
      "    accuracy                           0.75       999\n",
      "   macro avg       0.37      0.50      0.43       999\n",
      "weighted avg       0.56      0.75      0.64       999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Accuracy: 0.0000, Precision: 0.1829, Recall: 0.3653, F1-Score: 0.2297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Accuracy: 0.0000, Precision: 0.2141, Recall: 0.3857, F1-Score: 0.2673\n",
      "Model 3 - Accuracy: 0.0000, Precision: 0.1316, Recall: 0.2111, F1-Score: 0.1565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Adjust class weights to handle class imbalance\n",
    "class_counts = np.sum(val_labels, axis=0)\n",
    "total_counts = np.sum(class_counts)\n",
    "class_weights = total_counts / class_counts\n",
    "\n",
    "# Ensure weights are float tensors\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define the best hyperparameters\n",
    "best_learning_rate = 9.00873469960247e-05\n",
    "best_batch_size = 26\n",
    "best_dropout_rate = 0.10228576247508345\n",
    "num_models = 3\n",
    "models = []\n",
    "\n",
    "# Create model class with best dropout rate\n",
    "class HierarchicalCapsuleNetworkBERTLarge(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(HierarchicalCapsuleNetworkBERTLarge, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=1024, in_channels=1024, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=best_dropout_rate)\n",
    "        self.fc = nn.Linear(16 * 10 * 1, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# Train multiple models with mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "for i in range(num_models):\n",
    "    model = HierarchicalCapsuleNetworkBERTLarge(num_labels=num_labels).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=best_learning_rate)\n",
    "    \n",
    "    best_val_loss_aug = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_aug = 0\n",
    "        for batch in train_loader_aug:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss_aug += loss.item()\n",
    "        \n",
    "        train_loss_aug /= len(train_loader_aug)\n",
    "        val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "        \n",
    "        if val_loss_aug < best_val_loss_aug:\n",
    "            best_val_loss_aug = val_loss_aug\n",
    "            torch.save(model.state_dict(), f'best_model_with_weights_aug_bert_large_{i}.pth')\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'best_model_with_weights_aug_bert_large_{i}.pth'))\n",
    "    models.append(model)\n",
    "\n",
    "# Averaging predictions\n",
    "def ensemble_predict(models, data_loader, device):\n",
    "    all_preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "        all_preds.append(np.concatenate(preds, axis=0))\n",
    "    \n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds > 0.5  # Apply threshold\n",
    "\n",
    "# Evaluate the predictions\n",
    "def evaluate_predictions(predictions, true_labels):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Prepare validation labels\n",
    "val_labels = torch.cat([batch['labels'] for batch in val_loader_aug], dim=0).cpu().numpy()\n",
    "\n",
    "# Get ensemble predictions\n",
    "ensemble_preds = ensemble_predict(models, val_loader_aug, device)\n",
    "\n",
    "# Ensure predictions are in the correct shape and binary format\n",
    "ensemble_preds = ensemble_preds.astype(int)\n",
    "\n",
    "# Debug: print shapes and a few samples\n",
    "print(f\"Predictions shape: {ensemble_preds.shape}, Labels shape: {val_labels.shape}\")\n",
    "print(f\"Sample predictions: {ensemble_preds[:10]}, Sample labels: {val_labels[:10]}\")\n",
    "\n",
    "accuracy, precision, recall, f1 = evaluate_predictions(ensemble_preds, val_labels)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "for i in range(val_labels.shape[1]):\n",
    "    print(f\"Class {i} Confusion Matrix:\\n{confusion_matrix(val_labels[:, i], ensemble_preds[:, i])}\")\n",
    "    print(f\"Class {i} Classification Report:\\n{classification_report(val_labels[:, i], ensemble_preds[:, i])}\")\n",
    "\n",
    "# Optional: evaluate individual models\n",
    "for i, model in enumerate(models):\n",
    "    model_preds = ensemble_predict([model], val_loader_aug, device).astype(int)\n",
    "    acc, prec, rec, f1_ind = evaluate_predictions(model_preds, val_labels)\n",
    "    print(f\"Model {i+1} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1_ind:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf79c2-60c3-4dc9-b68e-373b4a8db6f1",
   "metadata": {},
   "source": [
    "Custom Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92dc1a3b-b4bc-4d9b-a78a-447a4f812aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling completed. New dataset size: 65\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def custom_oversample(X, y):\n",
    "    # Convert to numpy arrays if not already\n",
    "    if not isinstance(X, np.ndarray):\n",
    "        X = X.numpy()\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = y.numpy()\n",
    "\n",
    "    # Count the number of samples in each class\n",
    "    class_counts = y.sum(axis=0)\n",
    "    max_count = int(class_counts.max())  # Ensure max_count is an integer\n",
    "\n",
    "    # Initialize lists to store the oversampled data\n",
    "    X_resampled = []\n",
    "    y_resampled = []\n",
    "\n",
    "    # Oversample each class to the maximum count\n",
    "    for class_index in range(y.shape[1]):\n",
    "        class_samples = X[y[:, class_index] == 1]\n",
    "        class_labels = y[y[:, class_index] == 1]\n",
    "\n",
    "        if class_samples.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Repeat the samples until we have enough\n",
    "        while len(class_samples) < max_count:\n",
    "            class_samples = np.vstack([class_samples, class_samples])\n",
    "            class_labels = np.vstack([class_labels, class_labels])\n",
    "\n",
    "        # Trim the excess samples\n",
    "        class_samples = class_samples[:max_count]\n",
    "        class_labels = class_labels[:max_count]\n",
    "\n",
    "        X_resampled.append(class_samples)\n",
    "        y_resampled.append(class_labels)\n",
    "\n",
    "    # Concatenate all the oversampled classes\n",
    "    X_resampled = np.vstack(X_resampled)\n",
    "    y_resampled = np.vstack(y_resampled)\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Flatten the input_ids and labels for oversampling\n",
    "X_train = batch['input_ids'].numpy()\n",
    "y_train = batch['labels'].numpy()\n",
    "\n",
    "# Apply custom oversampling\n",
    "X_resampled, y_resampled = custom_oversample(X_train, y_train)\n",
    "\n",
    "# Convert resampled data back to PyTorch tensors and reshape\n",
    "X_resampled_tensor = torch.tensor(X_resampled, dtype=torch.long)\n",
    "y_resampled_tensor = torch.tensor(y_resampled, dtype=torch.float)\n",
    "\n",
    "# Create a new DataLoader with the resampled data\n",
    "train_dataset_resampled = TensorDataset(X_resampled_tensor, y_resampled_tensor)\n",
    "train_loader_resampled = DataLoader(train_dataset_resampled, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "print(\"Resampling completed. New dataset size:\", len(train_dataset_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded4e73-2bfb-49be-ac16-03b4edf25520",
   "metadata": {},
   "source": [
    "Training and Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "205ef12b-dc93-4ee1-916d-0948508ab55c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.0180, Precision: 0.3771, Recall: 0.5354, F1-Score: 0.4079\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Define the best hyperparameters\n",
    "\n",
    "\n",
    "best_learning_rate = 9.00873469960247e-05\n",
    "\n",
    "best_dropout_rate = 0.10228576247508345\n",
    "num_models = 3\n",
    "models = []\n",
    "\n",
    "# Create model class with best dropout rate\n",
    "class HierarchicalCapsuleNetworkBERTLarge(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(HierarchicalCapsuleNetworkBERTLarge, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "        self.capsule_layer = CapsuleLayer(num_capsules=10, num_routes=1024, in_channels=1024, out_channels=16)\n",
    "        self.dropout = nn.Dropout(p=best_dropout_rate)\n",
    "        self.fc = nn.Linear(16 * 10 * 1, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.capsule_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# Train multiple models with mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "for i in range(num_models):\n",
    "    model = HierarchicalCapsuleNetworkBERTLarge(num_labels=num_labels).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=best_learning_rate)\n",
    "    \n",
    "    best_val_loss_aug = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_aug = 0\n",
    "        for batch in train_loader_resampled:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(device)  # Create attention mask\n",
    "            labels = batch[1].to(device).float()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss_aug += loss.item()\n",
    "        \n",
    "        train_loss_aug /= len(train_loader_resampled)\n",
    "        val_loss_aug = eval_model(model, val_loader_aug, criterion, device)\n",
    "        \n",
    "        if val_loss_aug < best_val_loss_aug:\n",
    "            best_val_loss_aug = val_loss_aug\n",
    "            torch.save(model.state_dict(), f'best_model_with_weights_aug_bert_large_{i}.pth')\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'best_model_with_weights_aug_bert_large_{i}.pth'))\n",
    "    models.append(model)\n",
    "\n",
    "# Averaging predictions\n",
    "def ensemble_predict(models, data_loader, device):\n",
    "    all_preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "        all_preds.append(np.concatenate(preds, axis=0))\n",
    "    \n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds > 0.5  # Apply threshold\n",
    "\n",
    "# Evaluate the predictions\n",
    "def evaluate_predictions(predictions, true_labels):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Prepare validation labels\n",
    "val_labels = torch.cat([batch['labels'] for batch in val_loader_aug], dim=0).cpu().numpy()\n",
    "\n",
    "# Get ensemble predictions\n",
    "ensemble_preds = ensemble_predict(models, val_loader_aug, device)\n",
    "accuracy, precision, recall, f1 = evaluate_predictions(ensemble_preds, val_labels)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a8dc6-8294-4ffc-9a35-b66b88ccf839",
   "metadata": {},
   "source": [
    " Verify Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a747beba-7185-455e-8f14-9ecc2321f7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled input_ids shape: torch.Size([65, 128])\n",
      "Resampled labels shape: torch.Size([65, 27])\n"
     ]
    }
   ],
   "source": [
    "# Convert resampled data back to PyTorch tensors and reshape\n",
    "X_resampled_tensor = torch.tensor(X_resampled, dtype=torch.long)\n",
    "y_resampled_tensor = torch.tensor(y_resampled, dtype=torch.float)\n",
    "\n",
    "# Create a new dataset with the resampled data\n",
    "class ResampledDataset(Dataset):\n",
    "    def __init__(self, input_ids, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "train_dataset_resampled = ResampledDataset(X_resampled_tensor, y_resampled_tensor)\n",
    "train_loader_resampled = DataLoader(train_dataset_resampled, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "# Check the shapes\n",
    "print(\"Resampled input_ids shape:\", X_resampled_tensor.shape)\n",
    "print(\"Resampled labels shape:\", y_resampled_tensor.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
